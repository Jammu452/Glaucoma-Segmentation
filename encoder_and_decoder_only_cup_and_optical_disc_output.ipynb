{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jammu452/Glaucoma-Segmentation/blob/main/encoder_and_decoder_only_cup_and_optical_disc_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzdPEGJ2C8S0",
        "outputId": "4153f5b8-c28a-47d5-8aad-cd5ef1898e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!unzip '/content/drive/MyDrive/origa.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8bEcATPjDGrN",
        "outputId": "c1cbdd2b-be77-43c0-a696-86d65a459eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/origa.zip\n",
            "  inflating: origa/readme.txt        \n",
            "  inflating: origa/manual_labels.xlsx  \n",
            "  inflating: origa/manual marking.rar  \n",
            "  inflating: origa/manual marking/manual marking/629.mat  \n",
            "  inflating: origa/manual marking/manual marking/625.mat  \n",
            "  inflating: origa/manual marking/manual marking/626.mat  \n",
            "  inflating: origa/manual marking/manual marking/648.mat  \n",
            "  inflating: origa/manual marking/manual marking/633.mat  \n",
            "  inflating: origa/manual marking/manual marking/650.mat  \n",
            "  inflating: origa/manual marking/manual marking/619.mat  \n",
            "  inflating: origa/manual marking/manual marking/627.mat  \n",
            "  inflating: origa/manual marking/manual marking/618.mat  \n",
            "  inflating: origa/manual marking/manual marking/622.mat  \n",
            "  inflating: origa/manual marking/manual marking/628.mat  \n",
            "  inflating: origa/manual marking/manual marking/632.mat  \n",
            "  inflating: origa/manual marking/manual marking/615.mat  \n",
            "  inflating: origa/manual marking/manual marking/635.mat  \n",
            "  inflating: origa/manual marking/manual marking/643.mat  \n",
            "  inflating: origa/manual marking/manual marking/649.mat  \n",
            "  inflating: origa/manual marking/manual marking/616.mat  \n",
            "  inflating: origa/manual marking/manual marking/642.mat  \n",
            "  inflating: origa/manual marking/manual marking/639.mat  \n",
            "  inflating: origa/manual marking/manual marking/630.mat  \n",
            "  inflating: origa/manual marking/manual marking/641.mat  \n",
            "  inflating: origa/manual marking/manual marking/644.mat  \n",
            "  inflating: origa/manual marking/manual marking/646.mat  \n",
            "  inflating: origa/manual marking/manual marking/647.mat  \n",
            "  inflating: origa/manual marking/manual marking/634.mat  \n",
            "  inflating: origa/manual marking/manual marking/623.mat  \n",
            "  inflating: origa/manual marking/manual marking/614.mat  \n",
            "  inflating: origa/manual marking/manual marking/602.mat  \n",
            "  inflating: origa/manual marking/manual marking/605.mat  \n",
            "  inflating: origa/manual marking/manual marking/601.mat  \n",
            "  inflating: origa/manual marking/manual marking/588.mat  \n",
            "  inflating: origa/manual marking/manual marking/587.mat  \n",
            "  inflating: origa/manual marking/manual marking/593.mat  \n",
            "  inflating: origa/manual marking/manual marking/640.mat  \n",
            "  inflating: origa/manual marking/manual marking/613.mat  \n",
            "  inflating: origa/manual marking/manual marking/620.mat  \n",
            "  inflating: origa/manual marking/manual marking/636.mat  \n",
            "  inflating: origa/manual marking/manual marking/612.mat  \n",
            "  inflating: origa/manual marking/manual marking/637.mat  \n",
            "  inflating: origa/manual marking/manual marking/621.mat  \n",
            "  inflating: origa/manual marking/manual marking/609.mat  \n",
            "  inflating: origa/manual marking/manual marking/595.mat  \n",
            "  inflating: origa/manual marking/manual marking/611.mat  \n",
            "  inflating: origa/manual marking/manual marking/581.mat  \n",
            "  inflating: origa/manual marking/manual marking/592.mat  \n",
            "  inflating: origa/manual marking/manual marking/589.mat  \n",
            "  inflating: origa/manual marking/manual marking/606.mat  \n",
            "  inflating: origa/manual marking/manual marking/608.mat  \n",
            "  inflating: origa/manual marking/manual marking/573.mat  \n",
            "  inflating: origa/manual marking/manual marking/576.mat  \n",
            "  inflating: origa/manual marking/manual marking/586.mat  \n",
            "  inflating: origa/manual marking/manual marking/568.mat  \n",
            "  inflating: origa/manual marking/manual marking/571.mat  \n",
            "  inflating: origa/manual marking/manual marking/569.mat  \n",
            "  inflating: origa/manual marking/manual marking/572.mat  \n",
            "  inflating: origa/manual marking/manual marking/585.mat  \n",
            "  inflating: origa/manual marking/manual marking/604.mat  \n",
            "  inflating: origa/manual marking/manual marking/590.mat  \n",
            "  inflating: origa/manual marking/manual marking/580.mat  \n",
            "  inflating: origa/manual marking/manual marking/563.mat  \n",
            "  inflating: origa/manual marking/manual marking/564.mat  \n",
            "  inflating: origa/manual marking/manual marking/574.mat  \n",
            "  inflating: origa/manual marking/manual marking/560.mat  \n",
            "  inflating: origa/manual marking/manual marking/607.mat  \n",
            "  inflating: origa/manual marking/manual marking/567.mat  \n",
            "  inflating: origa/manual marking/manual marking/599.mat  \n",
            "  inflating: origa/manual marking/manual marking/597.mat  \n",
            "  inflating: origa/manual marking/manual marking/565.mat  \n",
            "  inflating: origa/manual marking/manual marking/562.mat  \n",
            "  inflating: origa/manual marking/manual marking/594.mat  \n",
            "  inflating: origa/manual marking/manual marking/598.mat  \n",
            "  inflating: origa/manual marking/manual marking/582.mat  \n",
            "  inflating: origa/manual marking/manual marking/583.mat  \n",
            "  inflating: origa/manual marking/manual marking/554.mat  \n",
            "  inflating: origa/manual marking/manual marking/578.mat  \n",
            "  inflating: origa/manual marking/manual marking/579.mat  \n",
            "  inflating: origa/manual marking/manual marking/549.mat  \n",
            "  inflating: origa/manual marking/manual marking/566.mat  \n",
            "  inflating: origa/manual marking/manual marking/548.mat  \n",
            "  inflating: origa/manual marking/manual marking/550.mat  \n",
            "  inflating: origa/manual marking/manual marking/544.mat  \n",
            "  inflating: origa/manual marking/manual marking/552.mat  \n",
            "  inflating: origa/manual marking/manual marking/555.mat  \n",
            "  inflating: origa/manual marking/manual marking/537.mat  \n",
            "  inflating: origa/manual marking/manual marking/533.mat  \n",
            "  inflating: origa/manual marking/manual marking/534.mat  \n",
            "  inflating: origa/manual marking/manual marking/553.mat  \n",
            "  inflating: origa/manual marking/manual marking/529.mat  \n",
            "  inflating: origa/manual marking/manual marking/575.mat  \n",
            "  inflating: origa/manual marking/manual marking/542.mat  \n",
            "  inflating: origa/manual marking/manual marking/538.mat  \n",
            "  inflating: origa/manual marking/manual marking/527.mat  \n",
            "  inflating: origa/manual marking/manual marking/518.mat  \n",
            "  inflating: origa/manual marking/manual marking/530.mat  \n",
            "  inflating: origa/manual marking/manual marking/515.mat  \n",
            "  inflating: origa/manual marking/manual marking/561.mat  \n",
            "  inflating: origa/manual marking/manual marking/546.mat  \n",
            "  inflating: origa/manual marking/manual marking/508.mat  \n",
            "  inflating: origa/manual marking/manual marking/541.mat  \n",
            "  inflating: origa/manual marking/manual marking/521.mat  \n",
            "  inflating: origa/manual marking/manual marking/543.mat  \n",
            "  inflating: origa/manual marking/manual marking/547.mat  \n",
            "  inflating: origa/manual marking/manual marking/559.mat  \n",
            "  inflating: origa/manual marking/manual marking/520.mat  \n",
            "  inflating: origa/manual marking/manual marking/539.mat  \n",
            "  inflating: origa/manual marking/manual marking/511.mat  \n",
            "  inflating: origa/manual marking/manual marking/556.mat  \n",
            "  inflating: origa/manual marking/manual marking/525.mat  \n",
            "  inflating: origa/manual marking/manual marking/558.mat  \n",
            "  inflating: origa/manual marking/manual marking/523.mat  \n",
            "  inflating: origa/manual marking/manual marking/514.mat  \n",
            "  inflating: origa/manual marking/manual marking/526.mat  \n",
            "  inflating: origa/manual marking/manual marking/531.mat  \n",
            "  inflating: origa/manual marking/manual marking/528.mat  \n",
            "  inflating: origa/manual marking/manual marking/516.mat  \n",
            "  inflating: origa/manual marking/manual marking/536.mat  \n",
            "  inflating: origa/manual marking/manual marking/509.mat  \n",
            "  inflating: origa/manual marking/manual marking/519.mat  \n",
            "  inflating: origa/manual marking/manual marking/500.mat  \n",
            "  inflating: origa/manual marking/manual marking/512.mat  \n",
            "  inflating: origa/manual marking/manual marking/498.mat  \n",
            "  inflating: origa/manual marking/manual marking/513.mat  \n",
            "  inflating: origa/manual marking/manual marking/522.mat  \n",
            "  inflating: origa/manual marking/manual marking/481.mat  \n",
            "  inflating: origa/manual marking/manual marking/494.mat  \n",
            "  inflating: origa/manual marking/manual marking/497.mat  \n",
            "  inflating: origa/manual marking/manual marking/501.mat  \n",
            "  inflating: origa/manual marking/manual marking/492.mat  \n",
            "  inflating: origa/manual marking/manual marking/486.mat  \n",
            "  inflating: origa/manual marking/manual marking/496.mat  \n",
            "  inflating: origa/manual marking/manual marking/503.mat  \n",
            "  inflating: origa/manual marking/manual marking/478.mat  \n",
            "  inflating: origa/manual marking/manual marking/479.mat  \n",
            "  inflating: origa/manual marking/manual marking/489.mat  \n",
            "  inflating: origa/manual marking/manual marking/490.mat  \n",
            "  inflating: origa/manual marking/manual marking/491.mat  \n",
            "  inflating: origa/manual marking/manual marking/472.mat  \n",
            "  inflating: origa/manual marking/manual marking/469.mat  \n",
            "  inflating: origa/manual marking/manual marking/476.mat  \n",
            "  inflating: origa/manual marking/manual marking/474.mat  \n",
            "  inflating: origa/manual marking/manual marking/483.mat  \n",
            "  inflating: origa/manual marking/manual marking/506.mat  \n",
            "  inflating: origa/manual marking/manual marking/477.mat  \n",
            "  inflating: origa/manual marking/manual marking/467.mat  \n",
            "  inflating: origa/manual marking/manual marking/507.mat  \n",
            "  inflating: origa/manual marking/manual marking/480.mat  \n",
            "  inflating: origa/images/images/001.jpg  \n",
            "  inflating: origa/manual marking/manual marking/470.mat  \n",
            "  inflating: origa/manual marking/manual marking/459.mat  \n",
            "  inflating: origa/manual marking/manual marking/504.mat  \n",
            "  inflating: origa/manual marking/manual marking/458.mat  \n",
            "  inflating: origa/manual marking/manual marking/505.mat  \n",
            "  inflating: origa/manual marking/manual marking/487.mat  \n",
            "  inflating: origa/images/images/644.jpg  \n",
            "  inflating: origa/manual marking/manual marking/456.mat  \n",
            "  inflating: origa/manual marking/manual marking/466.mat  \n",
            "  inflating: origa/manual marking/manual marking/454.mat  \n",
            "  inflating: origa/images/images/650.jpg  \n",
            "  inflating: origa/manual marking/manual marking/462.mat  \n",
            "  inflating: origa/images/images/637.jpg  \n",
            "  inflating: origa/manual marking/manual marking/499.mat  \n",
            "  inflating: origa/manual marking/manual marking/453.mat  \n",
            "  inflating: origa/manual marking/manual marking/473.mat  \n",
            "  inflating: origa/manual marking/manual marking/447.mat  \n",
            "  inflating: origa/images/images/643.jpg  \n",
            "  inflating: origa/manual marking/manual marking/465.mat  \n",
            "  inflating: origa/manual marking/manual marking/463.mat  \n",
            "  inflating: origa/images/images/642.jpg  \n",
            "  inflating: origa/manual marking/manual marking/451.mat  \n",
            "  inflating: origa/images/images/641.jpg  \n",
            "  inflating: origa/manual marking/manual marking/446.mat  \n",
            "  inflating: origa/manual marking/manual marking/484.mat  \n",
            "  inflating: origa/manual marking/manual marking/485.mat  \n",
            "  inflating: origa/images/images/629.jpg  \n",
            "  inflating: origa/manual marking/manual marking/457.mat  \n",
            "  inflating: origa/images/images/639.jpg  \n",
            "  inflating: origa/images/images/636.jpg  \n",
            "  inflating: origa/manual marking/manual marking/464.mat  \n",
            "  inflating: origa/images/images/628.jpg  \n",
            "  inflating: origa/manual marking/manual marking/433.mat  \n",
            "  inflating: origa/images/images/627.jpg  \n",
            "  inflating: origa/manual marking/manual marking/444.mat  \n",
            "  inflating: origa/manual marking/manual marking/493.mat  \n",
            "  inflating: origa/images/images/640.jpg  \n",
            "  inflating: origa/manual marking/manual marking/452.mat  \n",
            "  inflating: origa/images/images/621.jpg  \n",
            "  inflating: origa/images/images/649.jpg  \n",
            "  inflating: origa/manual marking/manual marking/455.mat  \n",
            "  inflating: origa/images/images/620.jpg  \n",
            "  inflating: origa/images/images/613.jpg  \n",
            "  inflating: origa/manual marking/manual marking/460.mat  \n",
            "  inflating: origa/manual marking/manual marking/432.mat  \n",
            "  inflating: origa/images/images/630.jpg  \n",
            "  inflating: origa/manual marking/manual marking/450.mat  \n",
            "  inflating: origa/manual marking/manual marking/434.mat  \n",
            "  inflating: origa/manual marking/manual marking/449.mat  \n",
            "  inflating: origa/images/images/614.jpg  \n",
            "  inflating: origa/manual marking/manual marking/439.mat  \n",
            "  inflating: origa/images/images/625.jpg  \n",
            "  inflating: origa/manual marking/manual marking/443.mat  \n",
            "  inflating: origa/images/images/635.jpg  \n",
            "  inflating: origa/images/images/622.jpg  \n",
            "  inflating: origa/manual marking/manual marking/438.mat  \n",
            "  inflating: origa/manual marking/manual marking/448.mat  \n",
            "  inflating: origa/manual marking/manual marking/435.mat  \n",
            "  inflating: origa/manual marking/manual marking/431.mat  \n",
            "  inflating: origa/images/images/599.jpg  \n",
            "  inflating: origa/images/images/597.jpg  \n",
            "  inflating: origa/manual marking/manual marking/442.mat  \n",
            "  inflating: origa/images/images/626.jpg  \n",
            "  inflating: origa/images/images/609.jpg  \n",
            "  inflating: origa/manual marking/manual marking/437.mat  \n",
            "  inflating: origa/manual marking/manual marking/445.mat  \n",
            "  inflating: origa/images/images/605.jpg  \n",
            "  inflating: origa/manual marking/manual marking/420.mat  \n",
            "  inflating: origa/manual marking/manual marking/421.mat  \n",
            "  inflating: origa/images/images/595.jpg  \n",
            "  inflating: origa/images/images/606.jpg  \n",
            "  inflating: origa/images/images/602.jpg  \n",
            "  inflating: origa/manual marking/manual marking/429.mat  \n",
            "  inflating: origa/images/images/598.jpg  \n",
            "  inflating: origa/manual marking/manual marking/423.mat  \n",
            "  inflating: origa/images/images/580.jpg  \n",
            "  inflating: origa/images/images/585.jpg  \n",
            "  inflating: origa/images/images/590.jpg  \n",
            "  inflating: origa/images/images/579.jpg  \n",
            "  inflating: origa/images/images/582.jpg  \n",
            "  inflating: origa/manual marking/manual marking/441.mat  \n",
            "  inflating: origa/manual marking/manual marking/440.mat  \n",
            "  inflating: origa/images/images/601.jpg  \n",
            "  inflating: origa/manual marking/manual marking/428.mat  \n",
            "  inflating: origa/images/images/571.jpg  \n",
            "  inflating: origa/manual marking/manual marking/419.mat  \n",
            "  inflating: origa/images/images/572.jpg  \n",
            "  inflating: origa/manual marking/manual marking/413.mat  \n",
            "  inflating: origa/manual marking/manual marking/436.mat  \n",
            "  inflating: origa/manual marking/manual marking/414.mat  \n",
            "  inflating: origa/manual marking/manual marking/427.mat  \n",
            "  inflating: origa/manual marking/manual marking/412.mat  \n",
            "  inflating: origa/manual marking/manual marking/422.mat  \n",
            "  inflating: origa/images/images/568.jpg  \n",
            "  inflating: origa/manual marking/manual marking/410.mat  \n",
            "  inflating: origa/manual marking/manual marking/424.mat  \n",
            "  inflating: origa/manual marking/manual marking/430.mat  \n",
            "  inflating: origa/manual marking/manual marking/417.mat  \n",
            "  inflating: origa/images/images/569.jpg  \n",
            "  inflating: origa/manual marking/manual marking/426.mat  \n",
            "  inflating: origa/images/images/554.jpg  \n",
            "  inflating: origa/images/images/581.jpg  \n",
            "  inflating: origa/images/images/575.jpg  \n",
            "  inflating: origa/manual marking/manual marking/418.mat  \n",
            "  inflating: origa/manual marking/manual marking/416.mat  \n",
            "  inflating: origa/manual marking/manual marking/425.mat  \n",
            "  inflating: origa/images/images/586.jpg  \n",
            "  inflating: origa/images/images/576.jpg  \n",
            "  inflating: origa/manual marking/manual marking/409.mat  \n",
            "  inflating: origa/manual marking/manual marking/411.mat  \n",
            "  inflating: origa/images/images/558.jpg  \n",
            "  inflating: origa/images/images/567.jpg  \n",
            "  inflating: origa/manual marking/manual marking/415.mat  \n",
            "  inflating: origa/images/images/530.jpg  \n",
            "  inflating: origa/manual marking/manual marking/408.mat  \n",
            "  inflating: origa/manual marking/manual marking/400.mat  \n",
            "  inflating: origa/images/images/531.jpg  \n",
            "  inflating: origa/images/images/555.jpg  \n",
            "  inflating: origa/images/images/543.jpg  \n",
            "  inflating: origa/images/images/560.jpg  \n",
            "  inflating: origa/images/images/539.jpg  \n",
            "  inflating: origa/images/images/522.jpg  \n",
            "  inflating: origa/images/images/528.jpg  \n",
            "  inflating: origa/images/images/529.jpg  \n",
            "  inflating: origa/manual marking/manual marking/401.mat  \n",
            "  inflating: origa/manual marking/manual marking/405.mat  \n",
            "  inflating: origa/images/images/527.jpg  \n",
            "  inflating: origa/images/images/536.jpg  \n",
            "  inflating: origa/manual marking/manual marking/392.mat  \n",
            "  inflating: origa/images/images/518.jpg  \n",
            "  inflating: origa/manual marking/manual marking/404.mat  \n",
            "  inflating: origa/manual marking/manual marking/389.mat  \n",
            "  inflating: origa/images/images/514.jpg  \n",
            "  inflating: origa/manual marking/manual marking/403.mat  \n",
            "  inflating: origa/images/images/544.jpg  \n",
            "  inflating: origa/images/images/520.jpg  \n",
            "  inflating: origa/images/images/519.jpg  \n",
            "  inflating: origa/images/images/506.jpg  \n",
            "  inflating: origa/manual marking/manual marking/407.mat  \n",
            "  inflating: origa/manual marking/manual marking/391.mat  \n",
            "  inflating: origa/images/images/559.jpg  \n",
            "  inflating: origa/manual marking/manual marking/402.mat  \n",
            "  inflating: origa/images/images/504.jpg  \n",
            "  inflating: origa/images/images/507.jpg  \n",
            "  inflating: origa/manual marking/manual marking/393.mat  \n",
            "  inflating: origa/manual marking/manual marking/390.mat  \n",
            "  inflating: origa/manual marking/manual marking/395.mat  \n",
            "  inflating: origa/images/images/505.jpg  \n",
            "  inflating: origa/manual marking/manual marking/385.mat  \n",
            "  inflating: origa/manual marking/manual marking/377.mat  \n",
            "  inflating: origa/images/images/513.jpg  \n",
            "  inflating: origa/manual marking/manual marking/388.mat  \n",
            "  inflating: origa/manual marking/manual marking/394.mat  \n",
            "  inflating: origa/images/images/501.jpg  \n",
            "  inflating: origa/manual marking/manual marking/379.mat  \n",
            "  inflating: origa/images/images/521.jpg  \n",
            "  inflating: origa/manual marking/manual marking/399.mat  \n",
            "  inflating: origa/images/images/497.jpg  \n",
            "  inflating: origa/manual marking/manual marking/398.mat  \n",
            "  inflating: origa/images/images/511.jpg  \n",
            "  inflating: origa/manual marking/manual marking/387.mat  \n",
            "  inflating: origa/manual marking/manual marking/386.mat  \n",
            "  inflating: origa/images/images/512.jpg  \n",
            "  inflating: origa/manual marking/manual marking/396.mat  \n",
            "  inflating: origa/manual marking/manual marking/381.mat  \n",
            "  inflating: origa/images/images/503.jpg  \n",
            "  inflating: origa/manual marking/manual marking/382.mat  \n",
            "  inflating: origa/manual marking/manual marking/383.mat  \n",
            "  inflating: origa/manual marking/manual marking/376.mat  \n",
            "  inflating: origa/images/images/498.jpg  \n",
            "  inflating: origa/images/images/486.jpg  \n",
            "  inflating: origa/images/images/499.jpg  \n",
            "  inflating: origa/images/images/478.jpg  \n",
            "  inflating: origa/images/images/477.jpg  \n",
            "  inflating: origa/manual marking/manual marking/372.mat  \n",
            "  inflating: origa/images/images/485.jpg  \n",
            "  inflating: origa/images/images/500.jpg  \n",
            "  inflating: origa/manual marking/manual marking/371.mat  \n",
            "  inflating: origa/manual marking/manual marking/380.mat  \n",
            "  inflating: origa/images/images/457.jpg  \n",
            "  inflating: origa/images/images/484.jpg  \n",
            "  inflating: origa/images/images/458.jpg  \n",
            "  inflating: origa/manual marking/manual marking/369.mat  \n",
            "  inflating: origa/images/images/466.jpg  \n",
            "  inflating: origa/images/images/459.jpg  \n",
            "  inflating: origa/images/images/465.jpg  \n",
            "  inflating: origa/images/images/480.jpg  \n",
            "  inflating: origa/images/images/496.jpg  \n",
            "  inflating: origa/images/images/460.jpg  \n",
            "  inflating: origa/manual marking/manual marking/375.mat  \n",
            "  inflating: origa/manual marking/manual marking/378.mat  \n",
            "  inflating: origa/images/images/487.jpg  \n",
            "  inflating: origa/images/images/442.jpg  \n",
            "  inflating: origa/images/images/449.jpg  \n",
            "  inflating: origa/images/images/443.jpg  \n",
            "  inflating: origa/images/images/444.jpg  \n",
            "  inflating: origa/images/images/446.jpg  \n",
            "  inflating: origa/manual marking/manual marking/368.mat  \n",
            "  inflating: origa/images/images/439.jpg  \n",
            "  inflating: origa/images/images/440.jpg  \n",
            "  inflating: origa/images/images/447.jpg  \n",
            "  inflating: origa/manual marking/manual marking/374.mat  \n",
            "  inflating: origa/images/images/408.jpg  \n",
            "  inflating: origa/images/images/428.jpg  \n",
            "  inflating: origa/images/images/403.jpg  \n",
            "  inflating: origa/images/images/421.jpg  \n",
            "  inflating: origa/images/images/409.jpg  \n",
            "  inflating: origa/images/images/384.jpg  \n",
            "  inflating: origa/images/images/411.jpg  \n",
            "  inflating: origa/images/images/390.jpg  \n",
            "  inflating: origa/images/images/445.jpg  \n",
            "  inflating: origa/images/images/429.jpg  \n",
            "  inflating: origa/images/images/401.jpg  \n",
            "  inflating: origa/images/images/399.jpg  \n",
            "  inflating: origa/images/images/438.jpg  \n",
            "  inflating: origa/images/images/393.jpg  \n",
            "  inflating: origa/images/images/402.jpg  \n",
            "  inflating: origa/images/images/400.jpg  \n",
            "  inflating: origa/images/images/389.jpg  \n",
            "  inflating: origa/images/images/388.jpg  \n",
            "  inflating: origa/images/images/479.jpg  \n",
            "  inflating: origa/images/images/448.jpg  \n",
            "  inflating: origa/images/images/378.jpg  \n",
            "  inflating: origa/images/images/392.jpg  \n",
            "  inflating: origa/manual marking/manual marking/384.mat  \n",
            "  inflating: origa/images/images/410.jpg  \n",
            "  inflating: origa/images/images/383.jpg  \n",
            "  inflating: origa/images/images/372.jpg  \n",
            "  inflating: origa/images/images/381.jpg  \n",
            "  inflating: origa/images/images/441.jpg  \n",
            "  inflating: origa/images/images/420.jpg  \n",
            "  inflating: origa/images/images/347.jpg  \n",
            "  inflating: origa/images/images/367.jpg  \n",
            "  inflating: origa/images/images/375.jpg  \n",
            "  inflating: origa/images/images/340.jpg  \n",
            "  inflating: origa/images/images/380.jpg  \n",
            "  inflating: origa/images/images/352.jpg  \n",
            "  inflating: origa/images/images/398.jpg  \n",
            "  inflating: origa/images/images/376.jpg  \n",
            "  inflating: origa/images/images/382.jpg  \n",
            "  inflating: origa/images/images/377.jpg  \n",
            "  inflating: origa/images/images/358.jpg  \n",
            "  inflating: origa/images/images/366.jpg  \n",
            "  inflating: origa/images/images/374.jpg  \n",
            "  inflating: origa/images/images/336.jpg  \n",
            "  inflating: origa/images/images/379.jpg  \n",
            "  inflating: origa/images/images/333.jpg  \n",
            "  inflating: origa/images/images/342.jpg  \n",
            "  inflating: origa/images/images/323.jpg  \n",
            "  inflating: origa/images/images/332.jpg  \n",
            "  inflating: origa/images/images/334.jpg  \n",
            "  inflating: origa/images/images/328.jpg  \n",
            "  inflating: origa/images/images/335.jpg  \n",
            "  inflating: origa/images/images/373.jpg  \n",
            "  inflating: origa/images/images/320.jpg  \n",
            "  inflating: origa/images/images/387.jpg  \n",
            "  inflating: origa/images/images/357.jpg  \n",
            "  inflating: origa/images/images/303.jpg  \n",
            "  inflating: origa/images/images/339.jpg  \n",
            "  inflating: origa/images/images/302.jpg  \n",
            "  inflating: origa/images/images/337.jpg  \n",
            "  inflating: origa/images/images/346.jpg  \n",
            "  inflating: origa/images/images/312.jpg  \n",
            "  inflating: origa/images/images/315.jpg  \n",
            "  inflating: origa/images/images/338.jpg  \n",
            "  inflating: origa/images/images/300.jpg  \n",
            "  inflating: origa/images/images/316.jpg  \n",
            "  inflating: origa/images/images/301.jpg  \n",
            "  inflating: origa/images/images/296.jpg  \n",
            "  inflating: origa/images/images/311.jpg  \n",
            "  inflating: origa/images/images/314.jpg  \n",
            "  inflating: origa/images/images/285.jpg  \n",
            "  inflating: origa/images/images/313.jpg  \n",
            "  inflating: origa/images/images/272.jpg  \n",
            "  inflating: origa/images/images/324.jpg  \n",
            "  inflating: origa/images/images/329.jpg  \n",
            "  inflating: origa/images/images/278.jpg  \n",
            "  inflating: origa/images/images/261.jpg  \n",
            "  inflating: origa/images/images/262.jpg  \n",
            "  inflating: origa/images/images/277.jpg  \n",
            "  inflating: origa/images/images/268.jpg  \n",
            "  inflating: origa/images/images/281.jpg  \n",
            "  inflating: origa/images/images/319.jpg  \n",
            "  inflating: origa/images/images/327.jpg  \n",
            "  inflating: origa/images/images/271.jpg  \n",
            "  inflating: origa/images/images/267.jpg  \n",
            "  inflating: origa/images/images/286.jpg  \n",
            "  inflating: origa/images/images/269.jpg  \n",
            "  inflating: origa/images/images/283.jpg  \n",
            "  inflating: origa/images/images/258.jpg  \n",
            "  inflating: origa/images/images/254.jpg  \n",
            "  inflating: origa/images/images/257.jpg  \n",
            "  inflating: origa/images/images/282.jpg  \n",
            "  inflating: origa/images/images/253.jpg  \n",
            "  inflating: origa/images/images/242.jpg  \n",
            "  inflating: origa/manual marking/manual marking/397.mat  \n",
            "  inflating: origa/images/images/251.jpg  \n",
            "  inflating: origa/images/images/252.jpg  \n",
            "  inflating: origa/images/images/295.jpg  \n",
            "  inflating: origa/images/images/230.jpg  \n",
            "  inflating: origa/images/images/233.jpg  \n",
            "  inflating: origa/images/images/244.jpg  \n",
            "  inflating: origa/images/images/241.jpg  \n",
            "  inflating: origa/images/images/236.jpg  \n",
            "  inflating: origa/images/images/229.jpg  \n",
            "  inflating: origa/images/images/256.jpg  \n",
            "  inflating: origa/images/images/237.jpg  \n",
            "  inflating: origa/images/images/246.jpg  \n",
            "  inflating: origa/images/images/218.jpg  \n",
            "  inflating: origa/images/images/238.jpg  \n",
            "  inflating: origa/images/images/235.jpg  \n",
            "  inflating: origa/images/images/234.jpg  \n",
            "  inflating: origa/images/images/270.jpg  \n",
            "  inflating: origa/images/images/255.jpg  \n",
            "  inflating: origa/images/images/297.jpg  \n",
            "  inflating: origa/images/images/219.jpg  \n",
            "  inflating: origa/images/images/228.jpg  \n",
            "  inflating: origa/images/images/211.jpg  \n",
            "  inflating: origa/images/images/284.jpg  \n",
            "  inflating: origa/images/images/239.jpg  \n",
            "  inflating: origa/images/images/213.jpg  \n",
            "  inflating: origa/images/images/231.jpg  \n",
            "  inflating: origa/images/images/195.jpg  \n",
            "  inflating: origa/images/images/179.jpg  \n",
            "  inflating: origa/images/images/157.jpg  \n",
            "  inflating: origa/images/images/180.jpg  \n",
            "  inflating: origa/images/images/184.jpg  \n",
            "  inflating: origa/images/images/187.jpg  \n",
            "  inflating: origa/images/images/155.jpg  \n",
            "  inflating: origa/images/images/194.jpg  \n",
            "  inflating: origa/images/images/122.jpg  \n",
            "  inflating: origa/images/images/221.jpg  \n",
            "  inflating: origa/images/images/181.jpg  \n",
            "  inflating: origa/images/images/190.jpg  \n",
            "  inflating: origa/images/images/167.jpg  \n",
            "  inflating: origa/images/images/121.jpg  \n",
            "  inflating: origa/images/images/120.jpg  \n",
            "  inflating: origa/images/images/142.jpg  \n",
            "  inflating: origa/images/images/164.jpg  \n",
            "  inflating: origa/images/images/156.jpg  \n",
            "  inflating: origa/images/images/166.jpg  \n",
            "  inflating: origa/images/images/165.jpg  \n",
            "  inflating: origa/images/images/197.jpg  \n",
            "  inflating: origa/images/images/182.jpg  \n",
            "  inflating: origa/images/images/208.jpg  \n",
            "  inflating: origa/images/images/192.jpg  \n",
            "  inflating: origa/images/images/176.jpg  \n",
            "  inflating: origa/images/images/144.jpg  \n",
            "  inflating: origa/images/images/186.jpg  \n",
            "  inflating: origa/images/images/154.jpg  \n",
            "  inflating: origa/images/images/145.jpg  \n",
            "  inflating: origa/images/images/130.jpg  \n",
            "  inflating: origa/manual marking/manual marking/370.mat  \n",
            "  inflating: origa/manual marking/manual marking/355.mat  \n",
            "  inflating: origa/manual marking/manual marking/334.mat  \n",
            "  inflating: origa/manual marking/manual marking/342.mat  \n",
            "  inflating: origa/manual marking/manual marking/367.mat  \n",
            "  inflating: origa/manual marking/manual marking/358.mat  \n",
            "  inflating: origa/manual marking/manual marking/366.mat  \n",
            "  inflating: origa/manual marking/manual marking/336.mat  \n",
            "  inflating: origa/manual marking/manual marking/365.mat  \n",
            "  inflating: origa/manual marking/manual marking/356.mat  \n",
            "  inflating: origa/manual marking/manual marking/347.mat  \n",
            "  inflating: origa/manual marking/manual marking/345.mat  \n",
            "  inflating: origa/manual marking/manual marking/346.mat  \n",
            "  inflating: origa/manual marking/manual marking/350.mat  \n",
            "  inflating: origa/manual marking/manual marking/353.mat  \n",
            "  inflating: origa/images/images/245.jpg  \n",
            "  inflating: origa/manual marking/manual marking/373.mat  \n",
            "  inflating: origa/manual marking/manual marking/338.mat  \n",
            "  inflating: origa/manual marking/manual marking/351.mat  \n",
            "  inflating: origa/manual marking/manual marking/332.mat  \n",
            "  inflating: origa/manual marking/manual marking/362.mat  \n",
            "  inflating: origa/manual marking/manual marking/361.mat  \n",
            "  inflating: origa/manual marking/manual marking/330.mat  \n",
            "  inflating: origa/manual marking/manual marking/340.mat  \n",
            "  inflating: origa/manual marking/manual marking/331.mat  \n",
            "  inflating: origa/manual marking/manual marking/329.mat  \n",
            "  inflating: origa/manual marking/manual marking/348.mat  \n",
            "  inflating: origa/manual marking/manual marking/360.mat  \n",
            "  inflating: origa/manual marking/manual marking/352.mat  \n",
            "  inflating: origa/manual marking/manual marking/349.mat  \n",
            "  inflating: origa/manual marking/manual marking/363.mat  \n",
            "  inflating: origa/manual marking/manual marking/359.mat  \n",
            "  inflating: origa/manual marking/manual marking/328.mat  \n",
            "  inflating: origa/manual marking/manual marking/318.mat  \n",
            "  inflating: origa/manual marking/manual marking/333.mat  \n",
            "  inflating: origa/manual marking/manual marking/326.mat  \n",
            "  inflating: origa/manual marking/manual marking/357.mat  \n",
            "  inflating: origa/manual marking/manual marking/335.mat  \n",
            "  inflating: origa/manual marking/manual marking/339.mat  \n",
            "  inflating: origa/manual marking/manual marking/325.mat  \n",
            "  inflating: origa/manual marking/manual marking/324.mat  \n",
            "  inflating: origa/manual marking/manual marking/337.mat  \n",
            "  inflating: origa/manual marking/manual marking/364.mat  \n",
            "  inflating: origa/manual marking/manual marking/343.mat  \n",
            "  inflating: origa/manual marking/manual marking/312.mat  \n",
            "  inflating: origa/manual marking/manual marking/309.mat  \n",
            "  inflating: origa/manual marking/manual marking/306.mat  \n",
            "  inflating: origa/manual marking/manual marking/305.mat  \n",
            "  inflating: origa/manual marking/manual marking/308.mat  \n",
            "  inflating: origa/manual marking/manual marking/323.mat  \n",
            "  inflating: origa/manual marking/manual marking/313.mat  \n",
            "  inflating: origa/manual marking/manual marking/297.mat  \n",
            "  inflating: origa/manual marking/manual marking/354.mat  \n",
            "  inflating: origa/manual marking/manual marking/344.mat  \n",
            "  inflating: origa/manual marking/manual marking/310.mat  \n",
            "  inflating: origa/manual marking/manual marking/294.mat  \n",
            "  inflating: origa/manual marking/manual marking/319.mat  \n",
            "  inflating: origa/manual marking/manual marking/316.mat  \n",
            "  inflating: origa/manual marking/manual marking/293.mat  \n",
            "  inflating: origa/manual marking/manual marking/327.mat  \n",
            "  inflating: origa/manual marking/manual marking/299.mat  \n",
            "  inflating: origa/manual marking/manual marking/320.mat  \n",
            "  inflating: origa/manual marking/manual marking/303.mat  \n",
            "  inflating: origa/manual marking/manual marking/322.mat  \n",
            "  inflating: origa/manual marking/manual marking/282.mat  \n",
            "  inflating: origa/manual marking/manual marking/296.mat  \n",
            "  inflating: origa/manual marking/manual marking/301.mat  \n",
            "  inflating: origa/manual marking/manual marking/295.mat  \n",
            "  inflating: origa/manual marking/manual marking/321.mat  \n",
            "  inflating: origa/manual marking/manual marking/284.mat  \n",
            "  inflating: origa/manual marking/manual marking/283.mat  \n",
            "  inflating: origa/manual marking/manual marking/298.mat  \n",
            "  inflating: origa/manual marking/manual marking/287.mat  \n",
            "  inflating: origa/manual marking/manual marking/281.mat  \n",
            "  inflating: origa/manual marking/manual marking/285.mat  \n",
            "  inflating: origa/manual marking/manual marking/288.mat  \n",
            "  inflating: origa/manual marking/manual marking/302.mat  \n",
            "  inflating: origa/manual marking/manual marking/317.mat  \n",
            "  inflating: origa/manual marking/manual marking/307.mat  \n",
            "  inflating: origa/manual marking/manual marking/270.mat  \n",
            "  inflating: origa/manual marking/manual marking/272.mat  \n",
            "  inflating: origa/manual marking/manual marking/315.mat  \n",
            "  inflating: origa/manual marking/manual marking/314.mat  \n",
            "  inflating: origa/manual marking/manual marking/291.mat  \n",
            "  inflating: origa/manual marking/manual marking/304.mat  \n",
            "  inflating: origa/manual marking/manual marking/280.mat  \n",
            "  inflating: origa/manual marking/manual marking/271.mat  \n",
            "  inflating: origa/manual marking/manual marking/263.mat  \n",
            "  inflating: origa/manual marking/manual marking/292.mat  \n",
            "  inflating: origa/manual marking/manual marking/311.mat  \n",
            "  inflating: origa/manual marking/manual marking/262.mat  \n",
            "  inflating: origa/manual marking/manual marking/286.mat  \n",
            "  inflating: origa/manual marking/manual marking/273.mat  \n",
            "  inflating: origa/manual marking/manual marking/269.mat  \n",
            "  inflating: origa/manual marking/manual marking/275.mat  \n",
            "  inflating: origa/manual marking/manual marking/274.mat  \n",
            "  inflating: origa/manual marking/manual marking/248.mat  \n",
            "  inflating: origa/manual marking/manual marking/264.mat  \n",
            "  inflating: origa/manual marking/manual marking/260.mat  \n",
            "  inflating: origa/manual marking/manual marking/252.mat  \n",
            "  inflating: origa/manual marking/manual marking/268.mat  \n",
            "  inflating: origa/manual marking/manual marking/267.mat  \n",
            "  inflating: origa/manual marking/manual marking/251.mat  \n",
            "  inflating: origa/manual marking/manual marking/289.mat  \n",
            "  inflating: origa/manual marking/manual marking/290.mat  \n",
            "  inflating: origa/manual marking/manual marking/278.mat  \n",
            "  inflating: origa/manual marking/manual marking/300.mat  \n",
            "  inflating: origa/manual marking/manual marking/279.mat  \n",
            "  inflating: origa/manual marking/manual marking/258.mat  \n",
            "  inflating: origa/manual marking/manual marking/265.mat  \n",
            "  inflating: origa/manual marking/manual marking/250.mat  \n",
            "  inflating: origa/manual marking/manual marking/254.mat  \n",
            "  inflating: origa/manual marking/manual marking/257.mat  \n",
            "  inflating: origa/manual marking/manual marking/253.mat  \n",
            "  inflating: origa/manual marking/manual marking/241.mat  \n",
            "  inflating: origa/manual marking/manual marking/277.mat  \n",
            "  inflating: origa/manual marking/manual marking/261.mat  \n",
            "  inflating: origa/manual marking/manual marking/246.mat  \n",
            "  inflating: origa/manual marking/manual marking/222.mat  \n",
            "  inflating: origa/manual marking/manual marking/259.mat  \n",
            "  inflating: origa/manual marking/manual marking/228.mat  \n",
            "  inflating: origa/manual marking/manual marking/236.mat  \n",
            "  inflating: origa/manual marking/manual marking/247.mat  \n",
            "  inflating: origa/manual marking/manual marking/256.mat  \n",
            "  inflating: origa/manual marking/manual marking/237.mat  \n",
            "  inflating: origa/manual marking/manual marking/217.mat  \n",
            "  inflating: origa/manual marking/manual marking/223.mat  \n",
            "  inflating: origa/manual marking/manual marking/255.mat  \n",
            "  inflating: origa/manual marking/manual marking/249.mat  \n",
            "  inflating: origa/manual marking/manual marking/219.mat  \n",
            "  inflating: origa/manual marking/manual marking/240.mat  \n",
            "  inflating: origa/manual marking/manual marking/234.mat  \n",
            "  inflating: origa/manual marking/manual marking/229.mat  \n",
            "  inflating: origa/manual marking/manual marking/218.mat  \n",
            "  inflating: origa/manual marking/manual marking/216.mat  \n",
            "  inflating: origa/manual marking/manual marking/238.mat  \n",
            "  inflating: origa/manual marking/manual marking/206.mat  \n",
            "  inflating: origa/manual marking/manual marking/207.mat  \n",
            "  inflating: origa/manual marking/manual marking/225.mat  \n",
            "  inflating: origa/manual marking/manual marking/197.mat  \n",
            "  inflating: origa/manual marking/manual marking/231.mat  \n",
            "  inflating: origa/manual marking/manual marking/221.mat  \n",
            "  inflating: origa/manual marking/manual marking/230.mat  \n",
            "  inflating: origa/manual marking/manual marking/242.mat  \n",
            "  inflating: origa/manual marking/manual marking/224.mat  \n",
            "  inflating: origa/manual marking/manual marking/239.mat  \n",
            "  inflating: origa/manual marking/manual marking/227.mat  \n",
            "  inflating: origa/manual marking/manual marking/233.mat  \n",
            "  inflating: origa/manual marking/manual marking/245.mat  \n",
            "  inflating: origa/manual marking/manual marking/266.mat  \n",
            "  inflating: origa/manual marking/manual marking/244.mat  \n",
            "  inflating: origa/manual marking/manual marking/195.mat  \n",
            "  inflating: origa/manual marking/manual marking/235.mat  \n",
            "  inflating: origa/manual marking/manual marking/196.mat  \n",
            "  inflating: origa/manual marking/manual marking/200.mat  \n",
            "  inflating: origa/manual marking/manual marking/190.mat  \n",
            "  inflating: origa/manual marking/manual marking/194.mat  \n",
            "  inflating: origa/manual marking/manual marking/179.mat  \n",
            "  inflating: origa/manual marking/manual marking/208.mat  \n",
            "  inflating: origa/manual marking/manual marking/198.mat  \n",
            "  inflating: origa/manual marking/manual marking/177.mat  \n",
            "  inflating: origa/manual marking/manual marking/181.mat  \n",
            "  inflating: origa/manual marking/manual marking/202.mat  \n",
            "  inflating: origa/manual marking/manual marking/213.mat  \n",
            "  inflating: origa/manual marking/manual marking/210.mat  \n",
            "  inflating: origa/manual marking/manual marking/215.mat  \n",
            "  inflating: origa/manual marking/manual marking/176.mat  \n",
            "  inflating: origa/manual marking/manual marking/203.mat  \n",
            "  inflating: origa/manual marking/manual marking/171.mat  \n",
            "  inflating: origa/manual marking/manual marking/211.mat  \n",
            "  inflating: origa/manual marking/manual marking/169.mat  \n",
            "  inflating: origa/manual marking/manual marking/205.mat  \n",
            "  inflating: origa/manual marking/manual marking/165.mat  \n",
            "  inflating: origa/manual marking/manual marking/164.mat  \n",
            "  inflating: origa/manual marking/manual marking/180.mat  \n",
            "  inflating: origa/manual marking/manual marking/184.mat  \n",
            "  inflating: origa/manual marking/manual marking/187.mat  \n",
            "  inflating: origa/manual marking/manual marking/182.mat  \n",
            "  inflating: origa/manual marking/manual marking/189.mat  \n",
            "  inflating: origa/manual marking/manual marking/156.mat  \n",
            "  inflating: origa/manual marking/manual marking/201.mat  \n",
            "  inflating: origa/manual marking/manual marking/170.mat  \n",
            "  inflating: origa/manual marking/manual marking/185.mat  \n",
            "  inflating: origa/manual marking/manual marking/172.mat  \n",
            "  inflating: origa/manual marking/manual marking/143.mat  \n",
            "  inflating: origa/manual marking/manual marking/140.mat  \n",
            "  inflating: origa/manual marking/manual marking/159.mat  \n",
            "  inflating: origa/manual marking/manual marking/192.mat  \n",
            "  inflating: origa/manual marking/manual marking/186.mat  \n",
            "  inflating: origa/manual marking/manual marking/162.mat  \n",
            "  inflating: origa/manual marking/manual marking/191.mat  \n",
            "  inflating: origa/manual marking/manual marking/154.mat  \n",
            "  inflating: origa/manual marking/manual marking/175.mat  \n",
            "  inflating: origa/manual marking/manual marking/150.mat  \n",
            "  inflating: origa/manual marking/manual marking/160.mat  \n",
            "  inflating: origa/manual marking/manual marking/149.mat  \n",
            "  inflating: origa/manual marking/manual marking/167.mat  \n",
            "  inflating: origa/manual marking/manual marking/138.mat  \n",
            "  inflating: origa/manual marking/manual marking/139.mat  \n",
            "  inflating: origa/manual marking/manual marking/174.mat  \n",
            "  inflating: origa/manual marking/manual marking/152.mat  \n",
            "  inflating: origa/manual marking/manual marking/151.mat  \n",
            "  inflating: origa/manual marking/manual marking/155.mat  \n",
            "  inflating: origa/manual marking/manual marking/121.mat  \n",
            "  inflating: origa/manual marking/manual marking/127.mat  \n",
            "  inflating: origa/manual marking/manual marking/135.mat  \n",
            "  inflating: origa/manual marking/manual marking/166.mat  \n",
            "  inflating: origa/manual marking/manual marking/157.mat  \n",
            "  inflating: origa/manual marking/manual marking/131.mat  \n",
            "  inflating: origa/manual marking/manual marking/148.mat  \n",
            "  inflating: origa/manual marking/manual marking/120.mat  \n",
            "  inflating: origa/manual marking/manual marking/134.mat  \n",
            "  inflating: origa/manual marking/manual marking/146.mat  \n",
            "  inflating: origa/manual marking/manual marking/126.mat  \n",
            "  inflating: origa/manual marking/manual marking/122.mat  \n",
            "  inflating: origa/manual marking/manual marking/112.mat  \n",
            "  inflating: origa/manual marking/manual marking/116.mat  \n",
            "  inflating: origa/manual marking/manual marking/108.mat  \n",
            "  inflating: origa/manual marking/manual marking/144.mat  \n",
            "  inflating: origa/manual marking/manual marking/105.mat  \n",
            "  inflating: origa/manual marking/manual marking/101.mat  \n",
            "  inflating: origa/manual marking/manual marking/125.mat  \n",
            "  inflating: origa/manual marking/manual marking/119.mat  \n",
            "  inflating: origa/manual marking/manual marking/161.mat  \n",
            "  inflating: origa/manual marking/manual marking/124.mat  \n",
            "  inflating: origa/manual marking/manual marking/099.mat  \n",
            "  inflating: origa/manual marking/manual marking/092.mat  \n",
            "  inflating: origa/manual marking/manual marking/096.mat  \n",
            "  inflating: origa/manual marking/manual marking/142.mat  \n",
            "  inflating: origa/manual marking/manual marking/137.mat  \n",
            "  inflating: origa/manual marking/manual marking/145.mat  \n",
            "  inflating: origa/manual marking/manual marking/129.mat  \n",
            "  inflating: origa/manual marking/manual marking/104.mat  \n",
            "  inflating: origa/manual marking/manual marking/130.mat  \n",
            "  inflating: origa/manual marking/manual marking/098.mat  \n",
            "  inflating: origa/manual marking/manual marking/132.mat  \n",
            "  inflating: origa/manual marking/manual marking/100.mat  \n",
            "  inflating: origa/manual marking/manual marking/115.mat  \n",
            "  inflating: origa/manual marking/manual marking/114.mat  \n",
            "  inflating: origa/images/images/119.jpg  \n",
            "  inflating: origa/manual marking/manual marking/090.mat  \n",
            "  inflating: origa/manual marking/manual marking/109.mat  \n",
            "  inflating: origa/images/images/112.jpg  \n",
            "  inflating: origa/manual marking/manual marking/103.mat  \n",
            "  inflating: origa/manual marking/manual marking/113.mat  \n",
            "  inflating: origa/manual marking/manual marking/118.mat  \n",
            "  inflating: origa/images/images/107.jpg  \n",
            "  inflating: origa/images/images/110.jpg  \n",
            "  inflating: origa/images/images/071.jpg  \n",
            "  inflating: origa/images/images/109.jpg  \n",
            "  inflating: origa/images/images/081.jpg  \n",
            "  inflating: origa/images/images/094.jpg  \n",
            "  inflating: origa/images/images/113.jpg  \n",
            "  inflating: origa/images/images/100.jpg  \n",
            "  inflating: origa/images/images/068.jpg  \n",
            "  inflating: origa/images/images/076.jpg  \n",
            "  inflating: origa/images/images/059.jpg  \n",
            "  inflating: origa/images/images/046.jpg  \n",
            "  inflating: origa/images/images/042.jpg  \n",
            "  inflating: origa/images/images/066.jpg  \n",
            "  inflating: origa/images/images/025.jpg  \n",
            "  inflating: origa/manual marking/manual marking/110.mat  \n",
            "  inflating: origa/images/images/118.jpg  \n",
            "  inflating: origa/manual marking/manual marking/107.mat  \n",
            "  inflating: origa/images/images/108.jpg  \n",
            "  inflating: origa/images/images/060.jpg  \n",
            "  inflating: origa/images/images/067.jpg  \n",
            "  inflating: origa/images/images/041.jpg  \n",
            "  inflating: origa/images/images/101.jpg  \n",
            "  inflating: origa/images/images/052.jpg  \n",
            "  inflating: origa/images/images/088.jpg  \n",
            "  inflating: origa/images/images/045.jpg  \n",
            "  inflating: origa/images/images/035.jpg  \n",
            "  inflating: origa/images/images/093.jpg  \n",
            "  inflating: origa/images/images/051.jpg  \n",
            "  inflating: origa/images/images/034.jpg  \n",
            "  inflating: origa/images/images/018.jpg  \n",
            "  inflating: origa/images/images/647.jpg  \n",
            "  inflating: origa/images/images/619.jpg  \n",
            "  inflating: origa/images/images/072.jpg  \n",
            "  inflating: origa/images/images/006.jpg  \n",
            "  inflating: origa/images/images/646.jpg  \n",
            "  inflating: origa/images/images/634.jpg  \n",
            "  inflating: origa/images/images/031.jpg  \n",
            "  inflating: origa/images/images/009.jpg  \n",
            "  inflating: origa/images/images/632.jpg  \n",
            "  inflating: origa/images/images/008.jpg  \n",
            "  inflating: origa/images/images/010.jpg  \n",
            "  inflating: origa/images/images/618.jpg  \n",
            "  inflating: origa/images/images/633.jpg  \n",
            "  inflating: origa/images/images/592.jpg  \n",
            "  inflating: origa/images/images/089.jpg  \n",
            "  inflating: origa/images/images/013.jpg  \n",
            "  inflating: origa/images/images/604.jpg  \n",
            "  inflating: origa/images/images/593.jpg  \n",
            "  inflating: origa/images/images/589.jpg  \n",
            "  inflating: origa/images/images/587.jpg  \n",
            "  inflating: origa/images/images/648.jpg  \n",
            "  inflating: origa/images/images/012.jpg  \n",
            "  inflating: origa/images/images/574.jpg  \n",
            "  inflating: origa/images/images/608.jpg  \n",
            "  inflating: origa/images/images/578.jpg  \n",
            "  inflating: origa/images/images/561.jpg  \n",
            "  inflating: origa/images/images/050.jpg  \n",
            "  inflating: origa/images/images/588.jpg  \n",
            "  inflating: origa/images/images/607.jpg  \n",
            "  inflating: origa/images/images/552.jpg  \n",
            "  inflating: origa/images/images/594.jpg  \n",
            "  inflating: origa/images/images/556.jpg  \n",
            "  inflating: origa/images/images/612.jpg  \n",
            "  inflating: origa/images/images/562.jpg  \n",
            "  inflating: origa/images/images/565.jpg  \n",
            "  inflating: origa/images/images/623.jpg  \n",
            "  inflating: origa/images/images/611.jpg  \n",
            "  inflating: origa/images/images/615.jpg  \n",
            "  inflating: origa/images/images/566.jpg  \n",
            "  inflating: origa/images/images/553.jpg  \n",
            "  inflating: origa/images/images/549.jpg  \n",
            "  inflating: origa/images/images/550.jpg  \n",
            "  inflating: origa/images/images/537.jpg  \n",
            "  inflating: origa/images/images/534.jpg  \n",
            "  inflating: origa/images/images/573.jpg  \n",
            "  inflating: origa/images/images/548.jpg  \n",
            "  inflating: origa/images/images/583.jpg  \n",
            "  inflating: origa/images/images/515.jpg  \n",
            "  inflating: origa/images/images/538.jpg  \n",
            "  inflating: origa/images/images/547.jpg  \n",
            "  inflating: origa/images/images/563.jpg  \n",
            "  inflating: origa/images/images/526.jpg  \n",
            "  inflating: origa/images/images/541.jpg  \n",
            "  inflating: origa/images/images/542.jpg  \n",
            "  inflating: origa/images/images/494.jpg  \n",
            "  inflating: origa/images/images/491.jpg  \n",
            "  inflating: origa/images/images/469.jpg  \n",
            "  inflating: origa/images/images/616.jpg  \n",
            "  inflating: origa/images/images/470.jpg  \n",
            "  inflating: origa/images/images/481.jpg  \n",
            "  inflating: origa/images/images/492.jpg  \n",
            "  inflating: origa/images/images/509.jpg  \n",
            "  inflating: origa/images/images/546.jpg  \n",
            "  inflating: origa/images/images/462.jpg  \n",
            "  inflating: origa/images/images/508.jpg  \n",
            "  inflating: origa/images/images/489.jpg  \n",
            "  inflating: origa/images/images/455.jpg  \n",
            "  inflating: origa/images/images/564.jpg  \n",
            "  inflating: origa/images/images/490.jpg  \n",
            "  inflating: origa/images/images/437.jpg  \n",
            "  inflating: origa/images/images/472.jpg  \n",
            "  inflating: origa/images/images/533.jpg  \n",
            "  inflating: origa/images/images/525.jpg  \n",
            "  inflating: origa/images/images/474.jpg  \n",
            "  inflating: origa/images/images/464.jpg  \n",
            "  inflating: origa/images/images/463.jpg  \n",
            "  inflating: origa/images/images/450.jpg  \n",
            "  inflating: origa/images/images/476.jpg  \n",
            "  inflating: origa/images/images/433.jpg  \n",
            "  inflating: origa/images/images/454.jpg  \n",
            "  inflating: origa/images/images/473.jpg  \n",
            "  inflating: origa/images/images/516.jpg  \n",
            "  inflating: origa/images/images/493.jpg  \n",
            "  inflating: origa/images/images/453.jpg  \n",
            "  inflating: origa/images/images/523.jpg  \n",
            "  inflating: origa/images/images/483.jpg  \n",
            "  inflating: origa/images/images/434.jpg  \n",
            "  inflating: origa/images/images/456.jpg  \n",
            "  inflating: origa/images/images/425.jpg  \n",
            "  inflating: origa/images/images/427.jpg  \n",
            "  inflating: origa/images/images/422.jpg  \n",
            "  inflating: origa/images/images/436.jpg  \n",
            "  inflating: origa/images/images/418.jpg  \n",
            "  inflating: origa/images/images/430.jpg  \n",
            "  inflating: origa/images/images/431.jpg  \n",
            "  inflating: origa/images/images/432.jpg  \n",
            "  inflating: origa/images/images/414.jpg  \n",
            "  inflating: origa/images/images/452.jpg  \n",
            "  inflating: origa/images/images/419.jpg  \n",
            "  inflating: origa/images/images/451.jpg  \n",
            "  inflating: origa/images/images/395.jpg  \n",
            "  inflating: origa/images/images/467.jpg  \n",
            "  inflating: origa/images/images/397.jpg  \n",
            "  inflating: origa/images/images/413.jpg  \n",
            "  inflating: origa/images/images/405.jpg  \n",
            "  inflating: origa/images/images/407.jpg  \n",
            "  inflating: origa/images/images/391.jpg  \n",
            "  inflating: origa/images/images/412.jpg  \n",
            "  inflating: origa/images/images/385.jpg  \n",
            "  inflating: origa/images/images/386.jpg  \n",
            "  inflating: origa/images/images/417.jpg  \n",
            "  inflating: origa/images/images/394.jpg  \n",
            "  inflating: origa/images/images/364.jpg  \n",
            "  inflating: origa/images/images/404.jpg  \n",
            "  inflating: origa/images/images/396.jpg  \n",
            "  inflating: origa/images/images/435.jpg  \n",
            "  inflating: origa/images/images/345.jpg  \n",
            "  inflating: origa/images/images/361.jpg  \n",
            "  inflating: origa/images/images/148.jpg  \n",
            "  inflating: origa/images/images/365.jpg  \n",
            "  inflating: origa/images/images/363.jpg  \n",
            "  inflating: origa/images/images/359.jpg  \n",
            "  inflating: origa/images/images/426.jpg  \n",
            "  inflating: origa/images/images/415.jpg  \n",
            "  inflating: origa/images/images/369.jpg  \n",
            "  inflating: origa/images/images/423.jpg  \n",
            "  inflating: origa/images/images/371.jpg  \n",
            "  inflating: origa/images/images/360.jpg  \n",
            "  inflating: origa/images/images/140.jpg  \n",
            "  inflating: origa/images/images/353.jpg  \n",
            "  inflating: origa/images/images/368.jpg  \n",
            "  inflating: origa/images/images/424.jpg  \n",
            "  inflating: origa/images/images/416.jpg  \n",
            "  inflating: origa/images/images/370.jpg  \n",
            "  inflating: origa/images/images/351.jpg  \n",
            "  inflating: origa/images/images/326.jpg  \n",
            "  inflating: origa/images/images/137.jpg  \n",
            "  inflating: origa/images/images/356.jpg  \n",
            "  inflating: origa/images/images/350.jpg  \n",
            "  inflating: origa/images/images/134.jpg  \n",
            "  inflating: origa/images/images/139.jpg  \n",
            "  inflating: origa/images/images/135.jpg  \n",
            "  inflating: origa/images/images/348.jpg  \n",
            "  inflating: origa/images/images/349.jpg  \n",
            "  inflating: origa/images/images/138.jpg  \n",
            "  inflating: origa/images/images/343.jpg  \n",
            "  inflating: origa/images/images/317.jpg  \n",
            "  inflating: origa/images/images/354.jpg  \n",
            "  inflating: origa/images/images/362.jpg  \n",
            "  inflating: origa/images/images/325.jpg  \n",
            "  inflating: origa/images/images/321.jpg  \n",
            "  inflating: origa/images/images/131.jpg  \n",
            "  inflating: origa/images/images/129.jpg  \n",
            "  inflating: origa/images/images/143.jpg  \n",
            "  inflating: origa/images/images/307.jpg  \n",
            "  inflating: origa/images/images/310.jpg  \n",
            "  inflating: origa/images/images/355.jpg  \n",
            "  inflating: origa/images/images/146.jpg  \n",
            "  inflating: origa/images/images/318.jpg  \n",
            "  inflating: origa/images/images/116.jpg  \n",
            "  inflating: origa/images/images/125.jpg  \n",
            "  inflating: origa/images/images/104.jpg  \n",
            "  inflating: origa/images/images/309.jpg  \n",
            "  inflating: origa/images/images/304.jpg  \n",
            "  inflating: origa/images/images/114.jpg  \n",
            "  inflating: origa/images/images/115.jpg  \n",
            "  inflating: origa/images/images/096.jpg  \n",
            "  inflating: origa/images/images/305.jpg  \n",
            "  inflating: origa/images/images/105.jpg  \n",
            "  inflating: origa/images/images/092.jpg  \n",
            "  inflating: origa/images/images/099.jpg  \n",
            "  inflating: origa/images/images/290.jpg  \n",
            "  inflating: origa/images/images/330.jpg  \n",
            "  inflating: origa/images/images/331.jpg  \n",
            "  inflating: origa/images/images/308.jpg  \n",
            "  inflating: origa/images/images/132.jpg  \n",
            "  inflating: origa/images/images/126.jpg  \n",
            "  inflating: origa/images/images/344.jpg  \n",
            "  inflating: origa/images/images/292.jpg  \n",
            "  inflating: origa/images/images/127.jpg  \n",
            "  inflating: origa/images/images/299.jpg  \n",
            "  inflating: origa/images/images/124.jpg  \n",
            "  inflating: origa/images/images/291.jpg  \n",
            "  inflating: origa/images/images/083.jpg  \n",
            "  inflating: origa/images/images/322.jpg  \n",
            "  inflating: origa/images/images/095.jpg  \n",
            "  inflating: origa/images/images/294.jpg  \n",
            "  inflating: origa/images/images/274.jpg  \n",
            "  inflating: origa/images/images/079.jpg  \n",
            "  inflating: origa/images/images/306.jpg  \n",
            "  inflating: origa/images/images/103.jpg  \n",
            "  inflating: origa/images/images/298.jpg  \n",
            "  inflating: origa/images/images/080.jpg  \n",
            "  inflating: origa/images/images/293.jpg  \n",
            "  inflating: origa/images/images/287.jpg  \n",
            "  inflating: origa/images/images/279.jpg  \n",
            "  inflating: origa/images/images/288.jpg  \n",
            "  inflating: origa/images/images/084.jpg  \n",
            "  inflating: origa/images/images/078.jpg  \n",
            "  inflating: origa/images/images/266.jpg  \n",
            "  inflating: origa/images/images/273.jpg  \n",
            "  inflating: origa/images/images/289.jpg  \n",
            "  inflating: origa/images/images/275.jpg  \n",
            "  inflating: origa/images/images/064.jpg  \n",
            "  inflating: origa/images/images/098.jpg  \n",
            "  inflating: origa/images/images/259.jpg  \n",
            "  inflating: origa/images/images/070.jpg  \n",
            "  inflating: origa/images/images/082.jpg  \n",
            "  inflating: origa/images/images/087.jpg  \n",
            "  inflating: origa/images/images/263.jpg  \n",
            "  inflating: origa/images/images/264.jpg  \n",
            "  inflating: origa/images/images/074.jpg  \n",
            "  inflating: origa/images/images/280.jpg  \n",
            "  inflating: origa/images/images/260.jpg  \n",
            "  inflating: origa/images/images/085.jpg  \n",
            "  inflating: origa/manual marking/manual marking/094.mat  \n",
            "  inflating: origa/images/images/056.jpg  \n",
            "  inflating: origa/manual marking/manual marking/089.mat  \n",
            "  inflating: origa/images/images/090.jpg  \n",
            "  inflating: origa/images/images/247.jpg  \n",
            "  inflating: origa/images/images/062.jpg  \n",
            "  inflating: origa/images/images/265.jpg  \n",
            "  inflating: origa/images/images/065.jpg  \n",
            "  inflating: origa/images/images/248.jpg  \n",
            "  inflating: origa/images/images/037.jpg  \n",
            "  inflating: origa/images/images/032.jpg  \n",
            "  inflating: origa/images/images/077.jpg  \n",
            "  inflating: origa/images/images/240.jpg  \n",
            "  inflating: origa/images/images/054.jpg  \n",
            "  inflating: origa/images/images/057.jpg  \n",
            "  inflating: origa/manual marking/manual marking/095.mat  \n",
            "  inflating: origa/images/images/061.jpg  \n",
            "  inflating: origa/images/images/227.jpg  \n",
            "  inflating: origa/images/images/250.jpg  \n",
            "  inflating: origa/images/images/249.jpg  \n",
            "  inflating: origa/manual marking/manual marking/093.mat  \n",
            "  inflating: origa/images/images/073.jpg  \n",
            "  inflating: origa/images/images/030.jpg  \n",
            "  inflating: origa/images/images/207.jpg  \n",
            "  inflating: origa/images/images/047.jpg  \n",
            "  inflating: origa/images/images/055.jpg  \n",
            "  inflating: origa/manual marking/manual marking/088.mat  \n",
            "  inflating: origa/images/images/029.jpg  \n",
            "  inflating: origa/images/images/039.jpg  \n",
            "  inflating: origa/images/images/210.jpg  \n",
            "  inflating: origa/images/images/049.jpg  \n",
            "  inflating: origa/images/images/021.jpg  \n",
            "  inflating: origa/manual marking/manual marking/080.mat  \n",
            "  inflating: origa/images/images/206.jpg  \n",
            "  inflating: origa/images/images/225.jpg  \n",
            "  inflating: origa/images/images/202.jpg  \n",
            "  inflating: origa/images/images/036.jpg  \n",
            "  inflating: origa/images/images/223.jpg  \n",
            "  inflating: origa/images/images/022.jpg  \n",
            "  inflating: origa/images/images/027.jpg  \n",
            "  inflating: origa/images/images/200.jpg  \n",
            "  inflating: origa/images/images/216.jpg  \n",
            "  inflating: origa/images/images/044.jpg  \n",
            "  inflating: origa/images/images/026.jpg  \n",
            "  inflating: origa/images/images/205.jpg  \n",
            "  inflating: origa/images/images/201.jpg  \n",
            "  inflating: origa/images/images/028.jpg  \n",
            "  inflating: origa/images/images/224.jpg  \n",
            "  inflating: origa/images/images/019.jpg  \n",
            "  inflating: origa/images/images/177.jpg  \n",
            "  inflating: origa/images/images/203.jpg  \n",
            "  inflating: origa/images/images/040.jpg  \n",
            "  inflating: origa/images/images/222.jpg  \n",
            "  inflating: origa/manual marking/manual marking/081.mat  \n",
            "  inflating: origa/manual marking/manual marking/087.mat  \n",
            "  inflating: origa/manual marking/manual marking/083.mat  \n",
            "  inflating: origa/images/images/024.jpg  \n",
            "  inflating: origa/images/images/175.jpg  \n",
            "  inflating: origa/images/images/215.jpg  \n",
            "  inflating: origa/images/images/016.jpg  \n",
            "  inflating: origa/images/images/217.jpg  \n",
            "  inflating: origa/images/images/023.jpg  \n",
            "  inflating: origa/images/images/196.jpg  \n",
            "  inflating: origa/manual marking/manual marking/085.mat  \n",
            "  inflating: origa/images/images/017.jpg  \n",
            "  inflating: origa/images/images/198.jpg  \n",
            "  inflating: origa/manual marking/manual marking/082.mat  \n",
            "  inflating: origa/images/images/020.jpg  \n",
            "  inflating: origa/images/images/007.jpg  \n",
            "  inflating: origa/manual marking/manual marking/077.mat  \n",
            "  inflating: origa/images/images/189.jpg  \n",
            "  inflating: origa/images/images/011.jpg  \n",
            "  inflating: origa/images/images/185.jpg  \n",
            "  inflating: origa/images/images/170.jpg  \n",
            "  inflating: origa/manual marking/manual marking/066.mat  \n",
            "  inflating: origa/manual marking/manual marking/084.mat  \n",
            "  inflating: origa/images/images/015.jpg  \n",
            "  inflating: origa/images/images/172.jpg  \n",
            "  inflating: origa/manual marking/manual marking/071.mat  \n",
            "  inflating: origa/images/images/191.jpg  \n",
            "  inflating: origa/images/images/005.jpg  \n",
            "  inflating: origa/images/images/149.jpg  \n",
            "  inflating: origa/manual marking/manual marking/078.mat  \n",
            "  inflating: origa/manual marking/manual marking/073.mat  \n",
            "  inflating: origa/manual marking/manual marking/057.mat  \n",
            "  inflating: origa/images/images/161.jpg  \n",
            "  inflating: origa/images/images/169.jpg  \n",
            "  inflating: origa/images/images/150.jpg  \n",
            "  inflating: origa/manual marking/manual marking/060.mat  \n",
            "  inflating: origa/images/images/174.jpg  \n",
            "  inflating: origa/images/images/171.jpg  \n",
            "  inflating: origa/manual marking/manual marking/072.mat  \n",
            "  inflating: origa/images/images/152.jpg  \n",
            "  inflating: origa/manual marking/manual marking/076.mat  \n",
            "  inflating: origa/manual marking/manual marking/062.mat  \n",
            "  inflating: origa/images/images/162.jpg  \n",
            "  inflating: origa/manual marking/manual marking/068.mat  \n",
            "  inflating: origa/manual marking/manual marking/079.mat  \n",
            "  inflating: origa/manual marking/manual marking/070.mat  \n",
            "  inflating: origa/manual marking/manual marking/064.mat  \n",
            "  inflating: origa/manual marking/manual marking/074.mat  \n",
            "  inflating: origa/manual marking/manual marking/046.mat  \n",
            "  inflating: origa/images/images/159.jpg  \n",
            "  inflating: origa/manual marking/manual marking/067.mat  \n",
            "  inflating: origa/images/images/160.jpg  \n",
            "  inflating: origa/manual marking/manual marking/054.mat  \n",
            "  inflating: origa/images/images/002.jpg  \n",
            "  inflating: origa/images/images/151.jpg  \n",
            "  inflating: origa/images/images/004.jpg  \n",
            "  inflating: origa/manual marking/manual marking/044.mat  \n",
            "  inflating: origa/manual marking/manual marking/059.mat  \n",
            "  inflating: origa/manual marking/manual marking/061.mat  \n",
            "  inflating: origa/manual marking/manual marking/049.mat  \n",
            "  inflating: origa/manual marking/manual marking/042.mat  \n",
            "  inflating: origa/manual marking/manual marking/050.mat  \n",
            "  inflating: origa/manual marking/manual marking/039.mat  \n",
            "  inflating: origa/manual marking/manual marking/040.mat  \n",
            "  inflating: origa/images/images/003.jpg  \n",
            "  inflating: origa/manual marking/manual marking/056.mat  \n",
            "  inflating: origa/manual marking/manual marking/024.mat  \n",
            "  inflating: origa/manual marking/manual marking/065.mat  \n",
            "  inflating: origa/manual marking/manual marking/031.mat  \n",
            "  inflating: origa/manual marking/manual marking/051.mat  \n",
            "  inflating: origa/manual marking/manual marking/025.mat  \n",
            "  inflating: origa/manual marking/manual marking/028.mat  \n",
            "  inflating: origa/manual marking/manual marking/026.mat  \n",
            "  inflating: origa/manual marking/manual marking/029.mat  \n",
            "  inflating: origa/manual marking/manual marking/027.mat  \n",
            "  inflating: origa/manual marking/manual marking/035.mat  \n",
            "  inflating: origa/manual marking/manual marking/015.mat  \n",
            "  inflating: origa/manual marking/manual marking/018.mat  \n",
            "  inflating: origa/manual marking/manual marking/009.mat  \n",
            "  inflating: origa/manual marking/manual marking/008.mat  \n",
            "  inflating: origa/manual marking/manual marking/017.mat  \n",
            "  inflating: origa/manual marking/manual marking/032.mat  \n",
            "  inflating: origa/manual marking/manual marking/047.mat  \n",
            "  inflating: origa/manual marking/manual marking/012.mat  \n",
            "  inflating: origa/manual marking/manual marking/036.mat  \n",
            "  inflating: origa/manual marking/manual marking/055.mat  \n",
            "  inflating: origa/manual marking/manual marking/052.mat  \n",
            "  inflating: origa/manual marking/manual marking/001.mat  \n",
            "  inflating: origa/manual marking/manual marking/003.mat  \n",
            "  inflating: origa/manual marking/manual marking/004.mat  \n",
            "  inflating: origa/manual marking/manual marking/023.mat  \n",
            "  inflating: origa/manual marking/manual marking/002.mat  \n",
            "  inflating: origa/manual marking/manual marking/034.mat  \n",
            "  inflating: origa/manual marking/manual marking/011.mat  \n",
            "  inflating: origa/manual marking/manual marking/041.mat  \n",
            "  inflating: origa/manual marking/manual marking/037.mat  \n",
            "  inflating: origa/manual marking/manual marking/045.mat  \n",
            "  inflating: origa/manual marking/manual marking/013.mat  \n",
            "  inflating: origa/manual marking/manual marking/005.mat  \n",
            "  inflating: origa/manual marking/manual marking/010.mat  \n",
            "  inflating: origa/manual marking/manual marking/007.mat  \n",
            "  inflating: origa/manual marking/manual marking/030.mat  \n",
            "  inflating: origa/manual marking/manual marking/019.mat  \n",
            "  inflating: origa/manual marking/manual marking/021.mat  \n",
            "  inflating: origa/manual marking/manual marking/022.mat  \n",
            "  inflating: origa/manual marking/manual marking/020.mat  \n",
            "  inflating: origa/manual marking/manual marking/006.mat  \n",
            "  inflating: origa/manual marking/manual marking/016.mat  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "NbVGQmrBDVy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image=np.array(Image.open('/content/origa/images/images/001.jpg'))"
      ],
      "metadata": {
        "id": "FdHUjc8iDaDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=np.array(Image.open('/content/origa/images/images/001.jpg'))\n"
      ],
      "metadata": {
        "id": "22YCdH7bDcKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2MNXwptDjSA",
        "outputId": "dfc94316-adc0-4a9d-c74d-0e023f88b5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2048, 3072, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "data=scipy.io.loadmat('/content/origa/manual marking/manual marking/001.mat')"
      ],
      "metadata": {
        "id": "zr_0KGUUDjxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = cv2.resize(data['mask'],(256,256))"
      ],
      "metadata": {
        "id": "8dkKeGtyDnCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "s_rpnQ8MDqUq",
        "outputId": "b26c4eb2-8c3d-4b92-f837-8fe4f706a40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b6a1f29f0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images=[]\n",
        "labels=[]\n",
        "folders_I=os.listdir('/content/origa/images/images/')\n",
        "len(folders_I)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GiojdexDtMk",
        "outputId": "29ae13f9-8b95-4253-a80d-4c13d2f06a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "576"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folders_M = os.listdir('/content/origa/manual marking/manual marking/')\n",
        "len(folders_M)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ptsb-ACDvc0",
        "outputId": "a2f851d0-811f-48aa-b681-bfdbe49d8293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "576"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images=[]\n",
        "labels=[]\n",
        "\n",
        "for filename in sorted(folders_I):\n",
        "  image=np.array(Image.open('/content/origa/images/images/'+filename))\n",
        "  image=cv2.resize(image,(256,256))\n",
        "  images.append(image)"
      ],
      "metadata": {
        "id": "5IIV5PiaDxvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in sorted(folders_M):\n",
        "  data=scipy.io.loadmat('/content/origa/manual marking/manual marking/'+filename)\n",
        "  mask=cv2.resize(data['mask'],(256,256))\n",
        "  labels.append(mask)"
      ],
      "metadata": {
        "id": "dLcsZMfhDz7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images=np.array(images)\n",
        "labels=np.array(labels)"
      ],
      "metadata": {
        "id": "9ct2bkSJD2L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhBMOAodD4YK",
        "outputId": "a82f080d-cbe0-4fb9-96f5-cc35e1b113ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iehI2l-D6SP",
        "outputId": "ce22e0cf-eca5-4f2e-c758-8663056a1022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(576, 256, 256, 3)\n",
            "(576, 256, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBA2m7yPD8fN",
        "outputId": "eb6d5ad1-aafa-463a-cacc-187f9b2e72c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "labels1=to_categorical(labels,3)"
      ],
      "metadata": {
        "id": "1BTHBdO2D-iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels1)\n",
        "np.unique(labels1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NKodoi8EAka",
        "outputId": "43d071a1-fb76-4897-9ffc-c02b0d025c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels1[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plnvOtn1ECjf",
        "outputId": "39da0268-7981-4548-b9dc-18e01654eb6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "qFLp_whpEX2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(1,3)\n",
        "ax[0].imshow(labels1[0][:,:,0])\n",
        "ax[1].imshow(labels1[0][:,:,1])\n",
        "\n",
        "ax[2].imshow(labels1[0][:,:,2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "Gty12JlGEjMp",
        "outputId": "c3e1cedd-fae5-4d08-d047-21f4f01ede01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b69bfbaf820>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optical_labels = labels1[:, :, :, 1:]\n",
        "optical_labels.shape\n",
        "\n",
        "fig,ax=plt.subplots(1,2)\n",
        "ax[0].imshow(optical_labels[0][:,:,0])\n",
        "ax[1].imshow(optical_labels[0][:,:,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "g_fDnY0QE9JE",
        "outputId": "7d5a667c-5b5d-43de-db11-29697bf16da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b69c1355ab0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optical_labels = labels1[:, :, :, 1:]\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, optical_labels, test_size=0.2, random_state=42)\n",
        "x_train_1, x_val, y_train_1, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "8-C-KSwLEEMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_1.shape,x_val.shape,x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMKR9n9XEI3I",
        "outputId": "80fb97c5-c781-446d-d5e0-4800b682eb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((368, 256, 256, 3), (92, 256, 256, 3), (116, 256, 256, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_train_1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1EpRuq8ELYN",
        "outputId": "35a69372-5a91-4016-c5cf-e4affc1953be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(368, 256, 256, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D,UpSampling2D,concatenate"
      ],
      "metadata": {
        "id": "BPzE1EKPENhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##model1"
      ],
      "metadata": {
        "id": "z1pkfJaKr59Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the SpikingNeuronLayer placeholder (assuming it is already defined elsewhere)\n",
        "class SpikingNeuronLayer(layers.Layer):\n",
        "    def __init__(self, beta=0.9, threshold=0.8, **kwargs):\n",
        "        super(SpikingNeuronLayer, self).__init__(**kwargs)\n",
        "        self.beta = beta\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        membrane_potential = self.beta * inputs\n",
        "        spikes = tf.cast(membrane_potential >= self.threshold, tf.float32)\n",
        "        reset_mask = membrane_potential >= self.threshold\n",
        "        membrane_potential = tf.where(reset_mask, tf.zeros_like(membrane_potential), membrane_potential)\n",
        "        return spikes\n",
        "\n",
        "def inception_module(input_tensor, filters):\n",
        "    f1, f3_r, f3, f5_r, f5, pool_proj = filters\n",
        "\n",
        "    # 1x1 convolution\n",
        "    conv_1x1 = layers.Conv2D(f1, (1, 1), padding='same', activation='relu')(input_tensor)\n",
        "\n",
        "    # 3x3 convolution\n",
        "    conv_3x3 = layers.Conv2D(f3_r, (1, 1), padding='same', activation='relu')(input_tensor)\n",
        "    conv_3x3 = layers.Conv2D(f3, (3, 3), padding='same', activation='relu')(conv_3x3)\n",
        "\n",
        "    # 5x5 convolution\n",
        "    conv_5x5 = layers.Conv2D(f5_r, (1, 1), padding='same', activation='relu')(input_tensor)\n",
        "    conv_5x5 = layers.Conv2D(f5, (5, 5), padding='same', activation='relu')(conv_5x5)\n",
        "\n",
        "    # Max pooling and projection\n",
        "    max_pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_tensor)\n",
        "    max_pool = layers.Conv2D(pool_proj, (1, 1), padding='same', activation='relu')(max_pool)\n",
        "\n",
        "    # Concatenate filters\n",
        "    output = layers.Concatenate()([conv_1x1, conv_3x3, conv_5x5, max_pool])\n",
        "\n",
        "    return output\n",
        "\n",
        "def create_inception_spiking_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial Conv Layer\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Inception Module 1\n",
        "    x = inception_module(x, filters=[64, 96, 128, 16, 32, 32])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Inception Module 2\n",
        "    x = inception_module(x, filters=[128, 128, 192, 32, 96, 64])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Spiking Layer\n",
        "    #x = SpikingNeuronLayer()(x)\n",
        "\n",
        "    # Inception Module 3\n",
        "    x = inception_module(x, filters=[192, 96, 208, 16, 48, 64])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Decoder (Upsample back to 256x256)\n",
        "    x = layers.Conv2DTranspose(192, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Final spiking layer and output\n",
        "\n",
        "    outputs = layers.Conv2D(2, (1, 1), activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create the model with the modified inception architecture\n",
        "inception_spiking_model = create_inception_spiking_model(input_shape=(256, 256, 3))\n",
        "inception_spiking_model.summary()\n"
      ],
      "metadata": {
        "id": "t-mgGZ2yF7BZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b989be8-b66c-4f65-974b-3e9ef7d2b911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                      \n",
              "\n",
              " conv2d (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m896\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " batch_normalization        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m128\u001b[0m  conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " max_pooling2d              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  batch_normalization[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m96\u001b[0m)             \u001b[38;5;34m3,168\u001b[0m  max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)               \u001b[38;5;34m528\u001b[0m  max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " max_pooling2d_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m2,112\u001b[0m  max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m110,720\u001b[0m  conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "\n",
              " conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)            \u001b[38;5;34m12,832\u001b[0m  conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "\n",
              " conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)             \u001b[38;5;34m1,056\u001b[0m  max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " concatenate (\u001b[38;5;33mConcatenate\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m0\u001b[0m  conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              "                                                                    conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              "                                                                    conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              "                                                                    conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "\n",
              " batch_normalization_1      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)            \u001b[38;5;34m1,024\u001b[0m  concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " max_pooling2d_2            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  batch_normalization_1 \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m32,896\u001b[0m  max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m8,224\u001b[0m  max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " max_pooling2d_3            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m32,896\u001b[0m  max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m192\u001b[0m)            \u001b[38;5;34m221,376\u001b[0m  conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "\n",
              " conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m)              \u001b[38;5;34m76,896\u001b[0m  conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)              \u001b[38;5;34m16,448\u001b[0m  max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " concatenate_1              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m480\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                                      conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              "                                                                    conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "                                                                    conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " batch_normalization_2      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m480\u001b[0m)              \u001b[38;5;34m1,920\u001b[0m  concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " max_pooling2d_4            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m480\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  batch_normalization_2 \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m96\u001b[0m)              \u001b[38;5;34m46,176\u001b[0m  max_pooling2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)               \u001b[38;5;34m7,696\u001b[0m  max_pooling2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " max_pooling2d_5            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m480\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  max_pooling2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m192\u001b[0m)             \u001b[38;5;34m92,352\u001b[0m  max_pooling2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m208\u001b[0m)            \u001b[38;5;34m179,920\u001b[0m  conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m)              \u001b[38;5;34m19,248\u001b[0m  conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)              \u001b[38;5;34m30,784\u001b[0m  max_pooling2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " concatenate_2              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                                      conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "                                                                    conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "                                                                    conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " batch_normalization_3      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)              \u001b[38;5;34m2,048\u001b[0m  concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " max_pooling2d_6            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  batch_normalization_3 \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " conv2d_transpose           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m192\u001b[0m)            \u001b[38;5;34m884,928\u001b[0m  max_pooling2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                         \n",
              "\n",
              " batch_normalization_4      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m192\u001b[0m)                \u001b[38;5;34m768\u001b[0m  conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " conv2d_transpose_1         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m221,312\u001b[0m  batch_normalization_4 \n",
              " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                         \n",
              "\n",
              " batch_normalization_5      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m512\u001b[0m  conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " conv2d_transpose_2         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m73,792\u001b[0m  batch_normalization_5 \n",
              " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                         \n",
              "\n",
              " batch_normalization_6      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)               \u001b[38;5;34m256\u001b[0m  conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " conv2d_transpose_3         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)            \u001b[38;5;34m18,464\u001b[0m  batch_normalization_6 \n",
              " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                         \n",
              "\n",
              " batch_normalization_7      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m128\u001b[0m  conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 \u001b[38;5;34m66\u001b[0m  batch_normalization_7 \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)              </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">        Param # </span><span style=\"font-weight: bold\"> Connected to           </span>\n",
              "\n",
              " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                      \n",
              "\n",
              " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " batch_normalization        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " max_pooling2d              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span>  max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span>  max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " max_pooling2d_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span>  max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">110,720</span>  conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "\n",
              " conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">12,832</span>  conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "\n",
              " conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span>  max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              "                                                                    conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              "                                                                    conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              "                                                                    conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "\n",
              " batch_normalization_1      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " max_pooling2d_2            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_1 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span>  max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span>  max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " max_pooling2d_3            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span>  max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">221,376</span>  conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "\n",
              " conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">76,896</span>  conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span>  max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " concatenate_1              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                                      conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              "                                                                    conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "                                                                    conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " batch_normalization_2      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span>  concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " max_pooling2d_4            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_2 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">46,176</span>  max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">7,696</span>  max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " max_pooling2d_5            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">92,352</span>  max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">179,920</span>  conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">19,248</span>  conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">30,784</span>  max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " concatenate_2              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                                      conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "                                                                    conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "                                                                    conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " batch_normalization_3      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " max_pooling2d_6            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_3 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " conv2d_transpose           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">884,928</span>  max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                         \n",
              "\n",
              " batch_normalization_4      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>  conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " conv2d_transpose_1         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span>  batch_normalization_4 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                         \n",
              "\n",
              " batch_normalization_5      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " conv2d_transpose_2         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span>  batch_normalization_5 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                         \n",
              "\n",
              " batch_normalization_6      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " conv2d_transpose_3         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span>  batch_normalization_6 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                         \n",
              "\n",
              " batch_normalization_7      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>  batch_normalization_7 \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,101,570\u001b[0m (8.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,101,570</span> (8.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,098,178\u001b[0m (8.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,178</span> (8.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,392\u001b[0m (13.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,392</span> (13.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###training"
      ],
      "metadata": {
        "id": "BXW3K78dr-Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = inception_spiking_model"
      ],
      "metadata": {
        "id": "DQRyMI1LGAD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ahjh1S5EmLHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def dice_loss(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return 1 - ((2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth))\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def dice_coef_OD(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true[:,:,0])\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred[:,:,0])\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_OC(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true[:,:,1])\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred[:,:,1])\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n"
      ],
      "metadata": {
        "id": "uYDkDcitGDAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "    return 1 - numerator / (denominator + 1e-7)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "    dice = dice_loss(y_true, y_pred)\n",
        "    return bce + dice\n",
        "\n",
        "m.compile(optimizer='sgd',\n",
        "              loss = bce_dice_loss,\n",
        "              metrics = ['accuracy', tf.keras.metrics.MeanIoU(num_classes = 2), dice_coefficient,dice_coef_OD,dice_coef_OC])\n"
      ],
      "metadata": {
        "id": "Y-bAdCQmGFSQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Keras backend\n",
        "from tensorflow import keras\n",
        "# Alias the backend as K for brevity\n",
        "K = keras.backend\n"
      ],
      "metadata": {
        "id": "qNyIZd8sxmPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dice Coefficient (You already have this)'''\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "    return numerator / (denominator + 1e-7)\n",
        "\n",
        "# Specificity (True Negative Rate)\n",
        "# def specificity(y_true, y_pred):\n",
        "#     true_negatives = tf.reduce_sum(tf.cast((y_true == 0) & (y_pred == 0), tf.float32))\n",
        "#     false_positives = tf.reduce_sum(tf.cast((y_true == 0) & (y_pred == 1), tf.float32))\n",
        "#     specificity_value = true_negatives / (true_negatives + false_positives + 1e-7)\n",
        "#     return specificity_value\n",
        "\n",
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())\n",
        "\n",
        "# Sensitivity (True Positive Rate), using Keras' Recall metric\n",
        "from tensorflow.keras.metrics import Recall as sensitivity\n",
        "\n",
        "# IoU (Intersection over Union), using Keras' MeanIoU metric\n",
        "iou = tf.keras.metrics.MeanIoU(num_classes=2)\n",
        "\n",
        "# AUC (Area Under the Curve), using Keras' AUC metric\n",
        "auc = tf.keras.metrics.AUC()\n",
        "\n",
        "# Precision, using Keras' Precision metric\n",
        "precision = tf.keras.metrics.Precision()\n",
        "\n",
        "# Compile the model with all the metrics\n",
        "m.compile(optimizer='sgd',\n",
        "          loss=bce_dice_loss,\n",
        "          metrics=[\n",
        "              'accuracy',              # Overall accuracy\n",
        "              iou,                     # Intersection over Union\n",
        "              dice_coefficient,         # Dice Coefficient\n",
        "              dice_coef_OD,             # Assuming these are defined elsewhere\n",
        "              dice_coef_OC,             # Assuming these are defined elsewhere\n",
        "              specificity,              # Custom specificity function\n",
        "              sensitivity(),            # Sensitivity (Recall)\n",
        "              auc,                      # Area Under the Curve\n",
        "              precision                 # Precision\n",
        "          ])\n"
      ],
      "metadata": {
        "id": "DhtOtyXDGHv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(x_train_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOC0B6EZfRaC",
        "outputId": "303988be-b21f-4d9a-b981-c77acd98d908",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
              "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
              "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
              "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
              "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
              "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
              "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
              "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
              "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
              "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
              "       247, 248, 249, 250, 251, 252, 253, 254, 255], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_1=x_train_1/255\n",
        "x_val=x_val/255\n",
        "x_test=x_test/255"
      ],
      "metadata": {
        "id": "MyXAfXslgn4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = m.fit(x_train_1, y_train_1, batch_size=2, epochs=100, validation_data = (x_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRPUPptDcIeT",
        "outputId": "faacc252-454f-4a64-a2b6-f002a87ec4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 74ms/step - accuracy: 0.5487 - auc: 0.5148 - dice_coef_oc: 0.0024 - dice_coef_od: 0.0021 - dice_coefficient: 0.0159 - loss: 1.6523 - mean_io_u_1: 0.4937 - precision: 0.0091 - recall: 0.3895 - specificity: 0.6565 - val_accuracy: 0.7660 - val_auc: 0.5334 - val_dice_coef_oc: 0.0034 - val_dice_coef_od: 0.0032 - val_dice_coefficient: 0.0156 - val_loss: 1.3334 - val_mean_io_u_1: 0.4960 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_specificity: 1.0000\n",
            "Epoch 2/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.6035 - auc: 0.5568 - dice_coef_oc: 0.0041 - dice_coef_od: 0.0038 - dice_coefficient: 0.0164 - loss: 1.2973 - mean_io_u_1: 0.4937 - precision: 0.0167 - recall: 0.0346 - specificity: 0.9842 - val_accuracy: 0.6651 - val_auc: 0.5268 - val_dice_coef_oc: 0.0061 - val_dice_coef_od: 0.0056 - val_dice_coefficient: 0.0154 - val_loss: 1.1765 - val_mean_io_u_1: 0.4960 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_specificity: 1.0000\n",
            "Epoch 3/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.6491 - auc: 0.6170 - dice_coef_oc: 0.0070 - dice_coef_od: 0.0065 - dice_coefficient: 0.0180 - loss: 1.1572 - mean_io_u_1: 0.4937 - precision: 0.0198 - recall: 0.0083 - specificity: 0.9967 - val_accuracy: 0.6761 - val_auc: 0.6550 - val_dice_coef_oc: 0.0101 - val_dice_coef_od: 0.0094 - val_dice_coefficient: 0.0181 - val_loss: 1.1021 - val_mean_io_u_1: 0.4960 - val_precision: 0.0811 - val_recall: 9.6096e-04 - val_specificity: 0.9999\n",
            "Epoch 4/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.6715 - auc: 0.7539 - dice_coef_oc: 0.0117 - dice_coef_od: 0.0107 - dice_coefficient: 0.0319 - loss: 1.0827 - mean_io_u_1: 0.4936 - precision: 0.1640 - recall: 0.0741 - specificity: 0.9972 - val_accuracy: 0.6600 - val_auc: 0.9053 - val_dice_coef_oc: 0.0186 - val_dice_coef_od: 0.0163 - val_dice_coefficient: 0.0707 - val_loss: 1.0142 - val_mean_io_u_1: 0.4960 - val_precision: 0.2854 - val_recall: 0.2749 - val_specificity: 0.9945\n",
            "Epoch 5/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.6574 - auc: 0.9544 - dice_coef_oc: 0.0231 - dice_coef_od: 0.0201 - dice_coefficient: 0.1172 - loss: 0.9658 - mean_io_u_1: 0.4937 - precision: 0.2878 - recall: 0.5092 - specificity: 0.9901 - val_accuracy: 0.6194 - val_auc: 0.9544 - val_dice_coef_oc: 0.0432 - val_dice_coef_od: 0.0378 - val_dice_coefficient: 0.1317 - val_loss: 0.9114 - val_mean_io_u_1: 0.4960 - val_precision: 0.4493 - val_recall: 0.2523 - val_specificity: 0.9975\n",
            "Epoch 6/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.6276 - auc: 0.9907 - dice_coef_oc: 0.0570 - dice_coef_od: 0.0518 - dice_coefficient: 0.2827 - loss: 0.7710 - mean_io_u_1: 0.4938 - precision: 0.4062 - recall: 0.8104 - specificity: 0.9908 - val_accuracy: 0.6159 - val_auc: 0.9894 - val_dice_coef_oc: 0.1303 - val_dice_coef_od: 0.1169 - val_dice_coefficient: 0.3166 - val_loss: 0.7157 - val_mean_io_u_1: 0.4960 - val_precision: 0.4752 - val_recall: 0.5558 - val_specificity: 0.9951\n",
            "Epoch 7/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.5638 - auc: 0.9939 - dice_coef_oc: 0.1658 - dice_coef_od: 0.1552 - dice_coefficient: 0.4734 - loss: 0.5672 - mean_io_u_1: 0.4937 - precision: 0.4971 - recall: 0.8597 - specificity: 0.9931 - val_accuracy: 0.5940 - val_auc: 0.9953 - val_dice_coef_oc: 0.2936 - val_dice_coef_od: 0.2660 - val_dice_coefficient: 0.4656 - val_loss: 0.5970 - val_mean_io_u_1: 0.4975 - val_precision: 0.3895 - val_recall: 0.9296 - val_specificity: 0.9883\n",
            "Epoch 8/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.5509 - auc: 0.9948 - dice_coef_oc: 0.3375 - dice_coef_od: 0.3153 - dice_coefficient: 0.5676 - loss: 0.4718 - mean_io_u_1: 0.4941 - precision: 0.5404 - recall: 0.8550 - specificity: 0.9943 - val_accuracy: 0.6030 - val_auc: 0.9942 - val_dice_coef_oc: 0.4577 - val_dice_coef_od: 0.4253 - val_dice_coefficient: 0.5614 - val_loss: 0.4733 - val_mean_io_u_1: 0.4960 - val_precision: 0.5770 - val_recall: 0.7270 - val_specificity: 0.9957\n",
            "Epoch 9/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5995 - auc: 0.9951 - dice_coef_oc: 0.4897 - dice_coef_od: 0.4623 - dice_coefficient: 0.6112 - loss: 0.4310 - mean_io_u_1: 0.4942 - precision: 0.5607 - recall: 0.8599 - specificity: 0.9948 - val_accuracy: 0.6757 - val_auc: 0.9955 - val_dice_coef_oc: 0.5809 - val_dice_coef_od: 0.5559 - val_dice_coefficient: 0.5846 - val_loss: 0.4691 - val_mean_io_u_1: 0.4996 - val_precision: 0.5016 - val_recall: 0.8932 - val_specificity: 0.9929\n",
            "Epoch 10/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.6733 - auc: 0.9952 - dice_coef_oc: 0.6010 - dice_coef_od: 0.5752 - dice_coefficient: 0.6398 - loss: 0.4034 - mean_io_u_1: 0.4943 - precision: 0.5767 - recall: 0.8762 - specificity: 0.9949 - val_accuracy: 0.7708 - val_auc: 0.9953 - val_dice_coef_oc: 0.6591 - val_dice_coef_od: 0.6343 - val_dice_coefficient: 0.6199 - val_loss: 0.4223 - val_mean_io_u_1: 0.4964 - val_precision: 0.5741 - val_recall: 0.8272 - val_specificity: 0.9951\n",
            "Epoch 11/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.7707 - auc: 0.9954 - dice_coef_oc: 0.6805 - dice_coef_od: 0.6526 - dice_coefficient: 0.6528 - loss: 0.3921 - mean_io_u_1: 0.4947 - precision: 0.5855 - recall: 0.8739 - specificity: 0.9951 - val_accuracy: 0.8407 - val_auc: 0.9926 - val_dice_coef_oc: 0.7309 - val_dice_coef_od: 0.7031 - val_dice_coefficient: 0.6027 - val_loss: 0.4330 - val_mean_io_u_1: 0.4961 - val_precision: 0.6088 - val_recall: 0.7125 - val_specificity: 0.9963\n",
            "Epoch 12/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.8473 - auc: 0.9958 - dice_coef_oc: 0.7398 - dice_coef_od: 0.7139 - dice_coefficient: 0.6641 - loss: 0.3809 - mean_io_u_1: 0.4948 - precision: 0.5926 - recall: 0.8839 - specificity: 0.9952 - val_accuracy: 0.8896 - val_auc: 0.9963 - val_dice_coef_oc: 0.7740 - val_dice_coef_od: 0.7507 - val_dice_coefficient: 0.6395 - val_loss: 0.4115 - val_mean_io_u_1: 0.4983 - val_precision: 0.5402 - val_recall: 0.9149 - val_specificity: 0.9938\n",
            "Epoch 13/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9012 - auc: 0.9943 - dice_coef_oc: 0.7825 - dice_coef_od: 0.7569 - dice_coefficient: 0.6688 - loss: 0.3780 - mean_io_u_1: 0.4944 - precision: 0.5942 - recall: 0.8817 - specificity: 0.9951 - val_accuracy: 0.9321 - val_auc: 0.9953 - val_dice_coef_oc: 0.8098 - val_dice_coef_od: 0.7857 - val_dice_coefficient: 0.6252 - val_loss: 0.4344 - val_mean_io_u_1: 0.5041 - val_precision: 0.5135 - val_recall: 0.9094 - val_specificity: 0.9931\n",
            "Epoch 14/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9365 - auc: 0.9959 - dice_coef_oc: 0.8151 - dice_coef_od: 0.7899 - dice_coefficient: 0.6775 - loss: 0.3693 - mean_io_u_1: 0.4942 - precision: 0.6011 - recall: 0.8922 - specificity: 0.9952 - val_accuracy: 0.9535 - val_auc: 0.9860 - val_dice_coef_oc: 0.8337 - val_dice_coef_od: 0.8099 - val_dice_coefficient: 0.6060 - val_loss: 0.4352 - val_mean_io_u_1: 0.4966 - val_precision: 0.5944 - val_recall: 0.6935 - val_specificity: 0.9962\n",
            "Epoch 15/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9577 - auc: 0.9957 - dice_coef_oc: 0.8394 - dice_coef_od: 0.8142 - dice_coefficient: 0.6782 - loss: 0.3684 - mean_io_u_1: 0.4944 - precision: 0.6000 - recall: 0.8883 - specificity: 0.9953 - val_accuracy: 0.9668 - val_auc: 0.9946 - val_dice_coef_oc: 0.8541 - val_dice_coef_od: 0.8311 - val_dice_coefficient: 0.6206 - val_loss: 0.4150 - val_mean_io_u_1: 0.4960 - val_precision: 0.6099 - val_recall: 0.7363 - val_specificity: 0.9962\n",
            "Epoch 16/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9671 - auc: 0.9950 - dice_coef_oc: 0.8588 - dice_coef_od: 0.8348 - dice_coefficient: 0.6832 - loss: 0.3626 - mean_io_u_1: 0.4942 - precision: 0.6062 - recall: 0.8870 - specificity: 0.9954 - val_accuracy: 0.9736 - val_auc: 0.9958 - val_dice_coef_oc: 0.8712 - val_dice_coef_od: 0.8494 - val_dice_coefficient: 0.6673 - val_loss: 0.3821 - val_mean_io_u_1: 0.4976 - val_precision: 0.5750 - val_recall: 0.8931 - val_specificity: 0.9947\n",
            "Epoch 17/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9730 - auc: 0.9957 - dice_coef_oc: 0.8748 - dice_coef_od: 0.8519 - dice_coefficient: 0.6858 - loss: 0.3605 - mean_io_u_1: 0.4947 - precision: 0.6068 - recall: 0.8902 - specificity: 0.9955 - val_accuracy: 0.9798 - val_auc: 0.9822 - val_dice_coef_oc: 0.8847 - val_dice_coef_od: 0.8631 - val_dice_coefficient: 0.5281 - val_loss: 0.5061 - val_mean_io_u_1: 0.4960 - val_precision: 0.5770 - val_recall: 0.5152 - val_specificity: 0.9970\n",
            "Epoch 18/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9787 - auc: 0.9959 - dice_coef_oc: 0.8867 - dice_coef_od: 0.8644 - dice_coefficient: 0.6905 - loss: 0.3554 - mean_io_u_1: 0.4946 - precision: 0.6124 - recall: 0.8896 - specificity: 0.9955 - val_accuracy: 0.9818 - val_auc: 0.9806 - val_dice_coef_oc: 0.8959 - val_dice_coef_od: 0.8741 - val_dice_coefficient: 0.5493 - val_loss: 0.4863 - val_mean_io_u_1: 0.4960 - val_precision: 0.5898 - val_recall: 0.5484 - val_specificity: 0.9969\n",
            "Epoch 19/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9806 - auc: 0.9960 - dice_coef_oc: 0.8977 - dice_coef_od: 0.8753 - dice_coefficient: 0.6938 - loss: 0.3522 - mean_io_u_1: 0.4939 - precision: 0.6130 - recall: 0.8999 - specificity: 0.9955 - val_accuracy: 0.9841 - val_auc: 0.9936 - val_dice_coef_oc: 0.9053 - val_dice_coef_od: 0.8846 - val_dice_coefficient: 0.6527 - val_loss: 0.3884 - val_mean_io_u_1: 0.4961 - val_precision: 0.6028 - val_recall: 0.8026 - val_specificity: 0.9958\n",
            "Epoch 20/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9832 - auc: 0.9965 - dice_coef_oc: 0.9069 - dice_coef_od: 0.8845 - dice_coefficient: 0.6967 - loss: 0.3495 - mean_io_u_1: 0.4941 - precision: 0.6132 - recall: 0.9028 - specificity: 0.9955 - val_accuracy: 0.9845 - val_auc: 0.9932 - val_dice_coef_oc: 0.9132 - val_dice_coef_od: 0.8929 - val_dice_coefficient: 0.6633 - val_loss: 0.3819 - val_mean_io_u_1: 0.4965 - val_precision: 0.6017 - val_recall: 0.8183 - val_specificity: 0.9957\n",
            "Epoch 21/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9827 - auc: 0.9963 - dice_coef_oc: 0.9151 - dice_coef_od: 0.8928 - dice_coefficient: 0.6996 - loss: 0.3466 - mean_io_u_1: 0.4940 - precision: 0.6183 - recall: 0.8996 - specificity: 0.9956 - val_accuracy: 0.9850 - val_auc: 0.9945 - val_dice_coef_oc: 0.9209 - val_dice_coef_od: 0.8986 - val_dice_coefficient: 0.6715 - val_loss: 0.3708 - val_mean_io_u_1: 0.4960 - val_precision: 0.6152 - val_recall: 0.8295 - val_specificity: 0.9958\n",
            "Epoch 22/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9838 - auc: 0.9963 - dice_coef_oc: 0.9218 - dice_coef_od: 0.8988 - dice_coefficient: 0.7013 - loss: 0.3447 - mean_io_u_1: 0.4946 - precision: 0.6173 - recall: 0.9013 - specificity: 0.9956 - val_accuracy: 0.9846 - val_auc: 0.9968 - val_dice_coef_oc: 0.9264 - val_dice_coef_od: 0.9057 - val_dice_coefficient: 0.6597 - val_loss: 0.3967 - val_mean_io_u_1: 0.5006 - val_precision: 0.5389 - val_recall: 0.9425 - val_specificity: 0.9935\n",
            "Epoch 23/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9828 - auc: 0.9965 - dice_coef_oc: 0.9276 - dice_coef_od: 0.9050 - dice_coefficient: 0.7032 - loss: 0.3430 - mean_io_u_1: 0.4944 - precision: 0.6187 - recall: 0.9039 - specificity: 0.9955 - val_accuracy: 0.9833 - val_auc: 0.9723 - val_dice_coef_oc: 0.9321 - val_dice_coef_od: 0.9110 - val_dice_coefficient: 0.6302 - val_loss: 0.4173 - val_mean_io_u_1: 0.4975 - val_precision: 0.5969 - val_recall: 0.7336 - val_specificity: 0.9960\n",
            "Epoch 24/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9829 - auc: 0.9959 - dice_coef_oc: 0.9320 - dice_coef_od: 0.9095 - dice_coefficient: 0.7012 - loss: 0.3454 - mean_io_u_1: 0.4943 - precision: 0.6163 - recall: 0.9000 - specificity: 0.9955 - val_accuracy: 0.9832 - val_auc: 0.9941 - val_dice_coef_oc: 0.9350 - val_dice_coef_od: 0.9151 - val_dice_coefficient: 0.6739 - val_loss: 0.3704 - val_mean_io_u_1: 0.4963 - val_precision: 0.6053 - val_recall: 0.8425 - val_specificity: 0.9956\n",
            "Epoch 25/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9821 - auc: 0.9967 - dice_coef_oc: 0.9361 - dice_coef_od: 0.9147 - dice_coefficient: 0.7040 - loss: 0.3421 - mean_io_u_1: 0.4943 - precision: 0.6162 - recall: 0.9086 - specificity: 0.9955 - val_accuracy: 0.9829 - val_auc: 0.9962 - val_dice_coef_oc: 0.9401 - val_dice_coef_od: 0.9197 - val_dice_coefficient: 0.6803 - val_loss: 0.3653 - val_mean_io_u_1: 0.4962 - val_precision: 0.5911 - val_recall: 0.8974 - val_specificity: 0.9950\n",
            "Epoch 26/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9817 - auc: 0.9960 - dice_coef_oc: 0.9402 - dice_coef_od: 0.9189 - dice_coefficient: 0.7087 - loss: 0.3366 - mean_io_u_1: 0.4938 - precision: 0.6235 - recall: 0.9068 - specificity: 0.9956 - val_accuracy: 0.9808 - val_auc: 0.9940 - val_dice_coef_oc: 0.9433 - val_dice_coef_od: 0.9236 - val_dice_coefficient: 0.6762 - val_loss: 0.3663 - val_mean_io_u_1: 0.4961 - val_precision: 0.6101 - val_recall: 0.8451 - val_specificity: 0.9957\n",
            "Epoch 27/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9799 - auc: 0.9967 - dice_coef_oc: 0.9436 - dice_coef_od: 0.9232 - dice_coefficient: 0.7105 - loss: 0.3347 - mean_io_u_1: 0.4940 - precision: 0.6241 - recall: 0.9104 - specificity: 0.9956 - val_accuracy: 0.9807 - val_auc: 0.9943 - val_dice_coef_oc: 0.9466 - val_dice_coef_od: 0.9276 - val_dice_coefficient: 0.6513 - val_loss: 0.3929 - val_mean_io_u_1: 0.4963 - val_precision: 0.5669 - val_recall: 0.8672 - val_specificity: 0.9947\n",
            "Epoch 28/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9788 - auc: 0.9962 - dice_coef_oc: 0.9466 - dice_coef_od: 0.9269 - dice_coefficient: 0.7129 - loss: 0.3326 - mean_io_u_1: 0.4938 - precision: 0.6261 - recall: 0.9122 - specificity: 0.9956 - val_accuracy: 0.9767 - val_auc: 0.9954 - val_dice_coef_oc: 0.9489 - val_dice_coef_od: 0.9317 - val_dice_coefficient: 0.6744 - val_loss: 0.3724 - val_mean_io_u_1: 0.4965 - val_precision: 0.5777 - val_recall: 0.9077 - val_specificity: 0.9947\n",
            "Epoch 29/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9769 - auc: 0.9965 - dice_coef_oc: 0.9491 - dice_coef_od: 0.9309 - dice_coefficient: 0.7139 - loss: 0.3303 - mean_io_u_1: 0.4937 - precision: 0.6276 - recall: 0.9098 - specificity: 0.9957 - val_accuracy: 0.9747 - val_auc: 0.9964 - val_dice_coef_oc: 0.9517 - val_dice_coef_od: 0.9340 - val_dice_coefficient: 0.6395 - val_loss: 0.4167 - val_mean_io_u_1: 0.4986 - val_precision: 0.5035 - val_recall: 0.9538 - val_specificity: 0.9925\n",
            "Epoch 30/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9754 - auc: 0.9964 - dice_coef_oc: 0.9513 - dice_coef_od: 0.9334 - dice_coefficient: 0.7220 - loss: 0.3209 - mean_io_u_1: 0.4938 - precision: 0.6377 - recall: 0.9177 - specificity: 0.9958 - val_accuracy: 0.9765 - val_auc: 0.9927 - val_dice_coef_oc: 0.9531 - val_dice_coef_od: 0.9372 - val_dice_coefficient: 0.6810 - val_loss: 0.3580 - val_mean_io_u_1: 0.4960 - val_precision: 0.6247 - val_recall: 0.8279 - val_specificity: 0.9960\n",
            "Epoch 31/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9748 - auc: 0.9961 - dice_coef_oc: 0.9533 - dice_coef_od: 0.9370 - dice_coefficient: 0.7158 - loss: 0.3271 - mean_io_u_1: 0.4938 - precision: 0.6287 - recall: 0.9118 - specificity: 0.9958 - val_accuracy: 0.9748 - val_auc: 0.9954 - val_dice_coef_oc: 0.9552 - val_dice_coef_od: 0.9391 - val_dice_coefficient: 0.6898 - val_loss: 0.3616 - val_mean_io_u_1: 0.4989 - val_precision: 0.5790 - val_recall: 0.9168 - val_specificity: 0.9947\n",
            "Epoch 32/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9756 - auc: 0.9963 - dice_coef_oc: 0.9546 - dice_coef_od: 0.9380 - dice_coefficient: 0.7264 - loss: 0.3151 - mean_io_u_1: 0.4937 - precision: 0.6388 - recall: 0.9180 - specificity: 0.9959 - val_accuracy: 0.9754 - val_auc: 0.9950 - val_dice_coef_oc: 0.9564 - val_dice_coef_od: 0.9413 - val_dice_coefficient: 0.6896 - val_loss: 0.3528 - val_mean_io_u_1: 0.4960 - val_precision: 0.5969 - val_recall: 0.8938 - val_specificity: 0.9952\n",
            "Epoch 33/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9752 - auc: 0.9960 - dice_coef_oc: 0.9564 - dice_coef_od: 0.9407 - dice_coefficient: 0.7228 - loss: 0.3192 - mean_io_u_1: 0.4941 - precision: 0.6335 - recall: 0.9164 - specificity: 0.9958 - val_accuracy: 0.9739 - val_auc: 0.9865 - val_dice_coef_oc: 0.9577 - val_dice_coef_od: 0.9437 - val_dice_coefficient: 0.6719 - val_loss: 0.3666 - val_mean_io_u_1: 0.4961 - val_precision: 0.6200 - val_recall: 0.8086 - val_specificity: 0.9960\n",
            "Epoch 34/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9741 - auc: 0.9966 - dice_coef_oc: 0.9578 - dice_coef_od: 0.9431 - dice_coefficient: 0.7259 - loss: 0.3144 - mean_io_u_1: 0.4941 - precision: 0.6391 - recall: 0.9178 - specificity: 0.9959 - val_accuracy: 0.9753 - val_auc: 0.9949 - val_dice_coef_oc: 0.9585 - val_dice_coef_od: 0.9451 - val_dice_coefficient: 0.6929 - val_loss: 0.3482 - val_mean_io_u_1: 0.4962 - val_precision: 0.5999 - val_recall: 0.9003 - val_specificity: 0.9952\n",
            "Epoch 35/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9753 - auc: 0.9965 - dice_coef_oc: 0.9587 - dice_coef_od: 0.9449 - dice_coefficient: 0.7282 - loss: 0.3110 - mean_io_u_1: 0.4937 - precision: 0.6381 - recall: 0.9236 - specificity: 0.9959 - val_accuracy: 0.9767 - val_auc: 0.9852 - val_dice_coef_oc: 0.9599 - val_dice_coef_od: 0.9466 - val_dice_coefficient: 0.6544 - val_loss: 0.3791 - val_mean_io_u_1: 0.4960 - val_precision: 0.6244 - val_recall: 0.7442 - val_specificity: 0.9964\n",
            "Epoch 36/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9746 - auc: 0.9951 - dice_coef_oc: 0.9599 - dice_coef_od: 0.9464 - dice_coefficient: 0.7266 - loss: 0.3121 - mean_io_u_1: 0.4937 - precision: 0.6368 - recall: 0.9143 - specificity: 0.9958 - val_accuracy: 0.9756 - val_auc: 0.9885 - val_dice_coef_oc: 0.9602 - val_dice_coef_od: 0.9476 - val_dice_coefficient: 0.6608 - val_loss: 0.3728 - val_mean_io_u_1: 0.4960 - val_precision: 0.6049 - val_recall: 0.8077 - val_specificity: 0.9958\n",
            "Epoch 37/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9748 - auc: 0.9960 - dice_coef_oc: 0.9600 - dice_coef_od: 0.9469 - dice_coefficient: 0.7328 - loss: 0.3031 - mean_io_u_1: 0.4938 - precision: 0.6415 - recall: 0.9235 - specificity: 0.9959 - val_accuracy: 0.9763 - val_auc: 0.9941 - val_dice_coef_oc: 0.9606 - val_dice_coef_od: 0.9475 - val_dice_coefficient: 0.6902 - val_loss: 0.3408 - val_mean_io_u_1: 0.4962 - val_precision: 0.6105 - val_recall: 0.8682 - val_specificity: 0.9956\n",
            "Epoch 38/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9737 - auc: 0.9959 - dice_coef_oc: 0.9605 - dice_coef_od: 0.9468 - dice_coefficient: 0.7378 - loss: 0.2941 - mean_io_u_1: 0.4940 - precision: 0.6536 - recall: 0.9145 - specificity: 0.9961 - val_accuracy: 0.9770 - val_auc: 0.9857 - val_dice_coef_oc: 0.9607 - val_dice_coef_od: 0.9466 - val_dice_coefficient: 0.6828 - val_loss: 0.3467 - val_mean_io_u_1: 0.4961 - val_precision: 0.6314 - val_recall: 0.8152 - val_specificity: 0.9962\n",
            "Epoch 39/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9686 - auc: 0.9948 - dice_coef_oc: 0.9604 - dice_coef_od: 0.9469 - dice_coefficient: 0.7434 - loss: 0.2859 - mean_io_u_1: 0.4946 - precision: 0.6641 - recall: 0.9035 - specificity: 0.9963 - val_accuracy: 0.9718 - val_auc: 0.9772 - val_dice_coef_oc: 0.9601 - val_dice_coef_od: 0.9472 - val_dice_coefficient: 0.6717 - val_loss: 0.3512 - val_mean_io_u_1: 0.4962 - val_precision: 0.6639 - val_recall: 0.7389 - val_specificity: 0.9970\n",
            "Epoch 40/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.9672 - auc: 0.9937 - dice_coef_oc: 0.9597 - dice_coef_od: 0.9469 - dice_coefficient: 0.7549 - loss: 0.2689 - mean_io_u_1: 0.4953 - precision: 0.6785 - recall: 0.9032 - specificity: 0.9966 - val_accuracy: 0.9623 - val_auc: 0.9586 - val_dice_coef_oc: 0.9574 - val_dice_coef_od: 0.9465 - val_dice_coefficient: 0.6595 - val_loss: 0.3631 - val_mean_io_u_1: 0.4964 - val_precision: 0.6776 - val_recall: 0.6817 - val_specificity: 0.9974\n",
            "Epoch 41/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9664 - auc: 0.9928 - dice_coef_oc: 0.9574 - dice_coef_od: 0.9473 - dice_coefficient: 0.7820 - loss: 0.2335 - mean_io_u_1: 0.4961 - precision: 0.7259 - recall: 0.8965 - specificity: 0.9973 - val_accuracy: 0.9762 - val_auc: 0.9776 - val_dice_coef_oc: 0.9525 - val_dice_coef_od: 0.9478 - val_dice_coefficient: 0.7380 - val_loss: 0.2756 - val_mean_io_u_1: 0.4981 - val_precision: 0.7432 - val_recall: 0.7851 - val_specificity: 0.9978\n",
            "Epoch 42/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9642 - auc: 0.9885 - dice_coef_oc: 0.9527 - dice_coef_od: 0.9503 - dice_coefficient: 0.8032 - loss: 0.2080 - mean_io_u_1: 0.4978 - precision: 0.7798 - recall: 0.8715 - specificity: 0.9980 - val_accuracy: 0.9647 - val_auc: 0.9780 - val_dice_coef_oc: 0.9495 - val_dice_coef_od: 0.9501 - val_dice_coefficient: 0.7635 - val_loss: 0.2505 - val_mean_io_u_1: 0.5034 - val_precision: 0.7394 - val_recall: 0.8340 - val_specificity: 0.9976\n",
            "Epoch 43/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9575 - auc: 0.9858 - dice_coef_oc: 0.9514 - dice_coef_od: 0.9522 - dice_coefficient: 0.8123 - loss: 0.1989 - mean_io_u_1: 0.5018 - precision: 0.7924 - recall: 0.8668 - specificity: 0.9982 - val_accuracy: 0.9635 - val_auc: 0.9546 - val_dice_coef_oc: 0.9523 - val_dice_coef_od: 0.9536 - val_dice_coefficient: 0.7052 - val_loss: 0.3105 - val_mean_io_u_1: 0.4980 - val_precision: 0.7716 - val_recall: 0.6922 - val_specificity: 0.9984\n",
            "Epoch 44/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9554 - auc: 0.9856 - dice_coef_oc: 0.9550 - dice_coef_od: 0.9557 - dice_coefficient: 0.8226 - loss: 0.1884 - mean_io_u_1: 0.5031 - precision: 0.8033 - recall: 0.8738 - specificity: 0.9983 - val_accuracy: 0.9517 - val_auc: 0.9061 - val_dice_coef_oc: 0.9522 - val_dice_coef_od: 0.9565 - val_dice_coefficient: 0.6233 - val_loss: 0.4023 - val_mean_io_u_1: 0.4963 - val_precision: 0.7571 - val_recall: 0.5503 - val_specificity: 0.9986\n",
            "Epoch 45/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9518 - auc: 0.9836 - dice_coef_oc: 0.9536 - dice_coef_od: 0.9576 - dice_coefficient: 0.8264 - loss: 0.1853 - mean_io_u_1: 0.5049 - precision: 0.8106 - recall: 0.8693 - specificity: 0.9984 - val_accuracy: 0.9478 - val_auc: 0.8747 - val_dice_coef_oc: 0.9531 - val_dice_coef_od: 0.9589 - val_dice_coefficient: 0.6014 - val_loss: 0.4268 - val_mean_io_u_1: 0.4979 - val_precision: 0.7835 - val_recall: 0.5176 - val_specificity: 0.9989\n",
            "Epoch 46/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9498 - auc: 0.9848 - dice_coef_oc: 0.9552 - dice_coef_od: 0.9598 - dice_coefficient: 0.8323 - loss: 0.1787 - mean_io_u_1: 0.5074 - precision: 0.8169 - recall: 0.8720 - specificity: 0.9984 - val_accuracy: 0.9572 - val_auc: 0.9636 - val_dice_coef_oc: 0.9561 - val_dice_coef_od: 0.9609 - val_dice_coefficient: 0.7501 - val_loss: 0.2666 - val_mean_io_u_1: 0.5011 - val_precision: 0.7522 - val_recall: 0.7829 - val_specificity: 0.9979\n",
            "Epoch 47/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9462 - auc: 0.9849 - dice_coef_oc: 0.9579 - dice_coef_od: 0.9620 - dice_coefficient: 0.8396 - loss: 0.1709 - mean_io_u_1: 0.5098 - precision: 0.8244 - recall: 0.8803 - specificity: 0.9985 - val_accuracy: 0.9209 - val_auc: 0.9242 - val_dice_coef_oc: 0.9584 - val_dice_coef_od: 0.9629 - val_dice_coefficient: 0.6816 - val_loss: 0.3389 - val_mean_io_u_1: 0.4988 - val_precision: 0.8014 - val_recall: 0.6212 - val_specificity: 0.9988\n",
            "Epoch 48/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9431 - auc: 0.9850 - dice_coef_oc: 0.9597 - dice_coef_od: 0.9641 - dice_coefficient: 0.8397 - loss: 0.1707 - mean_io_u_1: 0.5144 - precision: 0.8236 - recall: 0.8780 - specificity: 0.9985 - val_accuracy: 0.9458 - val_auc: 0.8923 - val_dice_coef_oc: 0.9642 - val_dice_coef_od: 0.9674 - val_dice_coefficient: 0.6279 - val_loss: 0.4009 - val_mean_io_u_1: 0.4987 - val_precision: 0.7499 - val_recall: 0.5614 - val_specificity: 0.9985\n",
            "Epoch 49/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9326 - auc: 0.9828 - dice_coef_oc: 0.9620 - dice_coef_od: 0.9664 - dice_coefficient: 0.8426 - loss: 0.1684 - mean_io_u_1: 0.5187 - precision: 0.8297 - recall: 0.8775 - specificity: 0.9986 - val_accuracy: 0.9387 - val_auc: 0.9701 - val_dice_coef_oc: 0.9620 - val_dice_coef_od: 0.9672 - val_dice_coefficient: 0.7813 - val_loss: 0.2328 - val_mean_io_u_1: 0.5025 - val_precision: 0.7801 - val_recall: 0.8092 - val_specificity: 0.9982\n",
            "Epoch 50/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9232 - auc: 0.9842 - dice_coef_oc: 0.9627 - dice_coef_od: 0.9676 - dice_coefficient: 0.8476 - loss: 0.1629 - mean_io_u_1: 0.5193 - precision: 0.8325 - recall: 0.8838 - specificity: 0.9986 - val_accuracy: 0.9297 - val_auc: 0.9521 - val_dice_coef_oc: 0.9651 - val_dice_coef_od: 0.9690 - val_dice_coefficient: 0.7486 - val_loss: 0.2671 - val_mean_io_u_1: 0.5017 - val_precision: 0.7959 - val_recall: 0.7379 - val_specificity: 0.9985\n",
            "Epoch 51/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9215 - auc: 0.9831 - dice_coef_oc: 0.9645 - dice_coef_od: 0.9690 - dice_coefficient: 0.8476 - loss: 0.1631 - mean_io_u_1: 0.5200 - precision: 0.8351 - recall: 0.8804 - specificity: 0.9986 - val_accuracy: 0.9191 - val_auc: 0.9528 - val_dice_coef_oc: 0.9638 - val_dice_coef_od: 0.9703 - val_dice_coefficient: 0.7566 - val_loss: 0.2595 - val_mean_io_u_1: 0.5049 - val_precision: 0.7891 - val_recall: 0.7552 - val_specificity: 0.9984\n",
            "Epoch 52/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.9175 - auc: 0.9853 - dice_coef_oc: 0.9647 - dice_coef_od: 0.9706 - dice_coefficient: 0.8609 - loss: 0.1486 - mean_io_u_1: 0.5197 - precision: 0.8502 - recall: 0.8901 - specificity: 0.9987 - val_accuracy: 0.8845 - val_auc: 0.9582 - val_dice_coef_oc: 0.9641 - val_dice_coef_od: 0.9708 - val_dice_coefficient: 0.7372 - val_loss: 0.2817 - val_mean_io_u_1: 0.5071 - val_precision: 0.7049 - val_recall: 0.7966 - val_specificity: 0.9973\n",
            "Epoch 53/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9108 - auc: 0.9841 - dice_coef_oc: 0.9658 - dice_coef_od: 0.9715 - dice_coefficient: 0.8604 - loss: 0.1496 - mean_io_u_1: 0.5262 - precision: 0.8491 - recall: 0.8891 - specificity: 0.9987 - val_accuracy: 0.9373 - val_auc: 0.9132 - val_dice_coef_oc: 0.9671 - val_dice_coef_od: 0.9722 - val_dice_coefficient: 0.6111 - val_loss: 0.4097 - val_mean_io_u_1: 0.4961 - val_precision: 0.8665 - val_recall: 0.4902 - val_specificity: 0.9994\n",
            "Epoch 54/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.8997 - auc: 0.9836 - dice_coef_oc: 0.9686 - dice_coef_od: 0.9732 - dice_coefficient: 0.8618 - loss: 0.1478 - mean_io_u_1: 0.5282 - precision: 0.8546 - recall: 0.8860 - specificity: 0.9988 - val_accuracy: 0.9188 - val_auc: 0.9648 - val_dice_coef_oc: 0.9684 - val_dice_coef_od: 0.9741 - val_dice_coefficient: 0.7871 - val_loss: 0.2292 - val_mean_io_u_1: 0.5304 - val_precision: 0.7791 - val_recall: 0.8161 - val_specificity: 0.9981\n",
            "Epoch 55/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.8977 - auc: 0.9845 - dice_coef_oc: 0.9681 - dice_coef_od: 0.9736 - dice_coefficient: 0.8644 - loss: 0.1451 - mean_io_u_1: 0.5355 - precision: 0.8531 - recall: 0.8919 - specificity: 0.9988 - val_accuracy: 0.8028 - val_auc: 0.9461 - val_dice_coef_oc: 0.9698 - val_dice_coef_od: 0.9746 - val_dice_coefficient: 0.7466 - val_loss: 0.2733 - val_mean_io_u_1: 0.5275 - val_precision: 0.7732 - val_recall: 0.7478 - val_specificity: 0.9982\n",
            "Epoch 56/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.8926 - auc: 0.9837 - dice_coef_oc: 0.9707 - dice_coef_od: 0.9752 - dice_coefficient: 0.8692 - loss: 0.1403 - mean_io_u_1: 0.5352 - precision: 0.8611 - recall: 0.8925 - specificity: 0.9988 - val_accuracy: 0.9006 - val_auc: 0.9520 - val_dice_coef_oc: 0.9724 - val_dice_coef_od: 0.9763 - val_dice_coefficient: 0.7701 - val_loss: 0.2477 - val_mean_io_u_1: 0.5214 - val_precision: 0.7807 - val_recall: 0.7800 - val_specificity: 0.9982\n",
            "Epoch 57/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.8853 - auc: 0.9862 - dice_coef_oc: 0.9715 - dice_coef_od: 0.9764 - dice_coefficient: 0.8751 - loss: 0.1334 - mean_io_u_1: 0.5386 - precision: 0.8666 - recall: 0.9020 - specificity: 0.9989 - val_accuracy: 0.8556 - val_auc: 0.9424 - val_dice_coef_oc: 0.9732 - val_dice_coef_od: 0.9777 - val_dice_coefficient: 0.7677 - val_loss: 0.2509 - val_mean_io_u_1: 0.5149 - val_precision: 0.8187 - val_recall: 0.7381 - val_specificity: 0.9987\n",
            "Epoch 58/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.8745 - auc: 0.9862 - dice_coef_oc: 0.9730 - dice_coef_od: 0.9774 - dice_coefficient: 0.8764 - loss: 0.1323 - mean_io_u_1: 0.5425 - precision: 0.8666 - recall: 0.9019 - specificity: 0.9989 - val_accuracy: 0.9181 - val_auc: 0.9174 - val_dice_coef_oc: 0.9706 - val_dice_coef_od: 0.9770 - val_dice_coefficient: 0.6791 - val_loss: 0.3497 - val_mean_io_u_1: 0.5173 - val_precision: 0.6683 - val_recall: 0.7078 - val_specificity: 0.9972\n",
            "Epoch 59/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.8721 - auc: 0.9851 - dice_coef_oc: 0.9731 - dice_coef_od: 0.9779 - dice_coefficient: 0.8781 - loss: 0.1305 - mean_io_u_1: 0.5447 - precision: 0.8705 - recall: 0.8999 - specificity: 0.9989 - val_accuracy: 0.8829 - val_auc: 0.9452 - val_dice_coef_oc: 0.9742 - val_dice_coef_od: 0.9792 - val_dice_coefficient: 0.7456 - val_loss: 0.2731 - val_mean_io_u_1: 0.5153 - val_precision: 0.7728 - val_recall: 0.7460 - val_specificity: 0.9982\n",
            "Epoch 60/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.8618 - auc: 0.9866 - dice_coef_oc: 0.9740 - dice_coef_od: 0.9788 - dice_coefficient: 0.8813 - loss: 0.1271 - mean_io_u_1: 0.5506 - precision: 0.8729 - recall: 0.9049 - specificity: 0.9989 - val_accuracy: 0.8694 - val_auc: 0.9404 - val_dice_coef_oc: 0.9741 - val_dice_coef_od: 0.9795 - val_dice_coefficient: 0.7667 - val_loss: 0.2499 - val_mean_io_u_1: 0.5077 - val_precision: 0.8404 - val_recall: 0.7292 - val_specificity: 0.9989\n",
            "Epoch 61/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.8539 - auc: 0.9879 - dice_coef_oc: 0.9751 - dice_coef_od: 0.9796 - dice_coefficient: 0.8877 - loss: 0.1199 - mean_io_u_1: 0.5540 - precision: 0.8810 - recall: 0.9088 - specificity: 0.9990 - val_accuracy: 0.8943 - val_auc: 0.9076 - val_dice_coef_oc: 0.9754 - val_dice_coef_od: 0.9802 - val_dice_coefficient: 0.6919 - val_loss: 0.3308 - val_mean_io_u_1: 0.4987 - val_precision: 0.8383 - val_recall: 0.6110 - val_specificity: 0.9991\n",
            "Epoch 62/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.8503 - auc: 0.9867 - dice_coef_oc: 0.9753 - dice_coef_od: 0.9800 - dice_coefficient: 0.8846 - loss: 0.1236 - mean_io_u_1: 0.5543 - precision: 0.8771 - recall: 0.9069 - specificity: 0.9990 - val_accuracy: 0.8869 - val_auc: 0.9408 - val_dice_coef_oc: 0.9757 - val_dice_coef_od: 0.9805 - val_dice_coefficient: 0.7654 - val_loss: 0.2555 - val_mean_io_u_1: 0.5230 - val_precision: 0.7870 - val_recall: 0.7644 - val_specificity: 0.9983\n",
            "Epoch 63/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.8429 - auc: 0.9871 - dice_coef_oc: 0.9768 - dice_coef_od: 0.9810 - dice_coefficient: 0.8884 - loss: 0.1192 - mean_io_u_1: 0.5624 - precision: 0.8825 - recall: 0.9080 - specificity: 0.9990 - val_accuracy: 0.8685 - val_auc: 0.9451 - val_dice_coef_oc: 0.9783 - val_dice_coef_od: 0.9820 - val_dice_coefficient: 0.7840 - val_loss: 0.2336 - val_mean_io_u_1: 0.5159 - val_precision: 0.8208 - val_recall: 0.7679 - val_specificity: 0.9987\n",
            "Epoch 64/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.8369 - auc: 0.9869 - dice_coef_oc: 0.9781 - dice_coef_od: 0.9819 - dice_coefficient: 0.8912 - loss: 0.1163 - mean_io_u_1: 0.5612 - precision: 0.8887 - recall: 0.9073 - specificity: 0.9991 - val_accuracy: 0.8295 - val_auc: 0.9501 - val_dice_coef_oc: 0.9791 - val_dice_coef_od: 0.9826 - val_dice_coefficient: 0.7768 - val_loss: 0.2384 - val_mean_io_u_1: 0.5071 - val_precision: 0.8380 - val_recall: 0.7488 - val_specificity: 0.9988\n",
            "Epoch 65/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.8249 - auc: 0.9863 - dice_coef_oc: 0.9788 - dice_coef_od: 0.9824 - dice_coefficient: 0.8906 - loss: 0.1171 - mean_io_u_1: 0.5687 - precision: 0.8866 - recall: 0.9082 - specificity: 0.9991 - val_accuracy: 0.8345 - val_auc: 0.9096 - val_dice_coef_oc: 0.9783 - val_dice_coef_od: 0.9827 - val_dice_coefficient: 0.7053 - val_loss: 0.3156 - val_mean_io_u_1: 0.5078 - val_precision: 0.8572 - val_recall: 0.6295 - val_specificity: 0.9992\n",
            "Epoch 66/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.8223 - auc: 0.9888 - dice_coef_oc: 0.9795 - dice_coef_od: 0.9829 - dice_coefficient: 0.8974 - loss: 0.1096 - mean_io_u_1: 0.5742 - precision: 0.8943 - recall: 0.9141 - specificity: 0.9991 - val_accuracy: 0.8441 - val_auc: 0.9555 - val_dice_coef_oc: 0.9805 - val_dice_coef_od: 0.9837 - val_dice_coefficient: 0.7853 - val_loss: 0.2344 - val_mean_io_u_1: 0.5389 - val_precision: 0.7682 - val_recall: 0.8169 - val_specificity: 0.9980\n",
            "Epoch 67/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.8159 - auc: 0.9883 - dice_coef_oc: 0.9797 - dice_coef_od: 0.9833 - dice_coefficient: 0.8976 - loss: 0.1095 - mean_io_u_1: 0.5729 - precision: 0.8923 - recall: 0.9158 - specificity: 0.9991 - val_accuracy: 0.7888 - val_auc: 0.9330 - val_dice_coef_oc: 0.9794 - val_dice_coef_od: 0.9836 - val_dice_coefficient: 0.7764 - val_loss: 0.2456 - val_mean_io_u_1: 0.5609 - val_precision: 0.8216 - val_recall: 0.7513 - val_specificity: 0.9987\n",
            "Epoch 68/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.8071 - auc: 0.9885 - dice_coef_oc: 0.9800 - dice_coef_od: 0.9837 - dice_coefficient: 0.9007 - loss: 0.1059 - mean_io_u_1: 0.5760 - precision: 0.8985 - recall: 0.9153 - specificity: 0.9992 - val_accuracy: 0.8690 - val_auc: 0.9438 - val_dice_coef_oc: 0.9803 - val_dice_coef_od: 0.9843 - val_dice_coefficient: 0.7795 - val_loss: 0.2406 - val_mean_io_u_1: 0.5420 - val_precision: 0.7914 - val_recall: 0.7817 - val_specificity: 0.9984\n",
            "Epoch 69/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.7956 - auc: 0.9896 - dice_coef_oc: 0.9806 - dice_coef_od: 0.9844 - dice_coefficient: 0.9040 - loss: 0.1023 - mean_io_u_1: 0.5830 - precision: 0.9022 - recall: 0.9196 - specificity: 0.9992 - val_accuracy: 0.7463 - val_auc: 0.9436 - val_dice_coef_oc: 0.9807 - val_dice_coef_od: 0.9847 - val_dice_coefficient: 0.7764 - val_loss: 0.2400 - val_mean_io_u_1: 0.5127 - val_precision: 0.8504 - val_recall: 0.7382 - val_specificity: 0.9990\n",
            "Epoch 70/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.7924 - auc: 0.9887 - dice_coef_oc: 0.9807 - dice_coef_od: 0.9845 - dice_coefficient: 0.9017 - loss: 0.1050 - mean_io_u_1: 0.5836 - precision: 0.8977 - recall: 0.9196 - specificity: 0.9992 - val_accuracy: 0.8251 - val_auc: 0.9556 - val_dice_coef_oc: 0.9815 - val_dice_coef_od: 0.9853 - val_dice_coefficient: 0.8112 - val_loss: 0.2064 - val_mean_io_u_1: 0.5627 - val_precision: 0.8222 - val_recall: 0.8152 - val_specificity: 0.9986\n",
            "Epoch 71/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7824 - auc: 0.9894 - dice_coef_oc: 0.9816 - dice_coef_od: 0.9852 - dice_coefficient: 0.9060 - loss: 0.1003 - mean_io_u_1: 0.5922 - precision: 0.9038 - recall: 0.9203 - specificity: 0.9992 - val_accuracy: 0.8079 - val_auc: 0.9484 - val_dice_coef_oc: 0.9807 - val_dice_coef_od: 0.9851 - val_dice_coefficient: 0.7983 - val_loss: 0.2189 - val_mean_io_u_1: 0.5342 - val_precision: 0.8243 - val_recall: 0.7897 - val_specificity: 0.9987\n",
            "Epoch 72/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7779 - auc: 0.9880 - dice_coef_oc: 0.9814 - dice_coef_od: 0.9853 - dice_coefficient: 0.9040 - loss: 0.1027 - mean_io_u_1: 0.5923 - precision: 0.9024 - recall: 0.9173 - specificity: 0.9992 - val_accuracy: 0.7947 - val_auc: 0.9629 - val_dice_coef_oc: 0.9823 - val_dice_coef_od: 0.9859 - val_dice_coefficient: 0.8093 - val_loss: 0.2094 - val_mean_io_u_1: 0.5963 - val_precision: 0.7812 - val_recall: 0.8518 - val_specificity: 0.9981\n",
            "Epoch 73/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.7670 - auc: 0.9880 - dice_coef_oc: 0.9814 - dice_coef_od: 0.9855 - dice_coefficient: 0.9034 - loss: 0.1034 - mean_io_u_1: 0.5972 - precision: 0.8997 - recall: 0.9180 - specificity: 0.9992 - val_accuracy: 0.7221 - val_auc: 0.9402 - val_dice_coef_oc: 0.9827 - val_dice_coef_od: 0.9864 - val_dice_coefficient: 0.7819 - val_loss: 0.2354 - val_mean_io_u_1: 0.5128 - val_precision: 0.8443 - val_recall: 0.7484 - val_specificity: 0.9989\n",
            "Epoch 74/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.7567 - auc: 0.9886 - dice_coef_oc: 0.9820 - dice_coef_od: 0.9860 - dice_coefficient: 0.9071 - loss: 0.0994 - mean_io_u_1: 0.5987 - precision: 0.9045 - recall: 0.9211 - specificity: 0.9992 - val_accuracy: 0.7824 - val_auc: 0.9432 - val_dice_coef_oc: 0.9834 - val_dice_coef_od: 0.9868 - val_dice_coefficient: 0.7916 - val_loss: 0.2260 - val_mean_io_u_1: 0.5272 - val_precision: 0.8347 - val_recall: 0.7675 - val_specificity: 0.9988\n",
            "Epoch 75/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.7527 - auc: 0.9896 - dice_coef_oc: 0.9828 - dice_coef_od: 0.9866 - dice_coefficient: 0.9107 - loss: 0.0954 - mean_io_u_1: 0.5993 - precision: 0.9084 - recall: 0.9249 - specificity: 0.9993 - val_accuracy: 0.7825 - val_auc: 0.9447 - val_dice_coef_oc: 0.9830 - val_dice_coef_od: 0.9867 - val_dice_coefficient: 0.7910 - val_loss: 0.2289 - val_mean_io_u_1: 0.5549 - val_precision: 0.8020 - val_recall: 0.7907 - val_specificity: 0.9984\n",
            "Epoch 76/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.7430 - auc: 0.9898 - dice_coef_oc: 0.9828 - dice_coef_od: 0.9867 - dice_coefficient: 0.9107 - loss: 0.0953 - mean_io_u_1: 0.6072 - precision: 0.9088 - recall: 0.9240 - specificity: 0.9993 - val_accuracy: 0.6645 - val_auc: 0.9258 - val_dice_coef_oc: 0.9829 - val_dice_coef_od: 0.9870 - val_dice_coefficient: 0.7485 - val_loss: 0.2704 - val_mean_io_u_1: 0.5077 - val_precision: 0.8513 - val_recall: 0.6886 - val_specificity: 0.9990\n",
            "Epoch 77/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7341 - auc: 0.9909 - dice_coef_oc: 0.9832 - dice_coef_od: 0.9871 - dice_coefficient: 0.9154 - loss: 0.0901 - mean_io_u_1: 0.6108 - precision: 0.9132 - recall: 0.9284 - specificity: 0.9993 - val_accuracy: 0.7352 - val_auc: 0.9475 - val_dice_coef_oc: 0.9831 - val_dice_coef_od: 0.9873 - val_dice_coefficient: 0.7984 - val_loss: 0.2196 - val_mean_io_u_1: 0.5452 - val_precision: 0.8207 - val_recall: 0.7917 - val_specificity: 0.9986\n",
            "Epoch 78/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.7302 - auc: 0.9903 - dice_coef_oc: 0.9830 - dice_coef_od: 0.9871 - dice_coefficient: 0.9158 - loss: 0.0899 - mean_io_u_1: 0.6060 - precision: 0.9152 - recall: 0.9282 - specificity: 0.9993 - val_accuracy: 0.7002 - val_auc: 0.9469 - val_dice_coef_oc: 0.9843 - val_dice_coef_od: 0.9877 - val_dice_coefficient: 0.8078 - val_loss: 0.2107 - val_mean_io_u_1: 0.5771 - val_precision: 0.8359 - val_recall: 0.7951 - val_specificity: 0.9988\n",
            "Epoch 79/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.7249 - auc: 0.9911 - dice_coef_oc: 0.9839 - dice_coef_od: 0.9875 - dice_coefficient: 0.9194 - loss: 0.0859 - mean_io_u_1: 0.6169 - precision: 0.9178 - recall: 0.9320 - specificity: 0.9993 - val_accuracy: 0.7123 - val_auc: 0.9479 - val_dice_coef_oc: 0.9840 - val_dice_coef_od: 0.9877 - val_dice_coefficient: 0.8034 - val_loss: 0.2147 - val_mean_io_u_1: 0.5476 - val_precision: 0.8314 - val_recall: 0.7931 - val_specificity: 0.9987\n",
            "Epoch 80/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7153 - auc: 0.9913 - dice_coef_oc: 0.9844 - dice_coef_od: 0.9877 - dice_coefficient: 0.9211 - loss: 0.0841 - mean_io_u_1: 0.6176 - precision: 0.9206 - recall: 0.9333 - specificity: 0.9994 - val_accuracy: 0.6853 - val_auc: 0.9028 - val_dice_coef_oc: 0.9835 - val_dice_coef_od: 0.9878 - val_dice_coefficient: 0.7301 - val_loss: 0.2926 - val_mean_io_u_1: 0.5118 - val_precision: 0.8616 - val_recall: 0.6545 - val_specificity: 0.9992\n",
            "Epoch 81/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7040 - auc: 0.9911 - dice_coef_oc: 0.9841 - dice_coef_od: 0.9878 - dice_coefficient: 0.9194 - loss: 0.0861 - mean_io_u_1: 0.6249 - precision: 0.9172 - recall: 0.9316 - specificity: 0.9993 - val_accuracy: 0.6871 - val_auc: 0.9402 - val_dice_coef_oc: 0.9853 - val_dice_coef_od: 0.9883 - val_dice_coefficient: 0.7994 - val_loss: 0.2191 - val_mean_io_u_1: 0.5546 - val_precision: 0.8433 - val_recall: 0.7736 - val_specificity: 0.9988\n",
            "Epoch 82/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7015 - auc: 0.9909 - dice_coef_oc: 0.9850 - dice_coef_od: 0.9882 - dice_coefficient: 0.9217 - loss: 0.0834 - mean_io_u_1: 0.6278 - precision: 0.9218 - recall: 0.9320 - specificity: 0.9994 - val_accuracy: 0.6404 - val_auc: 0.9243 - val_dice_coef_oc: 0.9855 - val_dice_coef_od: 0.9887 - val_dice_coefficient: 0.7299 - val_loss: 0.2896 - val_mean_io_u_1: 0.5066 - val_precision: 0.8257 - val_recall: 0.6806 - val_specificity: 0.9989\n",
            "Epoch 83/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.6929 - auc: 0.9913 - dice_coef_oc: 0.9850 - dice_coef_od: 0.9884 - dice_coefficient: 0.9220 - loss: 0.0831 - mean_io_u_1: 0.6275 - precision: 0.9205 - recall: 0.9339 - specificity: 0.9994 - val_accuracy: 0.7340 - val_auc: 0.9533 - val_dice_coef_oc: 0.9847 - val_dice_coef_od: 0.9886 - val_dice_coefficient: 0.8113 - val_loss: 0.2092 - val_mean_io_u_1: 0.6033 - val_precision: 0.8008 - val_recall: 0.8308 - val_specificity: 0.9983\n",
            "Epoch 84/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.6859 - auc: 0.9931 - dice_coef_oc: 0.9849 - dice_coef_od: 0.9885 - dice_coefficient: 0.9283 - loss: 0.0761 - mean_io_u_1: 0.6296 - precision: 0.9284 - recall: 0.9388 - specificity: 0.9994 - val_accuracy: 0.6705 - val_auc: 0.9124 - val_dice_coef_oc: 0.9852 - val_dice_coef_od: 0.9888 - val_dice_coefficient: 0.7453 - val_loss: 0.2763 - val_mean_io_u_1: 0.5195 - val_precision: 0.8506 - val_recall: 0.6830 - val_specificity: 0.9990\n",
            "Epoch 85/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.6809 - auc: 0.9911 - dice_coef_oc: 0.9853 - dice_coef_od: 0.9889 - dice_coefficient: 0.9232 - loss: 0.0820 - mean_io_u_1: 0.6309 - precision: 0.9230 - recall: 0.9334 - specificity: 0.9994 - val_accuracy: 0.7157 - val_auc: 0.9327 - val_dice_coef_oc: 0.9854 - val_dice_coef_od: 0.9890 - val_dice_coefficient: 0.7711 - val_loss: 0.2514 - val_mean_io_u_1: 0.5341 - val_precision: 0.7987 - val_recall: 0.7596 - val_specificity: 0.9985\n",
            "Epoch 86/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.6738 - auc: 0.9922 - dice_coef_oc: 0.9852 - dice_coef_od: 0.9889 - dice_coefficient: 0.9270 - loss: 0.0776 - mean_io_u_1: 0.6328 - precision: 0.9276 - recall: 0.9370 - specificity: 0.9994 - val_accuracy: 0.7067 - val_auc: 0.9464 - val_dice_coef_oc: 0.9858 - val_dice_coef_od: 0.9893 - val_dice_coefficient: 0.8039 - val_loss: 0.2158 - val_mean_io_u_1: 0.5604 - val_precision: 0.8224 - val_recall: 0.7990 - val_specificity: 0.9986\n",
            "Epoch 87/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.6698 - auc: 0.9922 - dice_coef_oc: 0.9857 - dice_coef_od: 0.9891 - dice_coefficient: 0.9288 - loss: 0.0758 - mean_io_u_1: 0.6440 - precision: 0.9289 - recall: 0.9384 - specificity: 0.9994 - val_accuracy: 0.6981 - val_auc: 0.9452 - val_dice_coef_oc: 0.9865 - val_dice_coef_od: 0.9896 - val_dice_coefficient: 0.7879 - val_loss: 0.2315 - val_mean_io_u_1: 0.5393 - val_precision: 0.7973 - val_recall: 0.7948 - val_specificity: 0.9984\n",
            "Epoch 88/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6626 - auc: 0.9930 - dice_coef_oc: 0.9860 - dice_coef_od: 0.9895 - dice_coefficient: 0.9306 - loss: 0.0736 - mean_io_u_1: 0.6389 - precision: 0.9317 - recall: 0.9405 - specificity: 0.9994 - val_accuracy: 0.7162 - val_auc: 0.9357 - val_dice_coef_oc: 0.9859 - val_dice_coef_od: 0.9898 - val_dice_coefficient: 0.7958 - val_loss: 0.2246 - val_mean_io_u_1: 0.5470 - val_precision: 0.8360 - val_recall: 0.7695 - val_specificity: 0.9988\n",
            "Epoch 89/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.6582 - auc: 0.9922 - dice_coef_oc: 0.9863 - dice_coef_od: 0.9898 - dice_coefficient: 0.9293 - loss: 0.0753 - mean_io_u_1: 0.6474 - precision: 0.9301 - recall: 0.9389 - specificity: 0.9994 - val_accuracy: 0.7125 - val_auc: 0.9439 - val_dice_coef_oc: 0.9867 - val_dice_coef_od: 0.9900 - val_dice_coefficient: 0.8077 - val_loss: 0.2134 - val_mean_io_u_1: 0.5875 - val_precision: 0.8246 - val_recall: 0.8009 - val_specificity: 0.9986\n",
            "Epoch 90/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.6540 - auc: 0.9923 - dice_coef_oc: 0.9864 - dice_coef_od: 0.9899 - dice_coefficient: 0.9297 - loss: 0.0750 - mean_io_u_1: 0.6493 - precision: 0.9285 - recall: 0.9398 - specificity: 0.9994 - val_accuracy: 0.6395 - val_auc: 0.9371 - val_dice_coef_oc: 0.9866 - val_dice_coef_od: 0.9902 - val_dice_coefficient: 0.7945 - val_loss: 0.2266 - val_mean_io_u_1: 0.5675 - val_precision: 0.8323 - val_recall: 0.7739 - val_specificity: 0.9988\n",
            "Epoch 91/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.6471 - auc: 0.9924 - dice_coef_oc: 0.9870 - dice_coef_od: 0.9902 - dice_coefficient: 0.9317 - loss: 0.0726 - mean_io_u_1: 0.6543 - precision: 0.9319 - recall: 0.9411 - specificity: 0.9995 - val_accuracy: 0.5748 - val_auc: 0.9394 - val_dice_coef_oc: 0.9874 - val_dice_coef_od: 0.9904 - val_dice_coefficient: 0.7979 - val_loss: 0.2228 - val_mean_io_u_1: 0.5935 - val_precision: 0.8238 - val_recall: 0.7873 - val_specificity: 0.9987\n",
            "Epoch 92/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.6416 - auc: 0.9931 - dice_coef_oc: 0.9870 - dice_coef_od: 0.9901 - dice_coefficient: 0.9330 - loss: 0.0713 - mean_io_u_1: 0.6583 - precision: 0.9322 - recall: 0.9433 - specificity: 0.9995 - val_accuracy: 0.6818 - val_auc: 0.9267 - val_dice_coef_oc: 0.9870 - val_dice_coef_od: 0.9904 - val_dice_coefficient: 0.7785 - val_loss: 0.2406 - val_mean_io_u_1: 0.5157 - val_precision: 0.8616 - val_recall: 0.7266 - val_specificity: 0.9991\n",
            "Epoch 93/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.6341 - auc: 0.9926 - dice_coef_oc: 0.9871 - dice_coef_od: 0.9904 - dice_coefficient: 0.9344 - loss: 0.0698 - mean_io_u_1: 0.6533 - precision: 0.9373 - recall: 0.9405 - specificity: 0.9995 - val_accuracy: 0.6914 - val_auc: 0.9488 - val_dice_coef_oc: 0.9872 - val_dice_coef_od: 0.9905 - val_dice_coefficient: 0.8108 - val_loss: 0.2104 - val_mean_io_u_1: 0.6070 - val_precision: 0.8023 - val_recall: 0.8253 - val_specificity: 0.9984\n",
            "Epoch 94/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.6318 - auc: 0.9933 - dice_coef_oc: 0.9871 - dice_coef_od: 0.9905 - dice_coefficient: 0.9349 - loss: 0.0691 - mean_io_u_1: 0.6645 - precision: 0.9359 - recall: 0.9448 - specificity: 0.9995 - val_accuracy: 0.6083 - val_auc: 0.9415 - val_dice_coef_oc: 0.9873 - val_dice_coef_od: 0.9907 - val_dice_coefficient: 0.8009 - val_loss: 0.2189 - val_mean_io_u_1: 0.5662 - val_precision: 0.8278 - val_recall: 0.7907 - val_specificity: 0.9987\n",
            "Epoch 95/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.6250 - auc: 0.9921 - dice_coef_oc: 0.9875 - dice_coef_od: 0.9907 - dice_coefficient: 0.9324 - loss: 0.0720 - mean_io_u_1: 0.6632 - precision: 0.9334 - recall: 0.9408 - specificity: 0.9995 - val_accuracy: 0.7007 - val_auc: 0.9413 - val_dice_coef_oc: 0.9875 - val_dice_coef_od: 0.9909 - val_dice_coefficient: 0.7826 - val_loss: 0.2382 - val_mean_io_u_1: 0.5529 - val_precision: 0.7897 - val_recall: 0.7874 - val_specificity: 0.9983\n",
            "Epoch 96/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.6181 - auc: 0.9932 - dice_coef_oc: 0.9874 - dice_coef_od: 0.9908 - dice_coefficient: 0.9366 - loss: 0.0673 - mean_io_u_1: 0.6667 - precision: 0.9374 - recall: 0.9453 - specificity: 0.9995 - val_accuracy: 0.5582 - val_auc: 0.9243 - val_dice_coef_oc: 0.9878 - val_dice_coef_od: 0.9910 - val_dice_coefficient: 0.7850 - val_loss: 0.2370 - val_mean_io_u_1: 0.5720 - val_precision: 0.8537 - val_recall: 0.7429 - val_specificity: 0.9990\n",
            "Epoch 97/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.6132 - auc: 0.9934 - dice_coef_oc: 0.9879 - dice_coef_od: 0.9910 - dice_coefficient: 0.9368 - loss: 0.0672 - mean_io_u_1: 0.6690 - precision: 0.9377 - recall: 0.9447 - specificity: 0.9995 - val_accuracy: 0.6422 - val_auc: 0.9419 - val_dice_coef_oc: 0.9879 - val_dice_coef_od: 0.9911 - val_dice_coefficient: 0.8020 - val_loss: 0.2194 - val_mean_io_u_1: 0.5961 - val_precision: 0.8145 - val_recall: 0.8009 - val_specificity: 0.9985\n",
            "Epoch 98/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.6080 - auc: 0.9936 - dice_coef_oc: 0.9879 - dice_coef_od: 0.9910 - dice_coefficient: 0.9393 - loss: 0.0644 - mean_io_u_1: 0.6712 - precision: 0.9420 - recall: 0.9457 - specificity: 0.9995 - val_accuracy: 0.6676 - val_auc: 0.9243 - val_dice_coef_oc: 0.9873 - val_dice_coef_od: 0.9910 - val_dice_coefficient: 0.7833 - val_loss: 0.2369 - val_mean_io_u_1: 0.5246 - val_precision: 0.8619 - val_recall: 0.7310 - val_specificity: 0.9991\n",
            "Epoch 99/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.6023 - auc: 0.9929 - dice_coef_oc: 0.9882 - dice_coef_od: 0.9911 - dice_coefficient: 0.9366 - loss: 0.0674 - mean_io_u_1: 0.6777 - precision: 0.9385 - recall: 0.9435 - specificity: 0.9995 - val_accuracy: 0.6241 - val_auc: 0.9473 - val_dice_coef_oc: 0.9882 - val_dice_coef_od: 0.9912 - val_dice_coefficient: 0.8123 - val_loss: 0.2088 - val_mean_io_u_1: 0.6002 - val_precision: 0.8125 - val_recall: 0.8208 - val_specificity: 0.9985\n",
            "Epoch 100/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5994 - auc: 0.9937 - dice_coef_oc: 0.9884 - dice_coef_od: 0.9913 - dice_coefficient: 0.9388 - loss: 0.0650 - mean_io_u_1: 0.6771 - precision: 0.9406 - recall: 0.9466 - specificity: 0.9995 - val_accuracy: 0.6334 - val_auc: 0.9465 - val_dice_coef_oc: 0.9888 - val_dice_coef_od: 0.9914 - val_dice_coefficient: 0.8142 - val_loss: 0.2062 - val_mean_io_u_1: 0.6032 - val_precision: 0.8213 - val_recall: 0.8177 - val_specificity: 0.9986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.save_weights('cupandDisctrainedcnn_new.weights.h5')"
      ],
      "metadata": {
        "id": "es5QXnwdxsdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNVQQe05wp1e",
        "outputId": "ce86a458-3368-462d-d4d0-687b01dcb267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.6280 - auc: 0.9353 - dice_coef_oc: 0.8524 - dice_coef_od: 0.8828 - dice_coefficient: 0.8018 - loss: 0.2223 - mean_io_u_1: 0.5945 - precision: 0.8152 - recall: 0.7948 - specificity: 0.9985\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22023963928222656,\n",
              " 0.6332492232322693,\n",
              " 0.5968958735466003,\n",
              " 0.8025588989257812,\n",
              " 0.888976514339447,\n",
              " 0.85968416929245,\n",
              " 0.9985803961753845,\n",
              " 0.7940084934234619,\n",
              " 0.9347620010375977,\n",
              " 0.8184954524040222]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T=x_test[0]\n",
        "T=np.expand_dims(T,axis=0)\n",
        "out2=m.predict(T)\n",
        "\n",
        "y_test[0].shape"
      ],
      "metadata": {
        "id": "gXLpaV6mQnBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18bbc624-e295-44b0-e290-71f7263b184c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(out2)"
      ],
      "metadata": {
        "id": "Rspt5wXHnktY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a9d4d8-2768-4716-88ab-ae88d35858de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.5383386e-21, 2.0111619e-20, 2.6946631e-20, ..., 9.9999976e-01,\n",
              "       9.9999988e-01, 1.0000000e+00], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(out2[0][:,:,0]>0.8, cmap='gray')  # Channel 0\n",
        "ax[1].imshow(out2[0][:,:,1]>0.8, cmap='gray')  # Channel 1\n",
        "# Channel 2\n",
        "# ax[2].imshow(y_test[0][:,:,2], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "PB7_Ipf_efQc",
        "outputId": "16b20697-c9b4-483a-d30e-e2a52950e242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tgu2PG-g0_Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##model2"
      ],
      "metadata": {
        "id": "PsHI7cBZ7gxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_inception_spiking_model2(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial Conv Layer\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Inception Module 1\n",
        "    x = inception_module(x, filters=[64, 96, 128, 16, 32, 32])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = SpikingNeuronLayer()(x)  # Add spiking layer\n",
        "\n",
        "    # Inception Module 2\n",
        "    x = inception_module(x, filters=[128, 128, 192, 32, 96, 64])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = SpikingNeuronLayer()(x)  # Add spiking layer\n",
        "\n",
        "    # Inception Module 3\n",
        "    x = inception_module(x, filters=[192, 96, 208, 16, 48, 64])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = SpikingNeuronLayer()(x)  # Add spiking layer\n",
        "\n",
        "    # Decoder (Upsample back to 256x256)\n",
        "    x = layers.Conv2DTranspose(192, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    # x = SpikingNeuronLayer()(x)  # Add spiking layer\n",
        "\n",
        "    x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    # x = SpikingNeuronLayer()(x)  # Add spiking layer\n",
        "\n",
        "    x = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    # x = SpikingNeuronLayer()(x)  # Add spiking layer\n",
        "\n",
        "    x = layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    # x = SpikingNeuronLayer()(x)  # Add spiking layer\n",
        "\n",
        "    # Final output\n",
        "    outputs = layers.Conv2D(2, (1, 1), activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create the model with spiking layers\n",
        "inception_spiking_model2 = create_inception_spiking_model2(input_shape=(256, 256, 3))\n",
        "inception_spiking_model2.summary()\n",
        "\n",
        "m2 = inception_spiking_model2"
      ],
      "metadata": {
        "id": "jmVPHwNaelet",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "4476afd4-19e6-4caf-90b9-2e38800572fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_1              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                      \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                                              \n",
              "\n",
              " conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m896\u001b[0m  input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " batch_normalization_8      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m128\u001b[0m  conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " max_pooling2d_7            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  batch_normalization_8 \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m96\u001b[0m)             \u001b[38;5;34m3,168\u001b[0m  max_pooling2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)               \u001b[38;5;34m528\u001b[0m  max_pooling2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " max_pooling2d_8            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  max_pooling2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m2,112\u001b[0m  max_pooling2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m110,720\u001b[0m  conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)            \u001b[38;5;34m12,832\u001b[0m  conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)             \u001b[38;5;34m1,056\u001b[0m  max_pooling2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " concatenate_3              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m0\u001b[0m  conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                                      conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "                                                                    conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "                                                                    conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " batch_normalization_9      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)            \u001b[38;5;34m1,024\u001b[0m  concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " max_pooling2d_9            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  batch_normalization_9 \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " spiking_neuron_layer       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  max_pooling2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mSpikingNeuronLayer\u001b[0m)                                                                      \n",
              "\n",
              " conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m32,896\u001b[0m  spiking_neuron_layer[\u001b[38;5;34m\u001b[0m \n",
              "\n",
              " conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m8,224\u001b[0m  spiking_neuron_layer[\u001b[38;5;34m\u001b[0m \n",
              "\n",
              " max_pooling2d_10           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  spiking_neuron_layer[\u001b[38;5;34m\u001b[0m \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m32,896\u001b[0m  spiking_neuron_layer[\u001b[38;5;34m\u001b[0m \n",
              "\n",
              " conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m192\u001b[0m)            \u001b[38;5;34m221,376\u001b[0m  conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m)              \u001b[38;5;34m76,896\u001b[0m  conv2d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)              \u001b[38;5;34m16,448\u001b[0m  max_pooling2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " concatenate_4              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m480\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                                      conv2d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "                                                                    conv2d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "                                                                    conv2d_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " batch_normalization_10     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m480\u001b[0m)              \u001b[38;5;34m1,920\u001b[0m  concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " max_pooling2d_11           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m480\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  batch_normalization_1 \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " spiking_neuron_layer_1     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m480\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  max_pooling2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mSpikingNeuronLayer\u001b[0m)                                                                      \n",
              "\n",
              " conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m96\u001b[0m)              \u001b[38;5;34m46,176\u001b[0m  spiking_neuron_layer_ \n",
              "\n",
              " conv2d_36 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)               \u001b[38;5;34m7,696\u001b[0m  spiking_neuron_layer_ \n",
              "\n",
              " max_pooling2d_12           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m480\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  spiking_neuron_layer_ \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m192\u001b[0m)             \u001b[38;5;34m92,352\u001b[0m  spiking_neuron_layer_ \n",
              "\n",
              " conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m208\u001b[0m)            \u001b[38;5;34m179,920\u001b[0m  conv2d_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " conv2d_37 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m)              \u001b[38;5;34m19,248\u001b[0m  conv2d_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " conv2d_38 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)              \u001b[38;5;34m30,784\u001b[0m  max_pooling2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " concatenate_5              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  conv2d_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                                      conv2d_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "                                                                    conv2d_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "                                                                    conv2d_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " batch_normalization_11     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)              \u001b[38;5;34m2,048\u001b[0m  concatenate_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " max_pooling2d_13           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  batch_normalization_1 \n",
              " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                            \n",
              "\n",
              " spiking_neuron_layer_2     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  max_pooling2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mSpikingNeuronLayer\u001b[0m)                                                                      \n",
              "\n",
              " conv2d_transpose_4         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m192\u001b[0m)            \u001b[38;5;34m884,928\u001b[0m  spiking_neuron_layer_ \n",
              " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                         \n",
              "\n",
              " batch_normalization_12     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m192\u001b[0m)                \u001b[38;5;34m768\u001b[0m  conv2d_transpose_4[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " conv2d_transpose_5         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m221,312\u001b[0m  batch_normalization_1 \n",
              " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                         \n",
              "\n",
              " batch_normalization_13     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m512\u001b[0m  conv2d_transpose_5[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " conv2d_transpose_6         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m73,792\u001b[0m  batch_normalization_1 \n",
              " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                         \n",
              "\n",
              " batch_normalization_14     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)               \u001b[38;5;34m256\u001b[0m  conv2d_transpose_6[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " conv2d_transpose_7         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)            \u001b[38;5;34m18,464\u001b[0m  batch_normalization_1 \n",
              " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                         \n",
              "\n",
              " batch_normalization_15     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m128\u001b[0m  conv2d_transpose_7[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                      \n",
              "\n",
              " conv2d_39 (\u001b[38;5;33mConv2D\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 \u001b[38;5;34m66\u001b[0m  batch_normalization_1 \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)              </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">        Param # </span><span style=\"font-weight: bold\"> Connected to           </span>\n",
              "\n",
              " input_layer_1              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                                              \n",
              "\n",
              " conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>  input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " batch_normalization_8      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " max_pooling2d_7            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_8 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span>  max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span>  max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " max_pooling2d_8            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span>  max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">110,720</span>  conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">12,832</span>  conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span>  max_pooling2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " concatenate_3              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                                      conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "                                                                    conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "                                                                    conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " batch_normalization_9      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " max_pooling2d_9            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_9 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " spiking_neuron_layer       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  max_pooling2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpikingNeuronLayer</span>)                                                                      \n",
              "\n",
              " conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span>  spiking_neuron_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "\n",
              " conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span>  spiking_neuron_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "\n",
              " max_pooling2d_10           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  spiking_neuron_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span>  spiking_neuron_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "\n",
              " conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">221,376</span>  conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">76,896</span>  conv2d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span>  max_pooling2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " concatenate_4              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                                      conv2d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "                                                                    conv2d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "                                                                    conv2d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " batch_normalization_10     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span>  concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " max_pooling2d_11           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_1 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " spiking_neuron_layer_1     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  max_pooling2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpikingNeuronLayer</span>)                                                                      \n",
              "\n",
              " conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">46,176</span>  spiking_neuron_layer_ \n",
              "\n",
              " conv2d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">7,696</span>  spiking_neuron_layer_ \n",
              "\n",
              " max_pooling2d_12           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  spiking_neuron_layer_ \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">92,352</span>  spiking_neuron_layer_ \n",
              "\n",
              " conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">179,920</span>  conv2d_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " conv2d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">19,248</span>  conv2d_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " conv2d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">30,784</span>  max_pooling2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " concatenate_5              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                                      conv2d_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "                                                                    conv2d_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "                                                                    conv2d_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " batch_normalization_11     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " max_pooling2d_13           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_1 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                            \n",
              "\n",
              " spiking_neuron_layer_2     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  max_pooling2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpikingNeuronLayer</span>)                                                                      \n",
              "\n",
              " conv2d_transpose_4         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">884,928</span>  spiking_neuron_layer_ \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                         \n",
              "\n",
              " batch_normalization_12     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>  conv2d_transpose_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " conv2d_transpose_5         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span>  batch_normalization_1 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                         \n",
              "\n",
              " batch_normalization_13     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv2d_transpose_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " conv2d_transpose_6         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span>  batch_normalization_1 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                         \n",
              "\n",
              " batch_normalization_14     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_transpose_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " conv2d_transpose_7         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span>  batch_normalization_1 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                         \n",
              "\n",
              " batch_normalization_15     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv2d_transpose_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                      \n",
              "\n",
              " conv2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>  batch_normalization_1 \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,101,570\u001b[0m (8.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,101,570</span> (8.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,098,178\u001b[0m (8.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,178</span> (8.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,392\u001b[0m (13.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,392</span> (13.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the weights are in your Google Drive under 'MyDrive/model_weights'\n",
        "m2.load_weights('/content/cupandDisctrainedcnn_new.weights.h5')"
      ],
      "metadata": {
        "id": "62D0TWCv1Epp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###training"
      ],
      "metadata": {
        "id": "JjfkAwlY7tXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dice Coefficient (You already have this)'''\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "    return numerator / (denominator + 1e-7)\n",
        "\n",
        "# Specificity (True Negative Rate)\n",
        "# def specificity(y_true, y_pred):\n",
        "#     true_negatives = tf.reduce_sum(tf.cast((y_true == 0) & (y_pred == 0), tf.float32))\n",
        "#     false_positives = tf.reduce_sum(tf.cast((y_true == 0) & (y_pred == 1), tf.float32))\n",
        "#     specificity_value = true_negatives / (true_negatives + false_positives + 1e-7)\n",
        "#     return specificity_value\n",
        "\n",
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())\n",
        "\n",
        "# Sensitivity (True Positive Rate), using Keras' Recall metric\n",
        "from tensorflow.keras.metrics import Recall as sensitivity\n",
        "\n",
        "# IoU (Intersection over Union), using Keras' MeanIoU metric\n",
        "iou = tf.keras.metrics.MeanIoU(num_classes=2)\n",
        "\n",
        "# AUC (Area Under the Curve), using Keras' AUC metric\n",
        "auc = tf.keras.metrics.AUC()\n",
        "\n",
        "# Precision, using Keras' Precision metric\n",
        "precision = tf.keras.metrics.Precision()\n",
        "\n",
        "# Compile the model with all the metrics\n",
        "m2.compile(optimizer='sgd',\n",
        "          loss=bce_dice_loss,\n",
        "          metrics=[\n",
        "              'accuracy',              # Overall accuracy\n",
        "              iou,                     # Intersection over Union\n",
        "              dice_coefficient,         # Dice Coefficient\n",
        "              dice_coef_OD,             # Assuming these are defined elsewhere\n",
        "              dice_coef_OC,             # Assuming these are defined elsewhere\n",
        "              specificity,              # Custom specificity function\n",
        "              sensitivity(),            # Sensitivity (Recall)\n",
        "              auc,                      # Area Under the Curve\n",
        "              precision                 # Precision\n",
        "          ])\n"
      ],
      "metadata": {
        "id": "dfpyj6hnuzQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def dice_loss(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return 1 - ((2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth))\n",
        "\n",
        "def overall_dice_coef(y_true, y_pred, smooth=1):\n",
        "    \"\"\"\n",
        "    Calculates the overall Dice coefficient as the average of\n",
        "    Dice coefficients for optic disc (OD) and optic cup (OC).\n",
        "    \"\"\"\n",
        "    dice_od = dice_coef_OD(y_true, y_pred, smooth)\n",
        "    dice_oc = dice_coef_OC(y_true, y_pred, smooth)\n",
        "    return (dice_od + dice_oc) / 2.0\n",
        "\n",
        "def dice_coef_OD(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true[:,:,0])\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred[:,:,0])\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_OC(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true[:,:,1])\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred[:,:,1])\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n"
      ],
      "metadata": {
        "id": "yE2Pd4SUcpvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = m2.fit(x_train_1, y_train_1, batch_size=2, epochs=150, validation_data = (x_val, y_val))\n"
      ],
      "metadata": {
        "id": "OTgEUiI4m6dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "907dcc85-bde6-45c1-d79c-64b80fffffec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:678: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.5570 - auc_1: 0.8622 - dice_coef_oc: 0.9583 - dice_coef_od: 0.9768 - dice_coefficient: 0.4197 - loss: 0.6393 - mean_io_u_2: 0.5142 - precision_1: 0.3784 - recall_1: 0.5104 - specificity: 0.9934 - val_accuracy: 0.6913 - val_auc_1: 0.7378 - val_dice_coef_oc: 0.9675 - val_dice_coef_od: 0.9761 - val_dice_coefficient: 0.1682 - val_loss: 0.8772 - val_mean_io_u_2: 0.4960 - val_precision_1: 0.5752 - val_recall_1: 0.0843 - val_specificity: 0.9995\n",
            "Epoch 2/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.5756 - auc_1: 0.9287 - dice_coef_oc: 0.9623 - dice_coef_od: 0.9720 - dice_coefficient: 0.5600 - loss: 0.4793 - mean_io_u_2: 0.5314 - precision_1: 0.5065 - recall_1: 0.6632 - specificity: 0.9948 - val_accuracy: 0.6378 - val_auc_1: 0.9164 - val_dice_coef_oc: 0.9619 - val_dice_coef_od: 0.9726 - val_dice_coefficient: 0.5317 - val_loss: 0.5079 - val_mean_io_u_2: 0.5454 - val_precision_1: 0.4912 - val_recall_1: 0.6067 - val_specificity: 0.9950\n",
            "Epoch 3/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.5821 - auc_1: 0.9390 - dice_coef_oc: 0.9588 - dice_coef_od: 0.9712 - dice_coefficient: 0.6140 - loss: 0.4196 - mean_io_u_2: 0.5382 - precision_1: 0.5663 - recall_1: 0.7007 - specificity: 0.9957 - val_accuracy: 0.5761 - val_auc_1: 0.9148 - val_dice_coef_oc: 0.9701 - val_dice_coef_od: 0.9736 - val_dice_coefficient: 0.5933 - val_loss: 0.4453 - val_mean_io_u_2: 0.5381 - val_precision_1: 0.5584 - val_recall_1: 0.6578 - val_specificity: 0.9958\n",
            "Epoch 4/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5828 - auc_1: 0.9335 - dice_coef_oc: 0.9612 - dice_coef_od: 0.9725 - dice_coefficient: 0.6256 - loss: 0.4070 - mean_io_u_2: 0.5383 - precision_1: 0.5856 - recall_1: 0.6979 - specificity: 0.9961 - val_accuracy: 0.5928 - val_auc_1: 0.9288 - val_dice_coef_oc: 0.9683 - val_dice_coef_od: 0.9737 - val_dice_coefficient: 0.5977 - val_loss: 0.4460 - val_mean_io_u_2: 0.5621 - val_precision_1: 0.5281 - val_recall_1: 0.7079 - val_specificity: 0.9949\n",
            "Epoch 5/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.5818 - auc_1: 0.9458 - dice_coef_oc: 0.9618 - dice_coef_od: 0.9725 - dice_coefficient: 0.6500 - loss: 0.3805 - mean_io_u_2: 0.5345 - precision_1: 0.6008 - recall_1: 0.7362 - specificity: 0.9961 - val_accuracy: 0.5832 - val_auc_1: 0.9214 - val_dice_coef_oc: 0.9675 - val_dice_coef_od: 0.9728 - val_dice_coefficient: 0.6141 - val_loss: 0.4239 - val_mean_io_u_2: 0.5480 - val_precision_1: 0.5682 - val_recall_1: 0.6877 - val_specificity: 0.9958\n",
            "Epoch 6/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.5835 - auc_1: 0.9419 - dice_coef_oc: 0.9637 - dice_coef_od: 0.9735 - dice_coefficient: 0.6501 - loss: 0.3797 - mean_io_u_2: 0.5320 - precision_1: 0.6050 - recall_1: 0.7268 - specificity: 0.9962 - val_accuracy: 0.5844 - val_auc_1: 0.9416 - val_dice_coef_oc: 0.9717 - val_dice_coef_od: 0.9764 - val_dice_coefficient: 0.6259 - val_loss: 0.4164 - val_mean_io_u_2: 0.5616 - val_precision_1: 0.5361 - val_recall_1: 0.7643 - val_specificity: 0.9947\n",
            "Epoch 7/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.5796 - auc_1: 0.9466 - dice_coef_oc: 0.9679 - dice_coef_od: 0.9750 - dice_coefficient: 0.6615 - loss: 0.3666 - mean_io_u_2: 0.5321 - precision_1: 0.6148 - recall_1: 0.7407 - specificity: 0.9964 - val_accuracy: 0.5857 - val_auc_1: 0.9349 - val_dice_coef_oc: 0.9726 - val_dice_coef_od: 0.9753 - val_dice_coefficient: 0.6186 - val_loss: 0.4218 - val_mean_io_u_2: 0.5608 - val_precision_1: 0.5442 - val_recall_1: 0.7339 - val_specificity: 0.9951\n",
            "Epoch 8/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.5789 - auc_1: 0.9515 - dice_coef_oc: 0.9702 - dice_coef_od: 0.9757 - dice_coefficient: 0.6764 - loss: 0.3501 - mean_io_u_2: 0.5317 - precision_1: 0.6307 - recall_1: 0.7543 - specificity: 0.9965 - val_accuracy: 0.5705 - val_auc_1: 0.9422 - val_dice_coef_oc: 0.9749 - val_dice_coef_od: 0.9776 - val_dice_coefficient: 0.6165 - val_loss: 0.4276 - val_mean_io_u_2: 0.5620 - val_precision_1: 0.5214 - val_recall_1: 0.7677 - val_specificity: 0.9944\n",
            "Epoch 9/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.5756 - auc_1: 0.9486 - dice_coef_oc: 0.9715 - dice_coef_od: 0.9765 - dice_coefficient: 0.6686 - loss: 0.3597 - mean_io_u_2: 0.5289 - precision_1: 0.6211 - recall_1: 0.7476 - specificity: 0.9963 - val_accuracy: 0.5822 - val_auc_1: 0.9248 - val_dice_coef_oc: 0.9757 - val_dice_coef_od: 0.9779 - val_dice_coefficient: 0.6305 - val_loss: 0.4058 - val_mean_io_u_2: 0.5403 - val_precision_1: 0.5891 - val_recall_1: 0.6969 - val_specificity: 0.9961\n",
            "Epoch 10/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.5733 - auc_1: 0.9505 - dice_coef_oc: 0.9729 - dice_coef_od: 0.9773 - dice_coefficient: 0.6781 - loss: 0.3486 - mean_io_u_2: 0.5258 - precision_1: 0.6372 - recall_1: 0.7499 - specificity: 0.9965 - val_accuracy: 0.5740 - val_auc_1: 0.9104 - val_dice_coef_oc: 0.9762 - val_dice_coef_od: 0.9790 - val_dice_coefficient: 0.6206 - val_loss: 0.4124 - val_mean_io_u_2: 0.5306 - val_precision_1: 0.6148 - val_recall_1: 0.6455 - val_specificity: 0.9968\n",
            "Epoch 11/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.5727 - auc_1: 0.9426 - dice_coef_oc: 0.9739 - dice_coef_od: 0.9781 - dice_coefficient: 0.6618 - loss: 0.3668 - mean_io_u_2: 0.5243 - precision_1: 0.6245 - recall_1: 0.7293 - specificity: 0.9964 - val_accuracy: 0.5744 - val_auc_1: 0.9194 - val_dice_coef_oc: 0.9780 - val_dice_coef_od: 0.9782 - val_dice_coefficient: 0.6315 - val_loss: 0.4023 - val_mean_io_u_2: 0.5364 - val_precision_1: 0.6074 - val_recall_1: 0.6816 - val_specificity: 0.9965\n",
            "Epoch 12/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.5677 - auc_1: 0.9509 - dice_coef_oc: 0.9756 - dice_coef_od: 0.9784 - dice_coefficient: 0.6843 - loss: 0.3422 - mean_io_u_2: 0.5254 - precision_1: 0.6436 - recall_1: 0.7544 - specificity: 0.9967 - val_accuracy: 0.5604 - val_auc_1: 0.9406 - val_dice_coef_oc: 0.9791 - val_dice_coef_od: 0.9785 - val_dice_coefficient: 0.6342 - val_loss: 0.4030 - val_mean_io_u_2: 0.5463 - val_precision_1: 0.5525 - val_recall_1: 0.7537 - val_specificity: 0.9951\n",
            "Epoch 13/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.5631 - auc_1: 0.9453 - dice_coef_oc: 0.9767 - dice_coef_od: 0.9791 - dice_coefficient: 0.6796 - loss: 0.3465 - mean_io_u_2: 0.5216 - precision_1: 0.6446 - recall_1: 0.7441 - specificity: 0.9967 - val_accuracy: 0.5356 - val_auc_1: 0.9320 - val_dice_coef_oc: 0.9795 - val_dice_coef_od: 0.9802 - val_dice_coefficient: 0.6493 - val_loss: 0.3838 - val_mean_io_u_2: 0.5347 - val_precision_1: 0.6046 - val_recall_1: 0.7219 - val_specificity: 0.9962\n",
            "Epoch 14/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.5590 - auc_1: 0.9480 - dice_coef_oc: 0.9771 - dice_coef_od: 0.9791 - dice_coefficient: 0.6825 - loss: 0.3433 - mean_io_u_2: 0.5215 - precision_1: 0.6475 - recall_1: 0.7467 - specificity: 0.9968 - val_accuracy: 0.5700 - val_auc_1: 0.9266 - val_dice_coef_oc: 0.9803 - val_dice_coef_od: 0.9794 - val_dice_coefficient: 0.6360 - val_loss: 0.3998 - val_mean_io_u_2: 0.5424 - val_precision_1: 0.5875 - val_recall_1: 0.7136 - val_specificity: 0.9960\n",
            "Epoch 15/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.5559 - auc_1: 0.9527 - dice_coef_oc: 0.9776 - dice_coef_od: 0.9793 - dice_coefficient: 0.6897 - loss: 0.3356 - mean_io_u_2: 0.5250 - precision_1: 0.6518 - recall_1: 0.7570 - specificity: 0.9967 - val_accuracy: 0.5522 - val_auc_1: 0.9277 - val_dice_coef_oc: 0.9804 - val_dice_coef_od: 0.9803 - val_dice_coefficient: 0.6497 - val_loss: 0.3823 - val_mean_io_u_2: 0.5341 - val_precision_1: 0.6161 - val_recall_1: 0.7068 - val_specificity: 0.9965\n",
            "Epoch 16/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.5524 - auc_1: 0.9566 - dice_coef_oc: 0.9781 - dice_coef_od: 0.9797 - dice_coefficient: 0.6979 - loss: 0.3260 - mean_io_u_2: 0.5252 - precision_1: 0.6603 - recall_1: 0.7646 - specificity: 0.9969 - val_accuracy: 0.5770 - val_auc_1: 0.9265 - val_dice_coef_oc: 0.9807 - val_dice_coef_od: 0.9801 - val_dice_coefficient: 0.6291 - val_loss: 0.4057 - val_mean_io_u_2: 0.5414 - val_precision_1: 0.5847 - val_recall_1: 0.6946 - val_specificity: 0.9961\n",
            "Epoch 17/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5488 - auc_1: 0.9541 - dice_coef_oc: 0.9790 - dice_coef_od: 0.9803 - dice_coefficient: 0.6985 - loss: 0.3254 - mean_io_u_2: 0.5186 - precision_1: 0.6651 - recall_1: 0.7616 - specificity: 0.9969 - val_accuracy: 0.5473 - val_auc_1: 0.9331 - val_dice_coef_oc: 0.9811 - val_dice_coef_od: 0.9813 - val_dice_coefficient: 0.6463 - val_loss: 0.3869 - val_mean_io_u_2: 0.5354 - val_precision_1: 0.5995 - val_recall_1: 0.7199 - val_specificity: 0.9962\n",
            "Epoch 18/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5451 - auc_1: 0.9470 - dice_coef_oc: 0.9796 - dice_coef_od: 0.9810 - dice_coefficient: 0.6716 - loss: 0.3549 - mean_io_u_2: 0.5215 - precision_1: 0.6375 - recall_1: 0.7364 - specificity: 0.9967 - val_accuracy: 0.5458 - val_auc_1: 0.9167 - val_dice_coef_oc: 0.9819 - val_dice_coef_od: 0.9811 - val_dice_coefficient: 0.6422 - val_loss: 0.3888 - val_mean_io_u_2: 0.5174 - val_precision_1: 0.6347 - val_recall_1: 0.6733 - val_specificity: 0.9969\n",
            "Epoch 19/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.5403 - auc_1: 0.9510 - dice_coef_oc: 0.9802 - dice_coef_od: 0.9811 - dice_coefficient: 0.6888 - loss: 0.3361 - mean_io_u_2: 0.5160 - precision_1: 0.6550 - recall_1: 0.7486 - specificity: 0.9969 - val_accuracy: 0.5433 - val_auc_1: 0.9271 - val_dice_coef_oc: 0.9821 - val_dice_coef_od: 0.9806 - val_dice_coefficient: 0.6423 - val_loss: 0.3892 - val_mean_io_u_2: 0.5306 - val_precision_1: 0.6162 - val_recall_1: 0.6900 - val_specificity: 0.9966\n",
            "Epoch 20/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5405 - auc_1: 0.9541 - dice_coef_oc: 0.9802 - dice_coef_od: 0.9809 - dice_coefficient: 0.6891 - loss: 0.3355 - mean_io_u_2: 0.5188 - precision_1: 0.6504 - recall_1: 0.7573 - specificity: 0.9968 - val_accuracy: 0.5535 - val_auc_1: 0.9285 - val_dice_coef_oc: 0.9822 - val_dice_coef_od: 0.9807 - val_dice_coefficient: 0.6364 - val_loss: 0.3956 - val_mean_io_u_2: 0.5241 - val_precision_1: 0.6001 - val_recall_1: 0.6946 - val_specificity: 0.9963\n",
            "Epoch 21/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5366 - auc_1: 0.9575 - dice_coef_oc: 0.9807 - dice_coef_od: 0.9814 - dice_coefficient: 0.7028 - loss: 0.3198 - mean_io_u_2: 0.5151 - precision_1: 0.6661 - recall_1: 0.7698 - specificity: 0.9970 - val_accuracy: 0.5378 - val_auc_1: 0.9388 - val_dice_coef_oc: 0.9830 - val_dice_coef_od: 0.9819 - val_dice_coefficient: 0.6462 - val_loss: 0.3869 - val_mean_io_u_2: 0.5341 - val_precision_1: 0.5927 - val_recall_1: 0.7327 - val_specificity: 0.9960\n",
            "Epoch 22/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.5338 - auc_1: 0.9567 - dice_coef_oc: 0.9806 - dice_coef_od: 0.9814 - dice_coefficient: 0.6983 - loss: 0.3256 - mean_io_u_2: 0.5165 - precision_1: 0.6599 - recall_1: 0.7674 - specificity: 0.9968 - val_accuracy: 0.5369 - val_auc_1: 0.9296 - val_dice_coef_oc: 0.9832 - val_dice_coef_od: 0.9823 - val_dice_coefficient: 0.6472 - val_loss: 0.3847 - val_mean_io_u_2: 0.5267 - val_precision_1: 0.6108 - val_recall_1: 0.7075 - val_specificity: 0.9964\n",
            "Epoch 23/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.5272 - auc_1: 0.9516 - dice_coef_oc: 0.9816 - dice_coef_od: 0.9820 - dice_coefficient: 0.6956 - loss: 0.3294 - mean_io_u_2: 0.5161 - precision_1: 0.6639 - recall_1: 0.7563 - specificity: 0.9969 - val_accuracy: 0.5320 - val_auc_1: 0.9356 - val_dice_coef_oc: 0.9839 - val_dice_coef_od: 0.9819 - val_dice_coefficient: 0.6511 - val_loss: 0.3816 - val_mean_io_u_2: 0.5360 - val_precision_1: 0.5984 - val_recall_1: 0.7298 - val_specificity: 0.9961\n",
            "Epoch 24/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.5242 - auc_1: 0.9562 - dice_coef_oc: 0.9818 - dice_coef_od: 0.9819 - dice_coefficient: 0.7046 - loss: 0.3185 - mean_io_u_2: 0.5174 - precision_1: 0.6673 - recall_1: 0.7688 - specificity: 0.9970 - val_accuracy: 0.5395 - val_auc_1: 0.9377 - val_dice_coef_oc: 0.9836 - val_dice_coef_od: 0.9824 - val_dice_coefficient: 0.6526 - val_loss: 0.3812 - val_mean_io_u_2: 0.5356 - val_precision_1: 0.5926 - val_recall_1: 0.7395 - val_specificity: 0.9959\n",
            "Epoch 25/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5198 - auc_1: 0.9505 - dice_coef_oc: 0.9822 - dice_coef_od: 0.9821 - dice_coefficient: 0.6884 - loss: 0.3363 - mean_io_u_2: 0.5169 - precision_1: 0.6535 - recall_1: 0.7504 - specificity: 0.9968 - val_accuracy: 0.5020 - val_auc_1: 0.9250 - val_dice_coef_oc: 0.9839 - val_dice_coef_od: 0.9818 - val_dice_coefficient: 0.6458 - val_loss: 0.3851 - val_mean_io_u_2: 0.5175 - val_precision_1: 0.6214 - val_recall_1: 0.6907 - val_specificity: 0.9966\n",
            "Epoch 26/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5191 - auc_1: 0.9524 - dice_coef_oc: 0.9825 - dice_coef_od: 0.9825 - dice_coefficient: 0.6904 - loss: 0.3342 - mean_io_u_2: 0.5126 - precision_1: 0.6574 - recall_1: 0.7521 - specificity: 0.9969 - val_accuracy: 0.5255 - val_auc_1: 0.9262 - val_dice_coef_oc: 0.9839 - val_dice_coef_od: 0.9828 - val_dice_coefficient: 0.6543 - val_loss: 0.3757 - val_mean_io_u_2: 0.5166 - val_precision_1: 0.6317 - val_recall_1: 0.6966 - val_specificity: 0.9967\n",
            "Epoch 27/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.5132 - auc_1: 0.9537 - dice_coef_oc: 0.9828 - dice_coef_od: 0.9824 - dice_coefficient: 0.7028 - loss: 0.3202 - mean_io_u_2: 0.5106 - precision_1: 0.6727 - recall_1: 0.7593 - specificity: 0.9971 - val_accuracy: 0.4995 - val_auc_1: 0.9325 - val_dice_coef_oc: 0.9839 - val_dice_coef_od: 0.9827 - val_dice_coefficient: 0.6597 - val_loss: 0.3709 - val_mean_io_u_2: 0.5273 - val_precision_1: 0.6223 - val_recall_1: 0.7200 - val_specificity: 0.9965\n",
            "Epoch 28/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5099 - auc_1: 0.9583 - dice_coef_oc: 0.9827 - dice_coef_od: 0.9823 - dice_coefficient: 0.7016 - loss: 0.3217 - mean_io_u_2: 0.5118 - precision_1: 0.6620 - recall_1: 0.7708 - specificity: 0.9969 - val_accuracy: 0.5276 - val_auc_1: 0.9361 - val_dice_coef_oc: 0.9845 - val_dice_coef_od: 0.9836 - val_dice_coefficient: 0.6598 - val_loss: 0.3694 - val_mean_io_u_2: 0.5244 - val_precision_1: 0.6248 - val_recall_1: 0.7216 - val_specificity: 0.9965\n",
            "Epoch 29/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5102 - auc_1: 0.9567 - dice_coef_oc: 0.9833 - dice_coef_od: 0.9827 - dice_coefficient: 0.7074 - loss: 0.3156 - mean_io_u_2: 0.5133 - precision_1: 0.6722 - recall_1: 0.7712 - specificity: 0.9970 - val_accuracy: 0.5079 - val_auc_1: 0.9265 - val_dice_coef_oc: 0.9846 - val_dice_coef_od: 0.9825 - val_dice_coefficient: 0.6640 - val_loss: 0.3638 - val_mean_io_u_2: 0.5170 - val_precision_1: 0.6578 - val_recall_1: 0.6902 - val_specificity: 0.9971\n",
            "Epoch 30/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5050 - auc_1: 0.9529 - dice_coef_oc: 0.9834 - dice_coef_od: 0.9828 - dice_coefficient: 0.6931 - loss: 0.3310 - mean_io_u_2: 0.5138 - precision_1: 0.6615 - recall_1: 0.7546 - specificity: 0.9969 - val_accuracy: 0.4839 - val_auc_1: 0.9216 - val_dice_coef_oc: 0.9849 - val_dice_coef_od: 0.9828 - val_dice_coefficient: 0.6422 - val_loss: 0.3912 - val_mean_io_u_2: 0.5191 - val_precision_1: 0.6136 - val_recall_1: 0.6905 - val_specificity: 0.9965\n",
            "Epoch 31/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4999 - auc_1: 0.9566 - dice_coef_oc: 0.9835 - dice_coef_od: 0.9825 - dice_coefficient: 0.7030 - loss: 0.3200 - mean_io_u_2: 0.5136 - precision_1: 0.6668 - recall_1: 0.7664 - specificity: 0.9970 - val_accuracy: 0.4819 - val_auc_1: 0.9293 - val_dice_coef_oc: 0.9850 - val_dice_coef_od: 0.9830 - val_dice_coefficient: 0.6499 - val_loss: 0.3828 - val_mean_io_u_2: 0.5227 - val_precision_1: 0.6093 - val_recall_1: 0.7123 - val_specificity: 0.9963\n",
            "Epoch 32/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.5020 - auc_1: 0.9581 - dice_coef_oc: 0.9837 - dice_coef_od: 0.9830 - dice_coefficient: 0.7064 - loss: 0.3172 - mean_io_u_2: 0.5095 - precision_1: 0.6709 - recall_1: 0.7737 - specificity: 0.9970 - val_accuracy: 0.4866 - val_auc_1: 0.9396 - val_dice_coef_oc: 0.9856 - val_dice_coef_od: 0.9834 - val_dice_coefficient: 0.6690 - val_loss: 0.3602 - val_mean_io_u_2: 0.5222 - val_precision_1: 0.6231 - val_recall_1: 0.7382 - val_specificity: 0.9964\n",
            "Epoch 33/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.5005 - auc_1: 0.9560 - dice_coef_oc: 0.9838 - dice_coef_od: 0.9831 - dice_coefficient: 0.6958 - loss: 0.3275 - mean_io_u_2: 0.5116 - precision_1: 0.6597 - recall_1: 0.7619 - specificity: 0.9969 - val_accuracy: 0.4977 - val_auc_1: 0.9362 - val_dice_coef_oc: 0.9853 - val_dice_coef_od: 0.9836 - val_dice_coefficient: 0.6592 - val_loss: 0.3719 - val_mean_io_u_2: 0.5201 - val_precision_1: 0.6115 - val_recall_1: 0.7291 - val_specificity: 0.9963\n",
            "Epoch 34/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4959 - auc_1: 0.9586 - dice_coef_oc: 0.9838 - dice_coef_od: 0.9830 - dice_coefficient: 0.7107 - loss: 0.3121 - mean_io_u_2: 0.5097 - precision_1: 0.6771 - recall_1: 0.7736 - specificity: 0.9970 - val_accuracy: 0.4805 - val_auc_1: 0.9383 - val_dice_coef_oc: 0.9853 - val_dice_coef_od: 0.9837 - val_dice_coefficient: 0.6567 - val_loss: 0.3749 - val_mean_io_u_2: 0.5186 - val_precision_1: 0.6049 - val_recall_1: 0.7333 - val_specificity: 0.9962\n",
            "Epoch 35/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4939 - auc_1: 0.9590 - dice_coef_oc: 0.9843 - dice_coef_od: 0.9833 - dice_coefficient: 0.7081 - loss: 0.3143 - mean_io_u_2: 0.5096 - precision_1: 0.6730 - recall_1: 0.7733 - specificity: 0.9970 - val_accuracy: 0.4881 - val_auc_1: 0.9314 - val_dice_coef_oc: 0.9865 - val_dice_coef_od: 0.9840 - val_dice_coefficient: 0.6482 - val_loss: 0.3834 - val_mean_io_u_2: 0.5219 - val_precision_1: 0.6071 - val_recall_1: 0.7130 - val_specificity: 0.9963\n",
            "Epoch 36/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4916 - auc_1: 0.9553 - dice_coef_oc: 0.9847 - dice_coef_od: 0.9836 - dice_coefficient: 0.7064 - loss: 0.3173 - mean_io_u_2: 0.5077 - precision_1: 0.6734 - recall_1: 0.7667 - specificity: 0.9970 - val_accuracy: 0.5120 - val_auc_1: 0.9325 - val_dice_coef_oc: 0.9861 - val_dice_coef_od: 0.9849 - val_dice_coefficient: 0.6659 - val_loss: 0.3639 - val_mean_io_u_2: 0.5215 - val_precision_1: 0.6303 - val_recall_1: 0.7189 - val_specificity: 0.9966\n",
            "Epoch 37/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4896 - auc_1: 0.9577 - dice_coef_oc: 0.9846 - dice_coef_od: 0.9837 - dice_coefficient: 0.7075 - loss: 0.3157 - mean_io_u_2: 0.5109 - precision_1: 0.6727 - recall_1: 0.7685 - specificity: 0.9970 - val_accuracy: 0.4609 - val_auc_1: 0.9242 - val_dice_coef_oc: 0.9860 - val_dice_coef_od: 0.9842 - val_dice_coefficient: 0.6589 - val_loss: 0.3701 - val_mean_io_u_2: 0.5129 - val_precision_1: 0.6475 - val_recall_1: 0.6894 - val_specificity: 0.9970\n",
            "Epoch 38/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.4878 - auc_1: 0.9569 - dice_coef_oc: 0.9849 - dice_coef_od: 0.9840 - dice_coefficient: 0.7147 - loss: 0.3077 - mean_io_u_2: 0.5088 - precision_1: 0.6824 - recall_1: 0.7719 - specificity: 0.9972 - val_accuracy: 0.4727 - val_auc_1: 0.9410 - val_dice_coef_oc: 0.9870 - val_dice_coef_od: 0.9846 - val_dice_coefficient: 0.6684 - val_loss: 0.3625 - val_mean_io_u_2: 0.5209 - val_precision_1: 0.6132 - val_recall_1: 0.7489 - val_specificity: 0.9962\n",
            "Epoch 39/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4833 - auc_1: 0.9600 - dice_coef_oc: 0.9853 - dice_coef_od: 0.9839 - dice_coefficient: 0.7207 - loss: 0.3007 - mean_io_u_2: 0.5083 - precision_1: 0.6870 - recall_1: 0.7828 - specificity: 0.9972 - val_accuracy: 0.4706 - val_auc_1: 0.9410 - val_dice_coef_oc: 0.9868 - val_dice_coef_od: 0.9846 - val_dice_coefficient: 0.6706 - val_loss: 0.3596 - val_mean_io_u_2: 0.5223 - val_precision_1: 0.6194 - val_recall_1: 0.7511 - val_specificity: 0.9963\n",
            "Epoch 40/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4799 - auc_1: 0.9568 - dice_coef_oc: 0.9854 - dice_coef_od: 0.9840 - dice_coefficient: 0.7165 - loss: 0.3058 - mean_io_u_2: 0.5082 - precision_1: 0.6871 - recall_1: 0.7702 - specificity: 0.9971 - val_accuracy: 0.4763 - val_auc_1: 0.9327 - val_dice_coef_oc: 0.9870 - val_dice_coef_od: 0.9848 - val_dice_coefficient: 0.6631 - val_loss: 0.3667 - val_mean_io_u_2: 0.5161 - val_precision_1: 0.6275 - val_recall_1: 0.7161 - val_specificity: 0.9966\n",
            "Epoch 41/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4769 - auc_1: 0.9585 - dice_coef_oc: 0.9857 - dice_coef_od: 0.9841 - dice_coefficient: 0.7131 - loss: 0.3090 - mean_io_u_2: 0.5089 - precision_1: 0.6783 - recall_1: 0.7722 - specificity: 0.9971 - val_accuracy: 0.4611 - val_auc_1: 0.9227 - val_dice_coef_oc: 0.9871 - val_dice_coef_od: 0.9846 - val_dice_coefficient: 0.6536 - val_loss: 0.3759 - val_mean_io_u_2: 0.5077 - val_precision_1: 0.6469 - val_recall_1: 0.6795 - val_specificity: 0.9970\n",
            "Epoch 42/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4750 - auc_1: 0.9584 - dice_coef_oc: 0.9861 - dice_coef_od: 0.9845 - dice_coefficient: 0.7172 - loss: 0.3051 - mean_io_u_2: 0.5076 - precision_1: 0.6853 - recall_1: 0.7745 - specificity: 0.9971 - val_accuracy: 0.4668 - val_auc_1: 0.9361 - val_dice_coef_oc: 0.9870 - val_dice_coef_od: 0.9845 - val_dice_coefficient: 0.6713 - val_loss: 0.3587 - val_mean_io_u_2: 0.5206 - val_precision_1: 0.6294 - val_recall_1: 0.7370 - val_specificity: 0.9965\n",
            "Epoch 43/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4750 - auc_1: 0.9590 - dice_coef_oc: 0.9858 - dice_coef_od: 0.9844 - dice_coefficient: 0.7183 - loss: 0.3033 - mean_io_u_2: 0.5072 - precision_1: 0.6836 - recall_1: 0.7791 - specificity: 0.9972 - val_accuracy: 0.4622 - val_auc_1: 0.9356 - val_dice_coef_oc: 0.9873 - val_dice_coef_od: 0.9844 - val_dice_coefficient: 0.6598 - val_loss: 0.3714 - val_mean_io_u_2: 0.5204 - val_precision_1: 0.6091 - val_recall_1: 0.7361 - val_specificity: 0.9962\n",
            "Epoch 44/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4717 - auc_1: 0.9593 - dice_coef_oc: 0.9863 - dice_coef_od: 0.9843 - dice_coefficient: 0.7126 - loss: 0.3095 - mean_io_u_2: 0.5086 - precision_1: 0.6782 - recall_1: 0.7756 - specificity: 0.9971 - val_accuracy: 0.4660 - val_auc_1: 0.9407 - val_dice_coef_oc: 0.9880 - val_dice_coef_od: 0.9843 - val_dice_coefficient: 0.6650 - val_loss: 0.3663 - val_mean_io_u_2: 0.5212 - val_precision_1: 0.6098 - val_recall_1: 0.7439 - val_specificity: 0.9962\n",
            "Epoch 45/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4712 - auc_1: 0.9595 - dice_coef_oc: 0.9866 - dice_coef_od: 0.9847 - dice_coefficient: 0.7194 - loss: 0.3025 - mean_io_u_2: 0.5056 - precision_1: 0.6828 - recall_1: 0.7817 - specificity: 0.9971 - val_accuracy: 0.4530 - val_auc_1: 0.9341 - val_dice_coef_oc: 0.9879 - val_dice_coef_od: 0.9851 - val_dice_coefficient: 0.6645 - val_loss: 0.3647 - val_mean_io_u_2: 0.5108 - val_precision_1: 0.6328 - val_recall_1: 0.7145 - val_specificity: 0.9967\n",
            "Epoch 46/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4709 - auc_1: 0.9621 - dice_coef_oc: 0.9867 - dice_coef_od: 0.9849 - dice_coefficient: 0.7256 - loss: 0.2951 - mean_io_u_2: 0.5057 - precision_1: 0.6940 - recall_1: 0.7825 - specificity: 0.9972 - val_accuracy: 0.4863 - val_auc_1: 0.9365 - val_dice_coef_oc: 0.9882 - val_dice_coef_od: 0.9849 - val_dice_coefficient: 0.6731 - val_loss: 0.3557 - val_mean_io_u_2: 0.5134 - val_precision_1: 0.6328 - val_recall_1: 0.7352 - val_specificity: 0.9966\n",
            "Epoch 47/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4702 - auc_1: 0.9610 - dice_coef_oc: 0.9867 - dice_coef_od: 0.9849 - dice_coefficient: 0.7235 - loss: 0.2975 - mean_io_u_2: 0.5061 - precision_1: 0.6882 - recall_1: 0.7847 - specificity: 0.9972 - val_accuracy: 0.4677 - val_auc_1: 0.9386 - val_dice_coef_oc: 0.9880 - val_dice_coef_od: 0.9854 - val_dice_coefficient: 0.6762 - val_loss: 0.3524 - val_mean_io_u_2: 0.5126 - val_precision_1: 0.6363 - val_recall_1: 0.7373 - val_specificity: 0.9966\n",
            "Epoch 48/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4655 - auc_1: 0.9598 - dice_coef_oc: 0.9866 - dice_coef_od: 0.9847 - dice_coefficient: 0.7255 - loss: 0.2958 - mean_io_u_2: 0.5056 - precision_1: 0.6927 - recall_1: 0.7850 - specificity: 0.9972 - val_accuracy: 0.4766 - val_auc_1: 0.9257 - val_dice_coef_oc: 0.9881 - val_dice_coef_od: 0.9852 - val_dice_coefficient: 0.6539 - val_loss: 0.3764 - val_mean_io_u_2: 0.5138 - val_precision_1: 0.6279 - val_recall_1: 0.6920 - val_specificity: 0.9967\n",
            "Epoch 49/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4653 - auc_1: 0.9585 - dice_coef_oc: 0.9872 - dice_coef_od: 0.9851 - dice_coefficient: 0.7150 - loss: 0.3067 - mean_io_u_2: 0.5060 - precision_1: 0.6828 - recall_1: 0.7724 - specificity: 0.9972 - val_accuracy: 0.4534 - val_auc_1: 0.9208 - val_dice_coef_oc: 0.9885 - val_dice_coef_od: 0.9855 - val_dice_coefficient: 0.6624 - val_loss: 0.3673 - val_mean_io_u_2: 0.5071 - val_precision_1: 0.6537 - val_recall_1: 0.6892 - val_specificity: 0.9971\n",
            "Epoch 50/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4635 - auc_1: 0.9578 - dice_coef_oc: 0.9869 - dice_coef_od: 0.9846 - dice_coefficient: 0.7228 - loss: 0.2984 - mean_io_u_2: 0.5080 - precision_1: 0.6915 - recall_1: 0.7787 - specificity: 0.9973 - val_accuracy: 0.4352 - val_auc_1: 0.9216 - val_dice_coef_oc: 0.9884 - val_dice_coef_od: 0.9848 - val_dice_coefficient: 0.6530 - val_loss: 0.3776 - val_mean_io_u_2: 0.5095 - val_precision_1: 0.6315 - val_recall_1: 0.6906 - val_specificity: 0.9968\n",
            "Epoch 51/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4640 - auc_1: 0.9568 - dice_coef_oc: 0.9869 - dice_coef_od: 0.9851 - dice_coefficient: 0.7196 - loss: 0.3019 - mean_io_u_2: 0.5069 - precision_1: 0.6896 - recall_1: 0.7748 - specificity: 0.9973 - val_accuracy: 0.4586 - val_auc_1: 0.9337 - val_dice_coef_oc: 0.9886 - val_dice_coef_od: 0.9849 - val_dice_coefficient: 0.6675 - val_loss: 0.3623 - val_mean_io_u_2: 0.5127 - val_precision_1: 0.6282 - val_recall_1: 0.7231 - val_specificity: 0.9966\n",
            "Epoch 52/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4611 - auc_1: 0.9554 - dice_coef_oc: 0.9868 - dice_coef_od: 0.9849 - dice_coefficient: 0.7134 - loss: 0.3096 - mean_io_u_2: 0.5076 - precision_1: 0.6793 - recall_1: 0.7718 - specificity: 0.9971 - val_accuracy: 0.4687 - val_auc_1: 0.9294 - val_dice_coef_oc: 0.9884 - val_dice_coef_od: 0.9851 - val_dice_coefficient: 0.6661 - val_loss: 0.3631 - val_mean_io_u_2: 0.5151 - val_precision_1: 0.6424 - val_recall_1: 0.7078 - val_specificity: 0.9968\n",
            "Epoch 53/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4621 - auc_1: 0.9606 - dice_coef_oc: 0.9868 - dice_coef_od: 0.9850 - dice_coefficient: 0.7236 - loss: 0.2979 - mean_io_u_2: 0.5063 - precision_1: 0.6919 - recall_1: 0.7828 - specificity: 0.9972 - val_accuracy: 0.4447 - val_auc_1: 0.9241 - val_dice_coef_oc: 0.9883 - val_dice_coef_od: 0.9860 - val_dice_coefficient: 0.6623 - val_loss: 0.3663 - val_mean_io_u_2: 0.5057 - val_precision_1: 0.6611 - val_recall_1: 0.6826 - val_specificity: 0.9972\n",
            "Epoch 54/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4598 - auc_1: 0.9586 - dice_coef_oc: 0.9872 - dice_coef_od: 0.9854 - dice_coefficient: 0.7295 - loss: 0.2914 - mean_io_u_2: 0.5055 - precision_1: 0.7019 - recall_1: 0.7826 - specificity: 0.9973 - val_accuracy: 0.4572 - val_auc_1: 0.9387 - val_dice_coef_oc: 0.9887 - val_dice_coef_od: 0.9859 - val_dice_coefficient: 0.6783 - val_loss: 0.3499 - val_mean_io_u_2: 0.5116 - val_precision_1: 0.6413 - val_recall_1: 0.7345 - val_specificity: 0.9967\n",
            "Epoch 55/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4597 - auc_1: 0.9605 - dice_coef_oc: 0.9873 - dice_coef_od: 0.9857 - dice_coefficient: 0.7258 - loss: 0.2952 - mean_io_u_2: 0.5047 - precision_1: 0.6923 - recall_1: 0.7871 - specificity: 0.9973 - val_accuracy: 0.4588 - val_auc_1: 0.9313 - val_dice_coef_oc: 0.9887 - val_dice_coef_od: 0.9861 - val_dice_coefficient: 0.6727 - val_loss: 0.3559 - val_mean_io_u_2: 0.5074 - val_precision_1: 0.6498 - val_recall_1: 0.7153 - val_specificity: 0.9969\n",
            "Epoch 56/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4572 - auc_1: 0.9589 - dice_coef_oc: 0.9878 - dice_coef_od: 0.9860 - dice_coefficient: 0.7181 - loss: 0.3035 - mean_io_u_2: 0.5068 - precision_1: 0.6837 - recall_1: 0.7752 - specificity: 0.9972 - val_accuracy: 0.4649 - val_auc_1: 0.9339 - val_dice_coef_oc: 0.9888 - val_dice_coef_od: 0.9860 - val_dice_coefficient: 0.6732 - val_loss: 0.3555 - val_mean_io_u_2: 0.5135 - val_precision_1: 0.6384 - val_recall_1: 0.7252 - val_specificity: 0.9967\n",
            "Epoch 57/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4551 - auc_1: 0.9617 - dice_coef_oc: 0.9880 - dice_coef_od: 0.9857 - dice_coefficient: 0.7269 - loss: 0.2945 - mean_io_u_2: 0.5044 - precision_1: 0.6930 - recall_1: 0.7842 - specificity: 0.9972 - val_accuracy: 0.4320 - val_auc_1: 0.9318 - val_dice_coef_oc: 0.9894 - val_dice_coef_od: 0.9852 - val_dice_coefficient: 0.6743 - val_loss: 0.3540 - val_mean_io_u_2: 0.5092 - val_precision_1: 0.6523 - val_recall_1: 0.7112 - val_specificity: 0.9970\n",
            "Epoch 58/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4534 - auc_1: 0.9614 - dice_coef_oc: 0.9876 - dice_coef_od: 0.9855 - dice_coefficient: 0.7301 - loss: 0.2907 - mean_io_u_2: 0.5052 - precision_1: 0.6970 - recall_1: 0.7859 - specificity: 0.9973 - val_accuracy: 0.4501 - val_auc_1: 0.9268 - val_dice_coef_oc: 0.9894 - val_dice_coef_od: 0.9855 - val_dice_coefficient: 0.6646 - val_loss: 0.3644 - val_mean_io_u_2: 0.5093 - val_precision_1: 0.6446 - val_recall_1: 0.7001 - val_specificity: 0.9969\n",
            "Epoch 59/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4526 - auc_1: 0.9588 - dice_coef_oc: 0.9880 - dice_coef_od: 0.9856 - dice_coefficient: 0.7342 - loss: 0.2867 - mean_io_u_2: 0.5065 - precision_1: 0.7062 - recall_1: 0.7849 - specificity: 0.9974 - val_accuracy: 0.4495 - val_auc_1: 0.9281 - val_dice_coef_oc: 0.9897 - val_dice_coef_od: 0.9856 - val_dice_coefficient: 0.6755 - val_loss: 0.3518 - val_mean_io_u_2: 0.5082 - val_precision_1: 0.6661 - val_recall_1: 0.6992 - val_specificity: 0.9972\n",
            "Epoch 60/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4533 - auc_1: 0.9594 - dice_coef_oc: 0.9878 - dice_coef_od: 0.9859 - dice_coefficient: 0.7314 - loss: 0.2893 - mean_io_u_2: 0.5076 - precision_1: 0.7012 - recall_1: 0.7870 - specificity: 0.9974 - val_accuracy: 0.4387 - val_auc_1: 0.9408 - val_dice_coef_oc: 0.9894 - val_dice_coef_od: 0.9866 - val_dice_coefficient: 0.6600 - val_loss: 0.3724 - val_mean_io_u_2: 0.5205 - val_precision_1: 0.5937 - val_recall_1: 0.7569 - val_specificity: 0.9959\n",
            "Epoch 61/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4503 - auc_1: 0.9630 - dice_coef_oc: 0.9883 - dice_coef_od: 0.9861 - dice_coefficient: 0.7314 - loss: 0.2891 - mean_io_u_2: 0.5038 - precision_1: 0.6955 - recall_1: 0.7935 - specificity: 0.9973 - val_accuracy: 0.4524 - val_auc_1: 0.9405 - val_dice_coef_oc: 0.9901 - val_dice_coef_od: 0.9866 - val_dice_coefficient: 0.6670 - val_loss: 0.3636 - val_mean_io_u_2: 0.5145 - val_precision_1: 0.6096 - val_recall_1: 0.7524 - val_specificity: 0.9961\n",
            "Epoch 62/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4485 - auc_1: 0.9636 - dice_coef_oc: 0.9884 - dice_coef_od: 0.9863 - dice_coefficient: 0.7396 - loss: 0.2806 - mean_io_u_2: 0.5052 - precision_1: 0.7048 - recall_1: 0.7985 - specificity: 0.9974 - val_accuracy: 0.4471 - val_auc_1: 0.9375 - val_dice_coef_oc: 0.9899 - val_dice_coef_od: 0.9862 - val_dice_coefficient: 0.6734 - val_loss: 0.3560 - val_mean_io_u_2: 0.5156 - val_precision_1: 0.6302 - val_recall_1: 0.7362 - val_specificity: 0.9965\n",
            "Epoch 63/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.4493 - auc_1: 0.9584 - dice_coef_oc: 0.9883 - dice_coef_od: 0.9865 - dice_coefficient: 0.7192 - loss: 0.3030 - mean_io_u_2: 0.5047 - precision_1: 0.6833 - recall_1: 0.7792 - specificity: 0.9971 - val_accuracy: 0.4403 - val_auc_1: 0.9366 - val_dice_coef_oc: 0.9898 - val_dice_coef_od: 0.9865 - val_dice_coefficient: 0.6709 - val_loss: 0.3588 - val_mean_io_u_2: 0.5152 - val_precision_1: 0.6243 - val_recall_1: 0.7366 - val_specificity: 0.9965\n",
            "Epoch 64/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4477 - auc_1: 0.9613 - dice_coef_oc: 0.9885 - dice_coef_od: 0.9864 - dice_coefficient: 0.7412 - loss: 0.2782 - mean_io_u_2: 0.5047 - precision_1: 0.7157 - recall_1: 0.7898 - specificity: 0.9975 - val_accuracy: 0.4743 - val_auc_1: 0.9430 - val_dice_coef_oc: 0.9900 - val_dice_coef_od: 0.9872 - val_dice_coefficient: 0.6618 - val_loss: 0.3701 - val_mean_io_u_2: 0.5198 - val_precision_1: 0.5991 - val_recall_1: 0.7541 - val_specificity: 0.9960\n",
            "Epoch 65/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4473 - auc_1: 0.9619 - dice_coef_oc: 0.9891 - dice_coef_od: 0.9868 - dice_coefficient: 0.7308 - loss: 0.2897 - mean_io_u_2: 0.5043 - precision_1: 0.6964 - recall_1: 0.7911 - specificity: 0.9973 - val_accuracy: 0.4349 - val_auc_1: 0.9375 - val_dice_coef_oc: 0.9897 - val_dice_coef_od: 0.9870 - val_dice_coefficient: 0.6720 - val_loss: 0.3591 - val_mean_io_u_2: 0.5136 - val_precision_1: 0.6224 - val_recall_1: 0.7445 - val_specificity: 0.9964\n",
            "Epoch 66/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4456 - auc_1: 0.9621 - dice_coef_oc: 0.9889 - dice_coef_od: 0.9865 - dice_coefficient: 0.7340 - loss: 0.2860 - mean_io_u_2: 0.5043 - precision_1: 0.6989 - recall_1: 0.7936 - specificity: 0.9973 - val_accuracy: 0.4376 - val_auc_1: 0.9330 - val_dice_coef_oc: 0.9902 - val_dice_coef_od: 0.9871 - val_dice_coefficient: 0.6734 - val_loss: 0.3547 - val_mean_io_u_2: 0.5095 - val_precision_1: 0.6433 - val_recall_1: 0.7216 - val_specificity: 0.9968\n",
            "Epoch 67/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4452 - auc_1: 0.9621 - dice_coef_oc: 0.9890 - dice_coef_od: 0.9868 - dice_coefficient: 0.7382 - loss: 0.2819 - mean_io_u_2: 0.5021 - precision_1: 0.7100 - recall_1: 0.7923 - specificity: 0.9974 - val_accuracy: 0.4440 - val_auc_1: 0.9354 - val_dice_coef_oc: 0.9907 - val_dice_coef_od: 0.9862 - val_dice_coefficient: 0.6795 - val_loss: 0.3494 - val_mean_io_u_2: 0.5117 - val_precision_1: 0.6437 - val_recall_1: 0.7318 - val_specificity: 0.9968\n",
            "Epoch 68/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4452 - auc_1: 0.9591 - dice_coef_oc: 0.9890 - dice_coef_od: 0.9866 - dice_coefficient: 0.7344 - loss: 0.2858 - mean_io_u_2: 0.5045 - precision_1: 0.7090 - recall_1: 0.7845 - specificity: 0.9974 - val_accuracy: 0.4466 - val_auc_1: 0.9324 - val_dice_coef_oc: 0.9903 - val_dice_coef_od: 0.9872 - val_dice_coefficient: 0.6686 - val_loss: 0.3607 - val_mean_io_u_2: 0.5090 - val_precision_1: 0.6374 - val_recall_1: 0.7151 - val_specificity: 0.9967\n",
            "Epoch 69/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4448 - auc_1: 0.9592 - dice_coef_oc: 0.9891 - dice_coef_od: 0.9867 - dice_coefficient: 0.7269 - loss: 0.2942 - mean_io_u_2: 0.5048 - precision_1: 0.6946 - recall_1: 0.7850 - specificity: 0.9973 - val_accuracy: 0.4264 - val_auc_1: 0.9365 - val_dice_coef_oc: 0.9904 - val_dice_coef_od: 0.9871 - val_dice_coefficient: 0.6829 - val_loss: 0.3466 - val_mean_io_u_2: 0.5143 - val_precision_1: 0.6423 - val_recall_1: 0.7427 - val_specificity: 0.9967\n",
            "Epoch 70/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4442 - auc_1: 0.9598 - dice_coef_oc: 0.9894 - dice_coef_od: 0.9869 - dice_coefficient: 0.7365 - loss: 0.2844 - mean_io_u_2: 0.5054 - precision_1: 0.7072 - recall_1: 0.7911 - specificity: 0.9974 - val_accuracy: 0.4348 - val_auc_1: 0.9303 - val_dice_coef_oc: 0.9908 - val_dice_coef_od: 0.9867 - val_dice_coefficient: 0.6862 - val_loss: 0.3410 - val_mean_io_u_2: 0.5065 - val_precision_1: 0.6698 - val_recall_1: 0.7183 - val_specificity: 0.9972\n",
            "Epoch 71/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4443 - auc_1: 0.9650 - dice_coef_oc: 0.9891 - dice_coef_od: 0.9870 - dice_coefficient: 0.7477 - loss: 0.2716 - mean_io_u_2: 0.5031 - precision_1: 0.7159 - recall_1: 0.8042 - specificity: 0.9975 - val_accuracy: 0.4332 - val_auc_1: 0.9358 - val_dice_coef_oc: 0.9905 - val_dice_coef_od: 0.9881 - val_dice_coefficient: 0.6850 - val_loss: 0.3421 - val_mean_io_u_2: 0.5106 - val_precision_1: 0.6594 - val_recall_1: 0.7306 - val_specificity: 0.9970\n",
            "Epoch 72/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4430 - auc_1: 0.9625 - dice_coef_oc: 0.9894 - dice_coef_od: 0.9873 - dice_coefficient: 0.7400 - loss: 0.2797 - mean_io_u_2: 0.5021 - precision_1: 0.7094 - recall_1: 0.7927 - specificity: 0.9974 - val_accuracy: 0.4390 - val_auc_1: 0.9363 - val_dice_coef_oc: 0.9901 - val_dice_coef_od: 0.9876 - val_dice_coefficient: 0.6794 - val_loss: 0.3484 - val_mean_io_u_2: 0.5095 - val_precision_1: 0.6504 - val_recall_1: 0.7227 - val_specificity: 0.9969\n",
            "Epoch 73/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4421 - auc_1: 0.9608 - dice_coef_oc: 0.9890 - dice_coef_od: 0.9870 - dice_coefficient: 0.7364 - loss: 0.2842 - mean_io_u_2: 0.5040 - precision_1: 0.7052 - recall_1: 0.7909 - specificity: 0.9974 - val_accuracy: 0.4369 - val_auc_1: 0.9319 - val_dice_coef_oc: 0.9901 - val_dice_coef_od: 0.9880 - val_dice_coefficient: 0.6740 - val_loss: 0.3552 - val_mean_io_u_2: 0.5114 - val_precision_1: 0.6422 - val_recall_1: 0.7208 - val_specificity: 0.9968\n",
            "Epoch 74/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4427 - auc_1: 0.9619 - dice_coef_oc: 0.9892 - dice_coef_od: 0.9876 - dice_coefficient: 0.7410 - loss: 0.2790 - mean_io_u_2: 0.5034 - precision_1: 0.7116 - recall_1: 0.7948 - specificity: 0.9975 - val_accuracy: 0.4299 - val_auc_1: 0.9432 - val_dice_coef_oc: 0.9906 - val_dice_coef_od: 0.9878 - val_dice_coefficient: 0.6850 - val_loss: 0.3445 - val_mean_io_u_2: 0.5176 - val_precision_1: 0.6354 - val_recall_1: 0.7570 - val_specificity: 0.9965\n",
            "Epoch 75/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4416 - auc_1: 0.9601 - dice_coef_oc: 0.9895 - dice_coef_od: 0.9876 - dice_coefficient: 0.7294 - loss: 0.2915 - mean_io_u_2: 0.5027 - precision_1: 0.6993 - recall_1: 0.7891 - specificity: 0.9973 - val_accuracy: 0.4304 - val_auc_1: 0.9391 - val_dice_coef_oc: 0.9899 - val_dice_coef_od: 0.9885 - val_dice_coefficient: 0.6769 - val_loss: 0.3512 - val_mean_io_u_2: 0.5113 - val_precision_1: 0.6340 - val_recall_1: 0.7430 - val_specificity: 0.9966\n",
            "Epoch 76/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4419 - auc_1: 0.9616 - dice_coef_oc: 0.9897 - dice_coef_od: 0.9879 - dice_coefficient: 0.7361 - loss: 0.2835 - mean_io_u_2: 0.5027 - precision_1: 0.7065 - recall_1: 0.7918 - specificity: 0.9974 - val_accuracy: 0.4446 - val_auc_1: 0.9371 - val_dice_coef_oc: 0.9908 - val_dice_coef_od: 0.9884 - val_dice_coefficient: 0.6857 - val_loss: 0.3423 - val_mean_io_u_2: 0.5090 - val_precision_1: 0.6537 - val_recall_1: 0.7367 - val_specificity: 0.9969\n",
            "Epoch 77/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4407 - auc_1: 0.9595 - dice_coef_oc: 0.9899 - dice_coef_od: 0.9876 - dice_coefficient: 0.7309 - loss: 0.2897 - mean_io_u_2: 0.5033 - precision_1: 0.6975 - recall_1: 0.7887 - specificity: 0.9973 - val_accuracy: 0.4294 - val_auc_1: 0.9398 - val_dice_coef_oc: 0.9914 - val_dice_coef_od: 0.9884 - val_dice_coefficient: 0.6776 - val_loss: 0.3512 - val_mean_io_u_2: 0.5121 - val_precision_1: 0.6383 - val_recall_1: 0.7378 - val_specificity: 0.9967\n",
            "Epoch 78/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.4414 - auc_1: 0.9622 - dice_coef_oc: 0.9901 - dice_coef_od: 0.9875 - dice_coefficient: 0.7347 - loss: 0.2859 - mean_io_u_2: 0.5032 - precision_1: 0.7020 - recall_1: 0.7940 - specificity: 0.9973 - val_accuracy: 0.4397 - val_auc_1: 0.9319 - val_dice_coef_oc: 0.9915 - val_dice_coef_od: 0.9885 - val_dice_coefficient: 0.6707 - val_loss: 0.3566 - val_mean_io_u_2: 0.5078 - val_precision_1: 0.6523 - val_recall_1: 0.7037 - val_specificity: 0.9970\n",
            "Epoch 79/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4411 - auc_1: 0.9617 - dice_coef_oc: 0.9905 - dice_coef_od: 0.9880 - dice_coefficient: 0.7415 - loss: 0.2783 - mean_io_u_2: 0.5022 - precision_1: 0.7130 - recall_1: 0.7928 - specificity: 0.9975 - val_accuracy: 0.4329 - val_auc_1: 0.9411 - val_dice_coef_oc: 0.9916 - val_dice_coef_od: 0.9883 - val_dice_coefficient: 0.6896 - val_loss: 0.3376 - val_mean_io_u_2: 0.5127 - val_precision_1: 0.6527 - val_recall_1: 0.7470 - val_specificity: 0.9968\n",
            "Epoch 80/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4394 - auc_1: 0.9616 - dice_coef_oc: 0.9903 - dice_coef_od: 0.9879 - dice_coefficient: 0.7413 - loss: 0.2782 - mean_io_u_2: 0.5020 - precision_1: 0.7136 - recall_1: 0.7929 - specificity: 0.9975 - val_accuracy: 0.4341 - val_auc_1: 0.9295 - val_dice_coef_oc: 0.9916 - val_dice_coef_od: 0.9884 - val_dice_coefficient: 0.6817 - val_loss: 0.3455 - val_mean_io_u_2: 0.5076 - val_precision_1: 0.6724 - val_recall_1: 0.7072 - val_specificity: 0.9972\n",
            "Epoch 81/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.4387 - auc_1: 0.9590 - dice_coef_oc: 0.9902 - dice_coef_od: 0.9879 - dice_coefficient: 0.7346 - loss: 0.2859 - mean_io_u_2: 0.5041 - precision_1: 0.7085 - recall_1: 0.7863 - specificity: 0.9974 - val_accuracy: 0.4136 - val_auc_1: 0.9338 - val_dice_coef_oc: 0.9918 - val_dice_coef_od: 0.9884 - val_dice_coefficient: 0.6843 - val_loss: 0.3433 - val_mean_io_u_2: 0.5059 - val_precision_1: 0.6579 - val_recall_1: 0.7284 - val_specificity: 0.9970\n",
            "Epoch 82/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4369 - auc_1: 0.9587 - dice_coef_oc: 0.9904 - dice_coef_od: 0.9881 - dice_coefficient: 0.7389 - loss: 0.2812 - mean_io_u_2: 0.5024 - precision_1: 0.7111 - recall_1: 0.7898 - specificity: 0.9975 - val_accuracy: 0.4411 - val_auc_1: 0.9295 - val_dice_coef_oc: 0.9918 - val_dice_coef_od: 0.9883 - val_dice_coefficient: 0.6764 - val_loss: 0.3519 - val_mean_io_u_2: 0.5075 - val_precision_1: 0.6563 - val_recall_1: 0.7122 - val_specificity: 0.9970\n",
            "Epoch 83/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4389 - auc_1: 0.9598 - dice_coef_oc: 0.9902 - dice_coef_od: 0.9879 - dice_coefficient: 0.7419 - loss: 0.2783 - mean_io_u_2: 0.5027 - precision_1: 0.7126 - recall_1: 0.7912 - specificity: 0.9975 - val_accuracy: 0.4248 - val_auc_1: 0.9410 - val_dice_coef_oc: 0.9918 - val_dice_coef_od: 0.9883 - val_dice_coefficient: 0.6885 - val_loss: 0.3384 - val_mean_io_u_2: 0.5117 - val_precision_1: 0.6520 - val_recall_1: 0.7448 - val_specificity: 0.9968\n",
            "Epoch 84/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.4377 - auc_1: 0.9649 - dice_coef_oc: 0.9905 - dice_coef_od: 0.9880 - dice_coefficient: 0.7554 - loss: 0.2626 - mean_io_u_2: 0.5002 - precision_1: 0.7271 - recall_1: 0.8063 - specificity: 0.9976 - val_accuracy: 0.4083 - val_auc_1: 0.9321 - val_dice_coef_oc: 0.9924 - val_dice_coef_od: 0.9882 - val_dice_coefficient: 0.6879 - val_loss: 0.3396 - val_mean_io_u_2: 0.5058 - val_precision_1: 0.6711 - val_recall_1: 0.7198 - val_specificity: 0.9972\n",
            "Epoch 85/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4364 - auc_1: 0.9625 - dice_coef_oc: 0.9908 - dice_coef_od: 0.9886 - dice_coefficient: 0.7431 - loss: 0.2767 - mean_io_u_2: 0.5024 - precision_1: 0.7137 - recall_1: 0.7945 - specificity: 0.9975 - val_accuracy: 0.4484 - val_auc_1: 0.9346 - val_dice_coef_oc: 0.9926 - val_dice_coef_od: 0.9885 - val_dice_coefficient: 0.6861 - val_loss: 0.3407 - val_mean_io_u_2: 0.5085 - val_precision_1: 0.6634 - val_recall_1: 0.7258 - val_specificity: 0.9971\n",
            "Epoch 86/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4372 - auc_1: 0.9649 - dice_coef_oc: 0.9910 - dice_coef_od: 0.9885 - dice_coefficient: 0.7441 - loss: 0.2749 - mean_io_u_2: 0.5025 - precision_1: 0.7128 - recall_1: 0.7988 - specificity: 0.9975 - val_accuracy: 0.4434 - val_auc_1: 0.9428 - val_dice_coef_oc: 0.9928 - val_dice_coef_od: 0.9883 - val_dice_coefficient: 0.6730 - val_loss: 0.3587 - val_mean_io_u_2: 0.5162 - val_precision_1: 0.6092 - val_recall_1: 0.7619 - val_specificity: 0.9961\n",
            "Epoch 87/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4360 - auc_1: 0.9644 - dice_coef_oc: 0.9911 - dice_coef_od: 0.9883 - dice_coefficient: 0.7416 - loss: 0.2785 - mean_io_u_2: 0.5014 - precision_1: 0.7057 - recall_1: 0.8018 - specificity: 0.9973 - val_accuracy: 0.4166 - val_auc_1: 0.9337 - val_dice_coef_oc: 0.9929 - val_dice_coef_od: 0.9887 - val_dice_coefficient: 0.6800 - val_loss: 0.3476 - val_mean_io_u_2: 0.5044 - val_precision_1: 0.6514 - val_recall_1: 0.7256 - val_specificity: 0.9969\n",
            "Epoch 88/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4357 - auc_1: 0.9638 - dice_coef_oc: 0.9913 - dice_coef_od: 0.9883 - dice_coefficient: 0.7504 - loss: 0.2687 - mean_io_u_2: 0.5019 - precision_1: 0.7210 - recall_1: 0.8005 - specificity: 0.9975 - val_accuracy: 0.4124 - val_auc_1: 0.9433 - val_dice_coef_oc: 0.9923 - val_dice_coef_od: 0.9887 - val_dice_coefficient: 0.6920 - val_loss: 0.3358 - val_mean_io_u_2: 0.5085 - val_precision_1: 0.6491 - val_recall_1: 0.7561 - val_specificity: 0.9967\n",
            "Epoch 89/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4355 - auc_1: 0.9629 - dice_coef_oc: 0.9915 - dice_coef_od: 0.9884 - dice_coefficient: 0.7502 - loss: 0.2692 - mean_io_u_2: 0.5013 - precision_1: 0.7216 - recall_1: 0.8008 - specificity: 0.9975 - val_accuracy: 0.4483 - val_auc_1: 0.9292 - val_dice_coef_oc: 0.9930 - val_dice_coef_od: 0.9885 - val_dice_coefficient: 0.6882 - val_loss: 0.3387 - val_mean_io_u_2: 0.5071 - val_precision_1: 0.6739 - val_recall_1: 0.7171 - val_specificity: 0.9972\n",
            "Epoch 90/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4360 - auc_1: 0.9610 - dice_coef_oc: 0.9915 - dice_coef_od: 0.9884 - dice_coefficient: 0.7498 - loss: 0.2695 - mean_io_u_2: 0.5030 - precision_1: 0.7286 - recall_1: 0.7923 - specificity: 0.9976 - val_accuracy: 0.4451 - val_auc_1: 0.9331 - val_dice_coef_oc: 0.9928 - val_dice_coef_od: 0.9885 - val_dice_coefficient: 0.6890 - val_loss: 0.3382 - val_mean_io_u_2: 0.5086 - val_precision_1: 0.6677 - val_recall_1: 0.7268 - val_specificity: 0.9971\n",
            "Epoch 91/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4356 - auc_1: 0.9589 - dice_coef_oc: 0.9915 - dice_coef_od: 0.9886 - dice_coefficient: 0.7390 - loss: 0.2814 - mean_io_u_2: 0.5025 - precision_1: 0.7140 - recall_1: 0.7880 - specificity: 0.9975 - val_accuracy: 0.4337 - val_auc_1: 0.9324 - val_dice_coef_oc: 0.9927 - val_dice_coef_od: 0.9887 - val_dice_coefficient: 0.6966 - val_loss: 0.3287 - val_mean_io_u_2: 0.5047 - val_precision_1: 0.6899 - val_recall_1: 0.7187 - val_specificity: 0.9974\n",
            "Epoch 92/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4369 - auc_1: 0.9608 - dice_coef_oc: 0.9916 - dice_coef_od: 0.9887 - dice_coefficient: 0.7446 - loss: 0.2751 - mean_io_u_2: 0.5007 - precision_1: 0.7147 - recall_1: 0.7937 - specificity: 0.9975 - val_accuracy: 0.4385 - val_auc_1: 0.9397 - val_dice_coef_oc: 0.9928 - val_dice_coef_od: 0.9887 - val_dice_coefficient: 0.6905 - val_loss: 0.3377 - val_mean_io_u_2: 0.5090 - val_precision_1: 0.6501 - val_recall_1: 0.7505 - val_specificity: 0.9968\n",
            "Epoch 93/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4343 - auc_1: 0.9620 - dice_coef_oc: 0.9918 - dice_coef_od: 0.9886 - dice_coefficient: 0.7490 - loss: 0.2700 - mean_io_u_2: 0.5021 - precision_1: 0.7241 - recall_1: 0.7982 - specificity: 0.9976 - val_accuracy: 0.4399 - val_auc_1: 0.9357 - val_dice_coef_oc: 0.9933 - val_dice_coef_od: 0.9886 - val_dice_coefficient: 0.6920 - val_loss: 0.3352 - val_mean_io_u_2: 0.5064 - val_precision_1: 0.6680 - val_recall_1: 0.7330 - val_specificity: 0.9971\n",
            "Epoch 94/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.4349 - auc_1: 0.9612 - dice_coef_oc: 0.9921 - dice_coef_od: 0.9887 - dice_coefficient: 0.7441 - loss: 0.2753 - mean_io_u_2: 0.5028 - precision_1: 0.7172 - recall_1: 0.7929 - specificity: 0.9975 - val_accuracy: 0.4437 - val_auc_1: 0.9398 - val_dice_coef_oc: 0.9930 - val_dice_coef_od: 0.9891 - val_dice_coefficient: 0.6956 - val_loss: 0.3305 - val_mean_io_u_2: 0.5048 - val_precision_1: 0.6664 - val_recall_1: 0.7370 - val_specificity: 0.9970\n",
            "Epoch 95/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.4359 - auc_1: 0.9609 - dice_coef_oc: 0.9921 - dice_coef_od: 0.9888 - dice_coefficient: 0.7455 - loss: 0.2740 - mean_io_u_2: 0.5005 - precision_1: 0.7213 - recall_1: 0.7934 - specificity: 0.9975 - val_accuracy: 0.4264 - val_auc_1: 0.9332 - val_dice_coef_oc: 0.9935 - val_dice_coef_od: 0.9890 - val_dice_coefficient: 0.6913 - val_loss: 0.3351 - val_mean_io_u_2: 0.5039 - val_precision_1: 0.6712 - val_recall_1: 0.7209 - val_specificity: 0.9972\n",
            "Epoch 96/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.4355 - auc_1: 0.9609 - dice_coef_oc: 0.9922 - dice_coef_od: 0.9889 - dice_coefficient: 0.7488 - loss: 0.2701 - mean_io_u_2: 0.5010 - precision_1: 0.7253 - recall_1: 0.7935 - specificity: 0.9976 - val_accuracy: 0.4275 - val_auc_1: 0.9299 - val_dice_coef_oc: 0.9935 - val_dice_coef_od: 0.9888 - val_dice_coefficient: 0.6911 - val_loss: 0.3357 - val_mean_io_u_2: 0.5035 - val_precision_1: 0.6768 - val_recall_1: 0.7165 - val_specificity: 0.9973\n",
            "Epoch 97/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4337 - auc_1: 0.9617 - dice_coef_oc: 0.9923 - dice_coef_od: 0.9890 - dice_coefficient: 0.7456 - loss: 0.2740 - mean_io_u_2: 0.5005 - precision_1: 0.7180 - recall_1: 0.7960 - specificity: 0.9975 - val_accuracy: 0.4318 - val_auc_1: 0.9317 - val_dice_coef_oc: 0.9937 - val_dice_coef_od: 0.9893 - val_dice_coefficient: 0.6851 - val_loss: 0.3410 - val_mean_io_u_2: 0.5049 - val_precision_1: 0.6708 - val_recall_1: 0.7141 - val_specificity: 0.9972\n",
            "Epoch 98/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4323 - auc_1: 0.9641 - dice_coef_oc: 0.9922 - dice_coef_od: 0.9892 - dice_coefficient: 0.7554 - loss: 0.2632 - mean_io_u_2: 0.5016 - precision_1: 0.7300 - recall_1: 0.8010 - specificity: 0.9976 - val_accuracy: 0.4336 - val_auc_1: 0.9424 - val_dice_coef_oc: 0.9930 - val_dice_coef_od: 0.9889 - val_dice_coefficient: 0.6887 - val_loss: 0.3393 - val_mean_io_u_2: 0.5087 - val_precision_1: 0.6467 - val_recall_1: 0.7476 - val_specificity: 0.9967\n",
            "Epoch 99/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.4331 - auc_1: 0.9614 - dice_coef_oc: 0.9924 - dice_coef_od: 0.9893 - dice_coefficient: 0.7472 - loss: 0.2722 - mean_io_u_2: 0.5009 - precision_1: 0.7222 - recall_1: 0.7947 - specificity: 0.9976 - val_accuracy: 0.4235 - val_auc_1: 0.9290 - val_dice_coef_oc: 0.9931 - val_dice_coef_od: 0.9897 - val_dice_coefficient: 0.6796 - val_loss: 0.3483 - val_mean_io_u_2: 0.5049 - val_precision_1: 0.6610 - val_recall_1: 0.7119 - val_specificity: 0.9971\n",
            "Epoch 100/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4325 - auc_1: 0.9626 - dice_coef_oc: 0.9926 - dice_coef_od: 0.9892 - dice_coefficient: 0.7529 - loss: 0.2662 - mean_io_u_2: 0.5009 - precision_1: 0.7277 - recall_1: 0.7995 - specificity: 0.9976 - val_accuracy: 0.4222 - val_auc_1: 0.9393 - val_dice_coef_oc: 0.9938 - val_dice_coef_od: 0.9895 - val_dice_coefficient: 0.6955 - val_loss: 0.3315 - val_mean_io_u_2: 0.5068 - val_precision_1: 0.6610 - val_recall_1: 0.7458 - val_specificity: 0.9969\n",
            "Epoch 101/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4331 - auc_1: 0.9614 - dice_coef_oc: 0.9929 - dice_coef_od: 0.9894 - dice_coefficient: 0.7448 - loss: 0.2749 - mean_io_u_2: 0.4997 - precision_1: 0.7137 - recall_1: 0.7960 - specificity: 0.9974 - val_accuracy: 0.4193 - val_auc_1: 0.9231 - val_dice_coef_oc: 0.9935 - val_dice_coef_od: 0.9897 - val_dice_coefficient: 0.6823 - val_loss: 0.3447 - val_mean_io_u_2: 0.5019 - val_precision_1: 0.6889 - val_recall_1: 0.6880 - val_specificity: 0.9975\n",
            "Epoch 102/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.4329 - auc_1: 0.9618 - dice_coef_oc: 0.9928 - dice_coef_od: 0.9894 - dice_coefficient: 0.7471 - loss: 0.2724 - mean_io_u_2: 0.5002 - precision_1: 0.7208 - recall_1: 0.7969 - specificity: 0.9976 - val_accuracy: 0.4245 - val_auc_1: 0.9354 - val_dice_coef_oc: 0.9937 - val_dice_coef_od: 0.9898 - val_dice_coefficient: 0.6962 - val_loss: 0.3309 - val_mean_io_u_2: 0.5068 - val_precision_1: 0.6750 - val_recall_1: 0.7318 - val_specificity: 0.9972\n",
            "Epoch 103/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4318 - auc_1: 0.9610 - dice_coef_oc: 0.9929 - dice_coef_od: 0.9893 - dice_coefficient: 0.7521 - loss: 0.2674 - mean_io_u_2: 0.5007 - precision_1: 0.7242 - recall_1: 0.7982 - specificity: 0.9976 - val_accuracy: 0.4184 - val_auc_1: 0.9317 - val_dice_coef_oc: 0.9940 - val_dice_coef_od: 0.9894 - val_dice_coefficient: 0.6833 - val_loss: 0.3440 - val_mean_io_u_2: 0.5045 - val_precision_1: 0.6664 - val_recall_1: 0.7107 - val_specificity: 0.9972\n",
            "Epoch 104/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4320 - auc_1: 0.9646 - dice_coef_oc: 0.9929 - dice_coef_od: 0.9893 - dice_coefficient: 0.7581 - loss: 0.2606 - mean_io_u_2: 0.5003 - precision_1: 0.7321 - recall_1: 0.8063 - specificity: 0.9976 - val_accuracy: 0.4372 - val_auc_1: 0.9259 - val_dice_coef_oc: 0.9934 - val_dice_coef_od: 0.9897 - val_dice_coefficient: 0.6823 - val_loss: 0.3455 - val_mean_io_u_2: 0.5049 - val_precision_1: 0.6757 - val_recall_1: 0.7017 - val_specificity: 0.9973\n",
            "Epoch 105/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.4318 - auc_1: 0.9618 - dice_coef_oc: 0.9930 - dice_coef_od: 0.9895 - dice_coefficient: 0.7542 - loss: 0.2646 - mean_io_u_2: 0.5018 - precision_1: 0.7302 - recall_1: 0.7996 - specificity: 0.9976 - val_accuracy: 0.4278 - val_auc_1: 0.9293 - val_dice_coef_oc: 0.9942 - val_dice_coef_od: 0.9893 - val_dice_coefficient: 0.6909 - val_loss: 0.3357 - val_mean_io_u_2: 0.5046 - val_precision_1: 0.6794 - val_recall_1: 0.7150 - val_specificity: 0.9973\n",
            "Epoch 106/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4311 - auc_1: 0.9582 - dice_coef_oc: 0.9930 - dice_coef_od: 0.9893 - dice_coefficient: 0.7424 - loss: 0.2776 - mean_io_u_2: 0.5026 - precision_1: 0.7185 - recall_1: 0.7891 - specificity: 0.9976 - val_accuracy: 0.4373 - val_auc_1: 0.9361 - val_dice_coef_oc: 0.9938 - val_dice_coef_od: 0.9896 - val_dice_coefficient: 0.6875 - val_loss: 0.3397 - val_mean_io_u_2: 0.5072 - val_precision_1: 0.6550 - val_recall_1: 0.7317 - val_specificity: 0.9969\n",
            "Epoch 107/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4331 - auc_1: 0.9607 - dice_coef_oc: 0.9929 - dice_coef_od: 0.9895 - dice_coefficient: 0.7474 - loss: 0.2719 - mean_io_u_2: 0.5019 - precision_1: 0.7220 - recall_1: 0.7946 - specificity: 0.9976 - val_accuracy: 0.4231 - val_auc_1: 0.9365 - val_dice_coef_oc: 0.9937 - val_dice_coef_od: 0.9897 - val_dice_coefficient: 0.6880 - val_loss: 0.3394 - val_mean_io_u_2: 0.5051 - val_precision_1: 0.6572 - val_recall_1: 0.7349 - val_specificity: 0.9969\n",
            "Epoch 108/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4315 - auc_1: 0.9652 - dice_coef_oc: 0.9931 - dice_coef_od: 0.9896 - dice_coefficient: 0.7570 - loss: 0.2616 - mean_io_u_2: 0.5010 - precision_1: 0.7281 - recall_1: 0.8063 - specificity: 0.9976 - val_accuracy: 0.4264 - val_auc_1: 0.9366 - val_dice_coef_oc: 0.9942 - val_dice_coef_od: 0.9900 - val_dice_coefficient: 0.6944 - val_loss: 0.3319 - val_mean_io_u_2: 0.5076 - val_precision_1: 0.6708 - val_recall_1: 0.7359 - val_specificity: 0.9971\n",
            "Epoch 109/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.4311 - auc_1: 0.9624 - dice_coef_oc: 0.9932 - dice_coef_od: 0.9898 - dice_coefficient: 0.7505 - loss: 0.2684 - mean_io_u_2: 0.5015 - precision_1: 0.7249 - recall_1: 0.7992 - specificity: 0.9976 - val_accuracy: 0.4382 - val_auc_1: 0.9432 - val_dice_coef_oc: 0.9944 - val_dice_coef_od: 0.9900 - val_dice_coefficient: 0.6988 - val_loss: 0.3277 - val_mean_io_u_2: 0.5070 - val_precision_1: 0.6597 - val_recall_1: 0.7575 - val_specificity: 0.9969\n",
            "Epoch 110/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4322 - auc_1: 0.9594 - dice_coef_oc: 0.9933 - dice_coef_od: 0.9899 - dice_coefficient: 0.7440 - loss: 0.2755 - mean_io_u_2: 0.5012 - precision_1: 0.7182 - recall_1: 0.7897 - specificity: 0.9976 - val_accuracy: 0.4131 - val_auc_1: 0.9393 - val_dice_coef_oc: 0.9942 - val_dice_coef_od: 0.9904 - val_dice_coefficient: 0.6967 - val_loss: 0.3295 - val_mean_io_u_2: 0.5054 - val_precision_1: 0.6738 - val_recall_1: 0.7348 - val_specificity: 0.9972\n",
            "Epoch 111/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.4308 - auc_1: 0.9618 - dice_coef_oc: 0.9935 - dice_coef_od: 0.9899 - dice_coefficient: 0.7492 - loss: 0.2701 - mean_io_u_2: 0.5007 - precision_1: 0.7217 - recall_1: 0.7973 - specificity: 0.9976 - val_accuracy: 0.4150 - val_auc_1: 0.9356 - val_dice_coef_oc: 0.9941 - val_dice_coef_od: 0.9903 - val_dice_coefficient: 0.6903 - val_loss: 0.3358 - val_mean_io_u_2: 0.5034 - val_precision_1: 0.6726 - val_recall_1: 0.7238 - val_specificity: 0.9972\n",
            "Epoch 112/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.4293 - auc_1: 0.9638 - dice_coef_oc: 0.9936 - dice_coef_od: 0.9901 - dice_coefficient: 0.7481 - loss: 0.2710 - mean_io_u_2: 0.5003 - precision_1: 0.7198 - recall_1: 0.7990 - specificity: 0.9975 - val_accuracy: 0.4382 - val_auc_1: 0.9440 - val_dice_coef_oc: 0.9948 - val_dice_coef_od: 0.9901 - val_dice_coefficient: 0.6886 - val_loss: 0.3395 - val_mean_io_u_2: 0.5072 - val_precision_1: 0.6389 - val_recall_1: 0.7611 - val_specificity: 0.9966\n",
            "Epoch 113/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4296 - auc_1: 0.9655 - dice_coef_oc: 0.9937 - dice_coef_od: 0.9900 - dice_coefficient: 0.7549 - loss: 0.2642 - mean_io_u_2: 0.5005 - precision_1: 0.7268 - recall_1: 0.8057 - specificity: 0.9975 - val_accuracy: 0.4390 - val_auc_1: 0.9427 - val_dice_coef_oc: 0.9948 - val_dice_coef_od: 0.9901 - val_dice_coefficient: 0.6954 - val_loss: 0.3318 - val_mean_io_u_2: 0.5081 - val_precision_1: 0.6521 - val_recall_1: 0.7571 - val_specificity: 0.9968\n",
            "Epoch 114/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.4297 - auc_1: 0.9608 - dice_coef_oc: 0.9938 - dice_coef_od: 0.9901 - dice_coefficient: 0.7448 - loss: 0.2748 - mean_io_u_2: 0.5024 - precision_1: 0.7173 - recall_1: 0.7928 - specificity: 0.9975 - val_accuracy: 0.4284 - val_auc_1: 0.9337 - val_dice_coef_oc: 0.9946 - val_dice_coef_od: 0.9903 - val_dice_coefficient: 0.6779 - val_loss: 0.3510 - val_mean_io_u_2: 0.5104 - val_precision_1: 0.6404 - val_recall_1: 0.7283 - val_specificity: 0.9967\n",
            "Epoch 115/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.4288 - auc_1: 0.9650 - dice_coef_oc: 0.9934 - dice_coef_od: 0.9900 - dice_coefficient: 0.7579 - loss: 0.2606 - mean_io_u_2: 0.5009 - precision_1: 0.7291 - recall_1: 0.8094 - specificity: 0.9976 - val_accuracy: 0.4155 - val_auc_1: 0.9285 - val_dice_coef_oc: 0.9944 - val_dice_coef_od: 0.9903 - val_dice_coefficient: 0.6918 - val_loss: 0.3354 - val_mean_io_u_2: 0.5038 - val_precision_1: 0.6837 - val_recall_1: 0.7173 - val_specificity: 0.9973\n",
            "Epoch 116/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.4298 - auc_1: 0.9629 - dice_coef_oc: 0.9933 - dice_coef_od: 0.9900 - dice_coefficient: 0.7576 - loss: 0.2613 - mean_io_u_2: 0.5010 - precision_1: 0.7302 - recall_1: 0.8042 - specificity: 0.9976 - val_accuracy: 0.4250 - val_auc_1: 0.9314 - val_dice_coef_oc: 0.9952 - val_dice_coef_od: 0.9900 - val_dice_coefficient: 0.6890 - val_loss: 0.3378 - val_mean_io_u_2: 0.5025 - val_precision_1: 0.6724 - val_recall_1: 0.7208 - val_specificity: 0.9972\n",
            "Epoch 117/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4296 - auc_1: 0.9664 - dice_coef_oc: 0.9937 - dice_coef_od: 0.9902 - dice_coefficient: 0.7622 - loss: 0.2554 - mean_io_u_2: 0.4996 - precision_1: 0.7349 - recall_1: 0.8125 - specificity: 0.9977 - val_accuracy: 0.4169 - val_auc_1: 0.9280 - val_dice_coef_oc: 0.9945 - val_dice_coef_od: 0.9908 - val_dice_coefficient: 0.6886 - val_loss: 0.3387 - val_mean_io_u_2: 0.5036 - val_precision_1: 0.6790 - val_recall_1: 0.7082 - val_specificity: 0.9973\n",
            "Epoch 118/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4289 - auc_1: 0.9593 - dice_coef_oc: 0.9939 - dice_coef_od: 0.9901 - dice_coefficient: 0.7513 - loss: 0.2681 - mean_io_u_2: 0.5013 - precision_1: 0.7288 - recall_1: 0.7941 - specificity: 0.9976 - val_accuracy: 0.4358 - val_auc_1: 0.9298 - val_dice_coef_oc: 0.9946 - val_dice_coef_od: 0.9909 - val_dice_coefficient: 0.6987 - val_loss: 0.3267 - val_mean_io_u_2: 0.5039 - val_precision_1: 0.6931 - val_recall_1: 0.7198 - val_specificity: 0.9974\n",
            "Epoch 119/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.4293 - auc_1: 0.9615 - dice_coef_oc: 0.9939 - dice_coef_od: 0.9903 - dice_coefficient: 0.7575 - loss: 0.2614 - mean_io_u_2: 0.4995 - precision_1: 0.7344 - recall_1: 0.7996 - specificity: 0.9977 - val_accuracy: 0.4226 - val_auc_1: 0.9303 - val_dice_coef_oc: 0.9953 - val_dice_coef_od: 0.9904 - val_dice_coefficient: 0.6909 - val_loss: 0.3361 - val_mean_io_u_2: 0.5057 - val_precision_1: 0.6781 - val_recall_1: 0.7218 - val_specificity: 0.9973\n",
            "Epoch 120/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4292 - auc_1: 0.9642 - dice_coef_oc: 0.9942 - dice_coef_od: 0.9905 - dice_coefficient: 0.7513 - loss: 0.2678 - mean_io_u_2: 0.4991 - precision_1: 0.7225 - recall_1: 0.8025 - specificity: 0.9975 - val_accuracy: 0.4146 - val_auc_1: 0.9313 - val_dice_coef_oc: 0.9955 - val_dice_coef_od: 0.9905 - val_dice_coefficient: 0.6869 - val_loss: 0.3409 - val_mean_io_u_2: 0.5032 - val_precision_1: 0.6654 - val_recall_1: 0.7207 - val_specificity: 0.9971\n",
            "Epoch 121/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4284 - auc_1: 0.9646 - dice_coef_oc: 0.9943 - dice_coef_od: 0.9906 - dice_coefficient: 0.7589 - loss: 0.2593 - mean_io_u_2: 0.5002 - precision_1: 0.7327 - recall_1: 0.8075 - specificity: 0.9977 - val_accuracy: 0.4242 - val_auc_1: 0.9340 - val_dice_coef_oc: 0.9951 - val_dice_coef_od: 0.9911 - val_dice_coefficient: 0.6972 - val_loss: 0.3284 - val_mean_io_u_2: 0.5055 - val_precision_1: 0.6819 - val_recall_1: 0.7239 - val_specificity: 0.9973\n",
            "Epoch 122/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.4286 - auc_1: 0.9646 - dice_coef_oc: 0.9945 - dice_coef_od: 0.9908 - dice_coefficient: 0.7620 - loss: 0.2560 - mean_io_u_2: 0.4997 - precision_1: 0.7368 - recall_1: 0.8069 - specificity: 0.9977 - val_accuracy: 0.4305 - val_auc_1: 0.9356 - val_dice_coef_oc: 0.9951 - val_dice_coef_od: 0.9909 - val_dice_coefficient: 0.6936 - val_loss: 0.3330 - val_mean_io_u_2: 0.5077 - val_precision_1: 0.6693 - val_recall_1: 0.7306 - val_specificity: 0.9971\n",
            "Epoch 123/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4294 - auc_1: 0.9618 - dice_coef_oc: 0.9945 - dice_coef_od: 0.9907 - dice_coefficient: 0.7526 - loss: 0.2661 - mean_io_u_2: 0.5013 - precision_1: 0.7292 - recall_1: 0.7984 - specificity: 0.9977 - val_accuracy: 0.4253 - val_auc_1: 0.9267 - val_dice_coef_oc: 0.9952 - val_dice_coef_od: 0.9909 - val_dice_coefficient: 0.6924 - val_loss: 0.3334 - val_mean_io_u_2: 0.5033 - val_precision_1: 0.6927 - val_recall_1: 0.7073 - val_specificity: 0.9975\n",
            "Epoch 124/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4292 - auc_1: 0.9623 - dice_coef_oc: 0.9946 - dice_coef_od: 0.9908 - dice_coefficient: 0.7562 - loss: 0.2624 - mean_io_u_2: 0.5011 - precision_1: 0.7290 - recall_1: 0.8048 - specificity: 0.9977 - val_accuracy: 0.4254 - val_auc_1: 0.9351 - val_dice_coef_oc: 0.9953 - val_dice_coef_od: 0.9912 - val_dice_coefficient: 0.6917 - val_loss: 0.3343 - val_mean_io_u_2: 0.5040 - val_precision_1: 0.6703 - val_recall_1: 0.7253 - val_specificity: 0.9971\n",
            "Epoch 125/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.4283 - auc_1: 0.9662 - dice_coef_oc: 0.9945 - dice_coef_od: 0.9907 - dice_coefficient: 0.7730 - loss: 0.2442 - mean_io_u_2: 0.4991 - precision_1: 0.7469 - recall_1: 0.8159 - specificity: 0.9978 - val_accuracy: 0.4168 - val_auc_1: 0.9332 - val_dice_coef_oc: 0.9953 - val_dice_coef_od: 0.9914 - val_dice_coefficient: 0.6982 - val_loss: 0.3274 - val_mean_io_u_2: 0.5033 - val_precision_1: 0.6924 - val_recall_1: 0.7203 - val_specificity: 0.9974\n",
            "Epoch 126/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4289 - auc_1: 0.9648 - dice_coef_oc: 0.9946 - dice_coef_od: 0.9908 - dice_coefficient: 0.7612 - loss: 0.2571 - mean_io_u_2: 0.4994 - precision_1: 0.7333 - recall_1: 0.8094 - specificity: 0.9976 - val_accuracy: 0.4266 - val_auc_1: 0.9213 - val_dice_coef_oc: 0.9953 - val_dice_coef_od: 0.9907 - val_dice_coefficient: 0.6837 - val_loss: 0.3441 - val_mean_io_u_2: 0.5035 - val_precision_1: 0.6803 - val_recall_1: 0.6980 - val_specificity: 0.9974\n",
            "Epoch 127/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4300 - auc_1: 0.9639 - dice_coef_oc: 0.9944 - dice_coef_od: 0.9909 - dice_coefficient: 0.7609 - loss: 0.2577 - mean_io_u_2: 0.4995 - precision_1: 0.7322 - recall_1: 0.8096 - specificity: 0.9977 - val_accuracy: 0.4142 - val_auc_1: 0.9287 - val_dice_coef_oc: 0.9956 - val_dice_coef_od: 0.9913 - val_dice_coefficient: 0.6805 - val_loss: 0.3470 - val_mean_io_u_2: 0.5033 - val_precision_1: 0.6641 - val_recall_1: 0.7117 - val_specificity: 0.9971\n",
            "Epoch 128/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.4285 - auc_1: 0.9667 - dice_coef_oc: 0.9948 - dice_coef_od: 0.9909 - dice_coefficient: 0.7716 - loss: 0.2452 - mean_io_u_2: 0.4992 - precision_1: 0.7472 - recall_1: 0.8162 - specificity: 0.9978 - val_accuracy: 0.4306 - val_auc_1: 0.9387 - val_dice_coef_oc: 0.9955 - val_dice_coef_od: 0.9914 - val_dice_coefficient: 0.6955 - val_loss: 0.3326 - val_mean_io_u_2: 0.5083 - val_precision_1: 0.6601 - val_recall_1: 0.7474 - val_specificity: 0.9969\n",
            "Epoch 129/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4290 - auc_1: 0.9685 - dice_coef_oc: 0.9948 - dice_coef_od: 0.9910 - dice_coefficient: 0.7707 - loss: 0.2462 - mean_io_u_2: 0.4992 - precision_1: 0.7426 - recall_1: 0.8203 - specificity: 0.9978 - val_accuracy: 0.4062 - val_auc_1: 0.9319 - val_dice_coef_oc: 0.9957 - val_dice_coef_od: 0.9913 - val_dice_coefficient: 0.6943 - val_loss: 0.3338 - val_mean_io_u_2: 0.5082 - val_precision_1: 0.6684 - val_recall_1: 0.7321 - val_specificity: 0.9971\n",
            "Epoch 130/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4296 - auc_1: 0.9619 - dice_coef_oc: 0.9947 - dice_coef_od: 0.9911 - dice_coefficient: 0.7547 - loss: 0.2644 - mean_io_u_2: 0.5008 - precision_1: 0.7274 - recall_1: 0.8036 - specificity: 0.9976 - val_accuracy: 0.4256 - val_auc_1: 0.9338 - val_dice_coef_oc: 0.9956 - val_dice_coef_od: 0.9913 - val_dice_coefficient: 0.6916 - val_loss: 0.3361 - val_mean_io_u_2: 0.5059 - val_precision_1: 0.6623 - val_recall_1: 0.7369 - val_specificity: 0.9970\n",
            "Epoch 131/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4281 - auc_1: 0.9640 - dice_coef_oc: 0.9949 - dice_coef_od: 0.9912 - dice_coefficient: 0.7620 - loss: 0.2563 - mean_io_u_2: 0.5004 - precision_1: 0.7392 - recall_1: 0.8052 - specificity: 0.9977 - val_accuracy: 0.4213 - val_auc_1: 0.9303 - val_dice_coef_oc: 0.9958 - val_dice_coef_od: 0.9915 - val_dice_coefficient: 0.6867 - val_loss: 0.3400 - val_mean_io_u_2: 0.5025 - val_precision_1: 0.6677 - val_recall_1: 0.7175 - val_specificity: 0.9971\n",
            "Epoch 132/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.4297 - auc_1: 0.9646 - dice_coef_oc: 0.9948 - dice_coef_od: 0.9910 - dice_coefficient: 0.7692 - loss: 0.2483 - mean_io_u_2: 0.5010 - precision_1: 0.7452 - recall_1: 0.8127 - specificity: 0.9978 - val_accuracy: 0.4201 - val_auc_1: 0.9379 - val_dice_coef_oc: 0.9957 - val_dice_coef_od: 0.9915 - val_dice_coefficient: 0.6942 - val_loss: 0.3329 - val_mean_io_u_2: 0.5045 - val_precision_1: 0.6558 - val_recall_1: 0.7478 - val_specificity: 0.9969\n",
            "Epoch 133/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4304 - auc_1: 0.9673 - dice_coef_oc: 0.9948 - dice_coef_od: 0.9912 - dice_coefficient: 0.7669 - loss: 0.2505 - mean_io_u_2: 0.4992 - precision_1: 0.7396 - recall_1: 0.8168 - specificity: 0.9977 - val_accuracy: 0.4100 - val_auc_1: 0.9319 - val_dice_coef_oc: 0.9959 - val_dice_coef_od: 0.9917 - val_dice_coefficient: 0.6930 - val_loss: 0.3342 - val_mean_io_u_2: 0.5019 - val_precision_1: 0.6728 - val_recall_1: 0.7261 - val_specificity: 0.9972\n",
            "Epoch 134/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4298 - auc_1: 0.9643 - dice_coef_oc: 0.9950 - dice_coef_od: 0.9913 - dice_coefficient: 0.7631 - loss: 0.2552 - mean_io_u_2: 0.4989 - precision_1: 0.7359 - recall_1: 0.8110 - specificity: 0.9977 - val_accuracy: 0.4099 - val_auc_1: 0.9203 - val_dice_coef_oc: 0.9957 - val_dice_coef_od: 0.9919 - val_dice_coefficient: 0.6817 - val_loss: 0.3456 - val_mean_io_u_2: 0.5000 - val_precision_1: 0.6892 - val_recall_1: 0.6862 - val_specificity: 0.9975\n",
            "Epoch 135/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4304 - auc_1: 0.9612 - dice_coef_oc: 0.9949 - dice_coef_od: 0.9913 - dice_coefficient: 0.7578 - loss: 0.2611 - mean_io_u_2: 0.4993 - precision_1: 0.7310 - recall_1: 0.8017 - specificity: 0.9977 - val_accuracy: 0.4004 - val_auc_1: 0.9273 - val_dice_coef_oc: 0.9958 - val_dice_coef_od: 0.9919 - val_dice_coefficient: 0.6892 - val_loss: 0.3389 - val_mean_io_u_2: 0.5037 - val_precision_1: 0.6805 - val_recall_1: 0.7126 - val_specificity: 0.9973\n",
            "Epoch 136/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4295 - auc_1: 0.9646 - dice_coef_oc: 0.9949 - dice_coef_od: 0.9913 - dice_coefficient: 0.7692 - loss: 0.2484 - mean_io_u_2: 0.5001 - precision_1: 0.7462 - recall_1: 0.8101 - specificity: 0.9978 - val_accuracy: 0.3914 - val_auc_1: 0.9298 - val_dice_coef_oc: 0.9959 - val_dice_coef_od: 0.9917 - val_dice_coefficient: 0.6876 - val_loss: 0.3407 - val_mean_io_u_2: 0.5022 - val_precision_1: 0.6677 - val_recall_1: 0.7200 - val_specificity: 0.9971\n",
            "Epoch 137/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.4298 - auc_1: 0.9645 - dice_coef_oc: 0.9951 - dice_coef_od: 0.9915 - dice_coefficient: 0.7663 - loss: 0.2520 - mean_io_u_2: 0.4996 - precision_1: 0.7425 - recall_1: 0.8086 - specificity: 0.9977 - val_accuracy: 0.4409 - val_auc_1: 0.9309 - val_dice_coef_oc: 0.9959 - val_dice_coef_od: 0.9918 - val_dice_coefficient: 0.6951 - val_loss: 0.3314 - val_mean_io_u_2: 0.5017 - val_precision_1: 0.6813 - val_recall_1: 0.7212 - val_specificity: 0.9973\n",
            "Epoch 138/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4311 - auc_1: 0.9654 - dice_coef_oc: 0.9952 - dice_coef_od: 0.9914 - dice_coefficient: 0.7702 - loss: 0.2473 - mean_io_u_2: 0.4999 - precision_1: 0.7472 - recall_1: 0.8135 - specificity: 0.9978 - val_accuracy: 0.4138 - val_auc_1: 0.9384 - val_dice_coef_oc: 0.9961 - val_dice_coef_od: 0.9918 - val_dice_coefficient: 0.6997 - val_loss: 0.3267 - val_mean_io_u_2: 0.5037 - val_precision_1: 0.6679 - val_recall_1: 0.7440 - val_specificity: 0.9970\n",
            "Epoch 139/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4301 - auc_1: 0.9642 - dice_coef_oc: 0.9952 - dice_coef_od: 0.9914 - dice_coefficient: 0.7640 - loss: 0.2543 - mean_io_u_2: 0.4999 - precision_1: 0.7370 - recall_1: 0.8088 - specificity: 0.9977 - val_accuracy: 0.4384 - val_auc_1: 0.9349 - val_dice_coef_oc: 0.9958 - val_dice_coef_od: 0.9915 - val_dice_coefficient: 0.6964 - val_loss: 0.3303 - val_mean_io_u_2: 0.5031 - val_precision_1: 0.6729 - val_recall_1: 0.7313 - val_specificity: 0.9972\n",
            "Epoch 140/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.4312 - auc_1: 0.9666 - dice_coef_oc: 0.9952 - dice_coef_od: 0.9912 - dice_coefficient: 0.7668 - loss: 0.2508 - mean_io_u_2: 0.4981 - precision_1: 0.7401 - recall_1: 0.8139 - specificity: 0.9977 - val_accuracy: 0.4333 - val_auc_1: 0.9374 - val_dice_coef_oc: 0.9962 - val_dice_coef_od: 0.9915 - val_dice_coefficient: 0.6943 - val_loss: 0.3318 - val_mean_io_u_2: 0.5034 - val_precision_1: 0.6699 - val_recall_1: 0.7298 - val_specificity: 0.9971\n",
            "Epoch 141/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.4305 - auc_1: 0.9669 - dice_coef_oc: 0.9952 - dice_coef_od: 0.9914 - dice_coefficient: 0.7757 - loss: 0.2410 - mean_io_u_2: 0.4992 - precision_1: 0.7505 - recall_1: 0.8203 - specificity: 0.9978 - val_accuracy: 0.4070 - val_auc_1: 0.9339 - val_dice_coef_oc: 0.9962 - val_dice_coef_od: 0.9916 - val_dice_coefficient: 0.6907 - val_loss: 0.3365 - val_mean_io_u_2: 0.5073 - val_precision_1: 0.6676 - val_recall_1: 0.7266 - val_specificity: 0.9971\n",
            "Epoch 142/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.4297 - auc_1: 0.9631 - dice_coef_oc: 0.9953 - dice_coef_od: 0.9913 - dice_coefficient: 0.7629 - loss: 0.2555 - mean_io_u_2: 0.4984 - precision_1: 0.7387 - recall_1: 0.8047 - specificity: 0.9977 - val_accuracy: 0.4287 - val_auc_1: 0.9428 - val_dice_coef_oc: 0.9963 - val_dice_coef_od: 0.9918 - val_dice_coefficient: 0.7013 - val_loss: 0.3241 - val_mean_io_u_2: 0.5035 - val_precision_1: 0.6707 - val_recall_1: 0.7473 - val_specificity: 0.9971\n",
            "Epoch 143/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4300 - auc_1: 0.9671 - dice_coef_oc: 0.9955 - dice_coef_od: 0.9917 - dice_coefficient: 0.7687 - loss: 0.2487 - mean_io_u_2: 0.4989 - precision_1: 0.7401 - recall_1: 0.8166 - specificity: 0.9977 - val_accuracy: 0.4345 - val_auc_1: 0.9315 - val_dice_coef_oc: 0.9961 - val_dice_coef_od: 0.9919 - val_dice_coefficient: 0.6891 - val_loss: 0.3380 - val_mean_io_u_2: 0.5035 - val_precision_1: 0.6656 - val_recall_1: 0.7230 - val_specificity: 0.9971\n",
            "Epoch 144/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4304 - auc_1: 0.9646 - dice_coef_oc: 0.9955 - dice_coef_od: 0.9917 - dice_coefficient: 0.7662 - loss: 0.2514 - mean_io_u_2: 0.4973 - precision_1: 0.7431 - recall_1: 0.8097 - specificity: 0.9977 - val_accuracy: 0.4405 - val_auc_1: 0.9304 - val_dice_coef_oc: 0.9963 - val_dice_coef_od: 0.9917 - val_dice_coefficient: 0.6923 - val_loss: 0.3340 - val_mean_io_u_2: 0.5023 - val_precision_1: 0.6774 - val_recall_1: 0.7223 - val_specificity: 0.9972\n",
            "Epoch 145/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.4318 - auc_1: 0.9669 - dice_coef_oc: 0.9954 - dice_coef_od: 0.9918 - dice_coefficient: 0.7718 - loss: 0.2452 - mean_io_u_2: 0.4976 - precision_1: 0.7499 - recall_1: 0.8154 - specificity: 0.9978 - val_accuracy: 0.4121 - val_auc_1: 0.9364 - val_dice_coef_oc: 0.9958 - val_dice_coef_od: 0.9916 - val_dice_coefficient: 0.6972 - val_loss: 0.3294 - val_mean_io_u_2: 0.5031 - val_precision_1: 0.6779 - val_recall_1: 0.7314 - val_specificity: 0.9972\n",
            "Epoch 146/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4298 - auc_1: 0.9653 - dice_coef_oc: 0.9954 - dice_coef_od: 0.9917 - dice_coefficient: 0.7698 - loss: 0.2475 - mean_io_u_2: 0.5003 - precision_1: 0.7460 - recall_1: 0.8147 - specificity: 0.9978 - val_accuracy: 0.4386 - val_auc_1: 0.9422 - val_dice_coef_oc: 0.9964 - val_dice_coef_od: 0.9918 - val_dice_coefficient: 0.6860 - val_loss: 0.3428 - val_mean_io_u_2: 0.5098 - val_precision_1: 0.6352 - val_recall_1: 0.7563 - val_specificity: 0.9965\n",
            "Epoch 147/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4306 - auc_1: 0.9658 - dice_coef_oc: 0.9955 - dice_coef_od: 0.9919 - dice_coefficient: 0.7656 - loss: 0.2524 - mean_io_u_2: 0.4997 - precision_1: 0.7349 - recall_1: 0.8153 - specificity: 0.9976 - val_accuracy: 0.4216 - val_auc_1: 0.9345 - val_dice_coef_oc: 0.9959 - val_dice_coef_od: 0.9921 - val_dice_coefficient: 0.6839 - val_loss: 0.3449 - val_mean_io_u_2: 0.5099 - val_precision_1: 0.6464 - val_recall_1: 0.7401 - val_specificity: 0.9968\n",
            "Epoch 148/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4292 - auc_1: 0.9668 - dice_coef_oc: 0.9955 - dice_coef_od: 0.9921 - dice_coefficient: 0.7739 - loss: 0.2430 - mean_io_u_2: 0.4993 - precision_1: 0.7473 - recall_1: 0.8191 - specificity: 0.9978 - val_accuracy: 0.4315 - val_auc_1: 0.9459 - val_dice_coef_oc: 0.9967 - val_dice_coef_od: 0.9921 - val_dice_coefficient: 0.6938 - val_loss: 0.3338 - val_mean_io_u_2: 0.5056 - val_precision_1: 0.6383 - val_recall_1: 0.7709 - val_specificity: 0.9965\n",
            "Epoch 149/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.4293 - auc_1: 0.9672 - dice_coef_oc: 0.9957 - dice_coef_od: 0.9923 - dice_coefficient: 0.7690 - loss: 0.2481 - mean_io_u_2: 0.4988 - precision_1: 0.7400 - recall_1: 0.8196 - specificity: 0.9977 - val_accuracy: 0.4266 - val_auc_1: 0.9391 - val_dice_coef_oc: 0.9965 - val_dice_coef_od: 0.9924 - val_dice_coefficient: 0.6968 - val_loss: 0.3298 - val_mean_io_u_2: 0.5042 - val_precision_1: 0.6640 - val_recall_1: 0.7446 - val_specificity: 0.9970\n",
            "Epoch 150/150\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4291 - auc_1: 0.9672 - dice_coef_oc: 0.9958 - dice_coef_od: 0.9920 - dice_coefficient: 0.7713 - loss: 0.2460 - mean_io_u_2: 0.4982 - precision_1: 0.7455 - recall_1: 0.8167 - specificity: 0.9978 - val_accuracy: 0.4299 - val_auc_1: 0.9446 - val_dice_coef_oc: 0.9967 - val_dice_coef_od: 0.9922 - val_dice_coefficient: 0.7035 - val_loss: 0.3221 - val_mean_io_u_2: 0.5025 - val_precision_1: 0.6654 - val_recall_1: 0.7582 - val_specificity: 0.9969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_1.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbAeu8hcdbtJ",
        "outputId": "7eb2b512-b4e9-4be8-a72c-8ec66131983d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(368, 256, 256, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = m2.fit(x_train_1, y_train_1, batch_size=2, epochs=50, validation_data = (x_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6sZSczFOcoJ",
        "outputId": "defb1a4f-be05-4cc9-c05d-8e976a06dbc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4372 - auc_1: 0.9725 - dice_coef_oc: 0.9991 - dice_coef_od: 0.9969 - dice_coefficient: 0.8197 - loss: 0.1934 - mean_io_u_2: 0.4947 - precision_1: 0.8020 - recall_1: 0.8500 - specificity: 0.9983 - val_accuracy: 0.4431 - val_auc_1: 0.9382 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9969 - val_dice_coefficient: 0.7029 - val_loss: 0.3249 - val_mean_io_u_2: 0.4982 - val_precision_1: 0.6561 - val_recall_1: 0.7618 - val_specificity: 0.9968\n",
            "Epoch 2/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4361 - auc_1: 0.9726 - dice_coef_oc: 0.9991 - dice_coef_od: 0.9970 - dice_coefficient: 0.8152 - loss: 0.1985 - mean_io_u_2: 0.4950 - precision_1: 0.7950 - recall_1: 0.8498 - specificity: 0.9982 - val_accuracy: 0.4540 - val_auc_1: 0.9287 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.7063 - val_loss: 0.3203 - val_mean_io_u_2: 0.4974 - val_precision_1: 0.6815 - val_recall_1: 0.7363 - val_specificity: 0.9972\n",
            "Epoch 3/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.4360 - auc_1: 0.9692 - dice_coef_oc: 0.9991 - dice_coef_od: 0.9969 - dice_coefficient: 0.8109 - loss: 0.2032 - mean_io_u_2: 0.4944 - precision_1: 0.7930 - recall_1: 0.8424 - specificity: 0.9982 - val_accuracy: 0.4484 - val_auc_1: 0.9301 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9969 - val_dice_coefficient: 0.7030 - val_loss: 0.3243 - val_mean_io_u_2: 0.4972 - val_precision_1: 0.6743 - val_recall_1: 0.7388 - val_specificity: 0.9971\n",
            "Epoch 4/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4371 - auc_1: 0.9675 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9968 - dice_coefficient: 0.8066 - loss: 0.2079 - mean_io_u_2: 0.4947 - precision_1: 0.7898 - recall_1: 0.8361 - specificity: 0.9982 - val_accuracy: 0.4440 - val_auc_1: 0.9343 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.7162 - val_loss: 0.3095 - val_mean_io_u_2: 0.4979 - val_precision_1: 0.6906 - val_recall_1: 0.7514 - val_specificity: 0.9973\n",
            "Epoch 5/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4354 - auc_1: 0.9717 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9968 - dice_coefficient: 0.8136 - loss: 0.1999 - mean_io_u_2: 0.4949 - precision_1: 0.7956 - recall_1: 0.8480 - specificity: 0.9983 - val_accuracy: 0.4408 - val_auc_1: 0.9322 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.7027 - val_loss: 0.3252 - val_mean_io_u_2: 0.4980 - val_precision_1: 0.6671 - val_recall_1: 0.7425 - val_specificity: 0.9970\n",
            "Epoch 6/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4359 - auc_1: 0.9705 - dice_coef_oc: 0.9991 - dice_coef_od: 0.9968 - dice_coefficient: 0.8115 - loss: 0.2025 - mean_io_u_2: 0.4948 - precision_1: 0.7933 - recall_1: 0.8435 - specificity: 0.9982 - val_accuracy: 0.4547 - val_auc_1: 0.9225 - val_dice_coef_oc: 0.9988 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.7059 - val_loss: 0.3200 - val_mean_io_u_2: 0.4965 - val_precision_1: 0.7070 - val_recall_1: 0.7143 - val_specificity: 0.9976\n",
            "Epoch 7/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4362 - auc_1: 0.9685 - dice_coef_oc: 0.9990 - dice_coef_od: 0.9969 - dice_coefficient: 0.8122 - loss: 0.2017 - mean_io_u_2: 0.4948 - precision_1: 0.7988 - recall_1: 0.8401 - specificity: 0.9983 - val_accuracy: 0.4367 - val_auc_1: 0.9226 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.6993 - val_loss: 0.3285 - val_mean_io_u_2: 0.4966 - val_precision_1: 0.6866 - val_recall_1: 0.7190 - val_specificity: 0.9974\n",
            "Epoch 8/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4357 - auc_1: 0.9723 - dice_coef_oc: 0.9988 - dice_coef_od: 0.9969 - dice_coefficient: 0.8098 - loss: 0.2037 - mean_io_u_2: 0.4950 - precision_1: 0.7893 - recall_1: 0.8475 - specificity: 0.9982 - val_accuracy: 0.4371 - val_auc_1: 0.9245 - val_dice_coef_oc: 0.9992 - val_dice_coef_od: 0.9969 - val_dice_coefficient: 0.7091 - val_loss: 0.3175 - val_mean_io_u_2: 0.4969 - val_precision_1: 0.6989 - val_recall_1: 0.7233 - val_specificity: 0.9975\n",
            "Epoch 9/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4359 - auc_1: 0.9703 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9970 - dice_coefficient: 0.8131 - loss: 0.2007 - mean_io_u_2: 0.4949 - precision_1: 0.7962 - recall_1: 0.8443 - specificity: 0.9983 - val_accuracy: 0.4308 - val_auc_1: 0.9255 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.7047 - val_loss: 0.3214 - val_mean_io_u_2: 0.4967 - val_precision_1: 0.6985 - val_recall_1: 0.7199 - val_specificity: 0.9975\n",
            "Epoch 10/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4361 - auc_1: 0.9684 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9969 - dice_coefficient: 0.8156 - loss: 0.1982 - mean_io_u_2: 0.4946 - precision_1: 0.8028 - recall_1: 0.8427 - specificity: 0.9983 - val_accuracy: 0.4449 - val_auc_1: 0.9209 - val_dice_coef_oc: 0.9990 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.7025 - val_loss: 0.3245 - val_mean_io_u_2: 0.4969 - val_precision_1: 0.6963 - val_recall_1: 0.7136 - val_specificity: 0.9975\n",
            "Epoch 11/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4362 - auc_1: 0.9668 - dice_coef_oc: 0.9991 - dice_coef_od: 0.9969 - dice_coefficient: 0.7983 - loss: 0.2170 - mean_io_u_2: 0.4947 - precision_1: 0.7808 - recall_1: 0.8315 - specificity: 0.9981 - val_accuracy: 0.4344 - val_auc_1: 0.9330 - val_dice_coef_oc: 0.9989 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7045 - val_loss: 0.3235 - val_mean_io_u_2: 0.4975 - val_precision_1: 0.6631 - val_recall_1: 0.7479 - val_specificity: 0.9970\n",
            "Epoch 12/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4348 - auc_1: 0.9704 - dice_coef_oc: 0.9991 - dice_coef_od: 0.9969 - dice_coefficient: 0.8179 - loss: 0.1954 - mean_io_u_2: 0.4951 - precision_1: 0.8008 - recall_1: 0.8489 - specificity: 0.9983 - val_accuracy: 0.4369 - val_auc_1: 0.9329 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7135 - val_loss: 0.3133 - val_mean_io_u_2: 0.4986 - val_precision_1: 0.6859 - val_recall_1: 0.7506 - val_specificity: 0.9972\n",
            "Epoch 13/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4351 - auc_1: 0.9710 - dice_coef_oc: 0.9991 - dice_coef_od: 0.9969 - dice_coefficient: 0.8140 - loss: 0.1997 - mean_io_u_2: 0.4953 - precision_1: 0.7945 - recall_1: 0.8479 - specificity: 0.9983 - val_accuracy: 0.4354 - val_auc_1: 0.9311 - val_dice_coef_oc: 0.9991 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.7150 - val_loss: 0.3106 - val_mean_io_u_2: 0.4971 - val_precision_1: 0.6962 - val_recall_1: 0.7427 - val_specificity: 0.9974\n",
            "Epoch 14/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4353 - auc_1: 0.9683 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9970 - dice_coefficient: 0.8129 - loss: 0.2011 - mean_io_u_2: 0.4947 - precision_1: 0.7980 - recall_1: 0.8401 - specificity: 0.9983 - val_accuracy: 0.4290 - val_auc_1: 0.9274 - val_dice_coef_oc: 0.9990 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7095 - val_loss: 0.3171 - val_mean_io_u_2: 0.4971 - val_precision_1: 0.6932 - val_recall_1: 0.7310 - val_specificity: 0.9974\n",
            "Epoch 15/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.4355 - auc_1: 0.9705 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9970 - dice_coefficient: 0.8139 - loss: 0.1999 - mean_io_u_2: 0.4947 - precision_1: 0.7945 - recall_1: 0.8456 - specificity: 0.9983 - val_accuracy: 0.4347 - val_auc_1: 0.9379 - val_dice_coef_oc: 0.9992 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7200 - val_loss: 0.3060 - val_mean_io_u_2: 0.4972 - val_precision_1: 0.6841 - val_recall_1: 0.7640 - val_specificity: 0.9972\n",
            "Epoch 16/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4355 - auc_1: 0.9681 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9970 - dice_coefficient: 0.8081 - loss: 0.2065 - mean_io_u_2: 0.4947 - precision_1: 0.7877 - recall_1: 0.8408 - specificity: 0.9982 - val_accuracy: 0.4385 - val_auc_1: 0.9322 - val_dice_coef_oc: 0.9992 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.7181 - val_loss: 0.3077 - val_mean_io_u_2: 0.4973 - val_precision_1: 0.6957 - val_recall_1: 0.7497 - val_specificity: 0.9974\n",
            "Epoch 17/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4346 - auc_1: 0.9716 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9970 - dice_coefficient: 0.8169 - loss: 0.1966 - mean_io_u_2: 0.4949 - precision_1: 0.7994 - recall_1: 0.8481 - specificity: 0.9983 - val_accuracy: 0.4599 - val_auc_1: 0.9160 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.7037 - val_loss: 0.3225 - val_mean_io_u_2: 0.4966 - val_precision_1: 0.7184 - val_recall_1: 0.7026 - val_specificity: 0.9978\n",
            "Epoch 18/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4360 - auc_1: 0.9708 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9969 - dice_coefficient: 0.8089 - loss: 0.2049 - mean_io_u_2: 0.4947 - precision_1: 0.7916 - recall_1: 0.8414 - specificity: 0.9983 - val_accuracy: 0.4257 - val_auc_1: 0.9338 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.7134 - val_loss: 0.3127 - val_mean_io_u_2: 0.4978 - val_precision_1: 0.6853 - val_recall_1: 0.7530 - val_specificity: 0.9972\n",
            "Epoch 19/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4345 - auc_1: 0.9711 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9969 - dice_coefficient: 0.8135 - loss: 0.2003 - mean_io_u_2: 0.4950 - precision_1: 0.7947 - recall_1: 0.8458 - specificity: 0.9983 - val_accuracy: 0.4231 - val_auc_1: 0.9284 - val_dice_coef_oc: 0.9992 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.7037 - val_loss: 0.3237 - val_mean_io_u_2: 0.4971 - val_precision_1: 0.6787 - val_recall_1: 0.7354 - val_specificity: 0.9972\n",
            "Epoch 20/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4342 - auc_1: 0.9705 - dice_coef_oc: 0.9991 - dice_coef_od: 0.9969 - dice_coefficient: 0.8107 - loss: 0.2031 - mean_io_u_2: 0.4948 - precision_1: 0.7906 - recall_1: 0.8463 - specificity: 0.9982 - val_accuracy: 0.4545 - val_auc_1: 0.9278 - val_dice_coef_oc: 0.9990 - val_dice_coef_od: 0.9969 - val_dice_coefficient: 0.7106 - val_loss: 0.3156 - val_mean_io_u_2: 0.4973 - val_precision_1: 0.6909 - val_recall_1: 0.7398 - val_specificity: 0.9974\n",
            "Epoch 21/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.4350 - auc_1: 0.9680 - dice_coef_oc: 0.9991 - dice_coef_od: 0.9969 - dice_coefficient: 0.8087 - loss: 0.2057 - mean_io_u_2: 0.4949 - precision_1: 0.7901 - recall_1: 0.8406 - specificity: 0.9982 - val_accuracy: 0.4629 - val_auc_1: 0.9254 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.6998 - val_loss: 0.3275 - val_mean_io_u_2: 0.4973 - val_precision_1: 0.6848 - val_recall_1: 0.7240 - val_specificity: 0.9973\n",
            "Epoch 22/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4355 - auc_1: 0.9721 - dice_coef_oc: 0.9991 - dice_coef_od: 0.9969 - dice_coefficient: 0.8206 - loss: 0.1925 - mean_io_u_2: 0.4948 - precision_1: 0.8018 - recall_1: 0.8527 - specificity: 0.9983 - val_accuracy: 0.4306 - val_auc_1: 0.9309 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.7135 - val_loss: 0.3125 - val_mean_io_u_2: 0.4966 - val_precision_1: 0.6926 - val_recall_1: 0.7416 - val_specificity: 0.9974\n",
            "Epoch 23/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4351 - auc_1: 0.9678 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9970 - dice_coefficient: 0.8090 - loss: 0.2052 - mean_io_u_2: 0.4947 - precision_1: 0.7932 - recall_1: 0.8380 - specificity: 0.9983 - val_accuracy: 0.4158 - val_auc_1: 0.9255 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9969 - val_dice_coefficient: 0.7015 - val_loss: 0.3263 - val_mean_io_u_2: 0.4974 - val_precision_1: 0.6837 - val_recall_1: 0.7271 - val_specificity: 0.9973\n",
            "Epoch 24/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4355 - auc_1: 0.9703 - dice_coef_oc: 0.9991 - dice_coef_od: 0.9970 - dice_coefficient: 0.8153 - loss: 0.1984 - mean_io_u_2: 0.4946 - precision_1: 0.7988 - recall_1: 0.8457 - specificity: 0.9983 - val_accuracy: 0.4496 - val_auc_1: 0.9294 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9969 - val_dice_coefficient: 0.7093 - val_loss: 0.3166 - val_mean_io_u_2: 0.4977 - val_precision_1: 0.6892 - val_recall_1: 0.7364 - val_specificity: 0.9973\n",
            "Epoch 25/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4354 - auc_1: 0.9694 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9970 - dice_coefficient: 0.8171 - loss: 0.1968 - mean_io_u_2: 0.4949 - precision_1: 0.7991 - recall_1: 0.8468 - specificity: 0.9983 - val_accuracy: 0.4293 - val_auc_1: 0.9219 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9969 - val_dice_coefficient: 0.7019 - val_loss: 0.3253 - val_mean_io_u_2: 0.4965 - val_precision_1: 0.6954 - val_recall_1: 0.7184 - val_specificity: 0.9975\n",
            "Epoch 26/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4369 - auc_1: 0.9704 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9971 - dice_coefficient: 0.8124 - loss: 0.2013 - mean_io_u_2: 0.4946 - precision_1: 0.7959 - recall_1: 0.8445 - specificity: 0.9983 - val_accuracy: 0.4418 - val_auc_1: 0.9261 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7065 - val_loss: 0.3200 - val_mean_io_u_2: 0.4971 - val_precision_1: 0.6913 - val_recall_1: 0.7275 - val_specificity: 0.9974\n",
            "Epoch 27/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4366 - auc_1: 0.9703 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9971 - dice_coefficient: 0.8186 - loss: 0.1948 - mean_io_u_2: 0.4949 - precision_1: 0.8019 - recall_1: 0.8470 - specificity: 0.9983 - val_accuracy: 0.4411 - val_auc_1: 0.9194 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9969 - val_dice_coefficient: 0.7076 - val_loss: 0.3190 - val_mean_io_u_2: 0.4972 - val_precision_1: 0.7089 - val_recall_1: 0.7161 - val_specificity: 0.9976\n",
            "Epoch 28/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4380 - auc_1: 0.9692 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9971 - dice_coefficient: 0.8132 - loss: 0.2008 - mean_io_u_2: 0.4947 - precision_1: 0.7972 - recall_1: 0.8420 - specificity: 0.9983 - val_accuracy: 0.4271 - val_auc_1: 0.9178 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.6970 - val_loss: 0.3309 - val_mean_io_u_2: 0.4973 - val_precision_1: 0.6928 - val_recall_1: 0.7096 - val_specificity: 0.9975\n",
            "Epoch 29/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4372 - auc_1: 0.9681 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9971 - dice_coefficient: 0.8142 - loss: 0.1996 - mean_io_u_2: 0.4952 - precision_1: 0.8006 - recall_1: 0.8413 - specificity: 0.9984 - val_accuracy: 0.4179 - val_auc_1: 0.9316 - val_dice_coef_oc: 0.9995 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7147 - val_loss: 0.3118 - val_mean_io_u_2: 0.4976 - val_precision_1: 0.6910 - val_recall_1: 0.7462 - val_specificity: 0.9973\n",
            "Epoch 30/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4373 - auc_1: 0.9697 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9972 - dice_coefficient: 0.8142 - loss: 0.2001 - mean_io_u_2: 0.4945 - precision_1: 0.7971 - recall_1: 0.8445 - specificity: 0.9982 - val_accuracy: 0.4547 - val_auc_1: 0.9193 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7041 - val_loss: 0.3231 - val_mean_io_u_2: 0.4972 - val_precision_1: 0.6990 - val_recall_1: 0.7156 - val_specificity: 0.9975\n",
            "Epoch 31/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4365 - auc_1: 0.9709 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9972 - dice_coefficient: 0.8158 - loss: 0.1976 - mean_io_u_2: 0.4951 - precision_1: 0.7989 - recall_1: 0.8459 - specificity: 0.9983 - val_accuracy: 0.4283 - val_auc_1: 0.9252 - val_dice_coef_oc: 0.9992 - val_dice_coef_od: 0.9971 - val_dice_coefficient: 0.7041 - val_loss: 0.3226 - val_mean_io_u_2: 0.4967 - val_precision_1: 0.6911 - val_recall_1: 0.7241 - val_specificity: 0.9974\n",
            "Epoch 32/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4368 - auc_1: 0.9721 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9972 - dice_coefficient: 0.8194 - loss: 0.1937 - mean_io_u_2: 0.4946 - precision_1: 0.8030 - recall_1: 0.8498 - specificity: 0.9983 - val_accuracy: 0.4281 - val_auc_1: 0.9340 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9971 - val_dice_coefficient: 0.7158 - val_loss: 0.3106 - val_mean_io_u_2: 0.4970 - val_precision_1: 0.6861 - val_recall_1: 0.7530 - val_specificity: 0.9972\n",
            "Epoch 33/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4363 - auc_1: 0.9694 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9972 - dice_coefficient: 0.8125 - loss: 0.2013 - mean_io_u_2: 0.4945 - precision_1: 0.7942 - recall_1: 0.8450 - specificity: 0.9983 - val_accuracy: 0.4545 - val_auc_1: 0.9253 - val_dice_coef_oc: 0.9995 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.6995 - val_loss: 0.3276 - val_mean_io_u_2: 0.4969 - val_precision_1: 0.6771 - val_recall_1: 0.7283 - val_specificity: 0.9972\n",
            "Epoch 34/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4368 - auc_1: 0.9710 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9972 - dice_coefficient: 0.8182 - loss: 0.1951 - mean_io_u_2: 0.4948 - precision_1: 0.8039 - recall_1: 0.8449 - specificity: 0.9983 - val_accuracy: 0.4309 - val_auc_1: 0.9308 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.7117 - val_loss: 0.3148 - val_mean_io_u_2: 0.4972 - val_precision_1: 0.6898 - val_recall_1: 0.7437 - val_specificity: 0.9973\n",
            "Epoch 35/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4358 - auc_1: 0.9713 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9972 - dice_coefficient: 0.8160 - loss: 0.1973 - mean_io_u_2: 0.4947 - precision_1: 0.8005 - recall_1: 0.8482 - specificity: 0.9983 - val_accuracy: 0.4306 - val_auc_1: 0.9215 - val_dice_coef_oc: 0.9992 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.7059 - val_loss: 0.3209 - val_mean_io_u_2: 0.4968 - val_precision_1: 0.6997 - val_recall_1: 0.7182 - val_specificity: 0.9975\n",
            "Epoch 36/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4353 - auc_1: 0.9717 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9972 - dice_coefficient: 0.8204 - loss: 0.1925 - mean_io_u_2: 0.4944 - precision_1: 0.8041 - recall_1: 0.8508 - specificity: 0.9984 - val_accuracy: 0.4373 - val_auc_1: 0.9174 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.7020 - val_loss: 0.3250 - val_mean_io_u_2: 0.4967 - val_precision_1: 0.7087 - val_recall_1: 0.7054 - val_specificity: 0.9977\n",
            "Epoch 37/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4366 - auc_1: 0.9699 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9970 - dice_coefficient: 0.8206 - loss: 0.1929 - mean_io_u_2: 0.4946 - precision_1: 0.8063 - recall_1: 0.8478 - specificity: 0.9984 - val_accuracy: 0.4445 - val_auc_1: 0.9293 - val_dice_coef_oc: 0.9995 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.7119 - val_loss: 0.3145 - val_mean_io_u_2: 0.4968 - val_precision_1: 0.6904 - val_recall_1: 0.7422 - val_specificity: 0.9973\n",
            "Epoch 38/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4379 - auc_1: 0.9715 - dice_coef_oc: 0.9992 - dice_coef_od: 0.9971 - dice_coefficient: 0.8185 - loss: 0.1950 - mean_io_u_2: 0.4946 - precision_1: 0.7990 - recall_1: 0.8507 - specificity: 0.9983 - val_accuracy: 0.4397 - val_auc_1: 0.9280 - val_dice_coef_oc: 0.9992 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.7155 - val_loss: 0.3105 - val_mean_io_u_2: 0.4972 - val_precision_1: 0.7010 - val_recall_1: 0.7346 - val_specificity: 0.9975\n",
            "Epoch 39/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.4373 - auc_1: 0.9737 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9971 - dice_coefficient: 0.8232 - loss: 0.1896 - mean_io_u_2: 0.4947 - precision_1: 0.8050 - recall_1: 0.8546 - specificity: 0.9983 - val_accuracy: 0.4632 - val_auc_1: 0.9258 - val_dice_coef_oc: 0.9992 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7142 - val_loss: 0.3107 - val_mean_io_u_2: 0.4966 - val_precision_1: 0.7120 - val_recall_1: 0.7251 - val_specificity: 0.9977\n",
            "Epoch 40/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4363 - auc_1: 0.9723 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9970 - dice_coefficient: 0.8192 - loss: 0.1938 - mean_io_u_2: 0.4946 - precision_1: 0.8037 - recall_1: 0.8479 - specificity: 0.9984 - val_accuracy: 0.4572 - val_auc_1: 0.9260 - val_dice_coef_oc: 0.9992 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.7052 - val_loss: 0.3215 - val_mean_io_u_2: 0.4966 - val_precision_1: 0.6929 - val_recall_1: 0.7239 - val_specificity: 0.9974\n",
            "Epoch 41/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4373 - auc_1: 0.9714 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9971 - dice_coefficient: 0.8177 - loss: 0.1955 - mean_io_u_2: 0.4947 - precision_1: 0.8043 - recall_1: 0.8442 - specificity: 0.9984 - val_accuracy: 0.4491 - val_auc_1: 0.9282 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9972 - val_dice_coefficient: 0.7075 - val_loss: 0.3193 - val_mean_io_u_2: 0.4974 - val_precision_1: 0.6873 - val_recall_1: 0.7347 - val_specificity: 0.9973\n",
            "Epoch 42/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.4370 - auc_1: 0.9707 - dice_coef_oc: 0.9994 - dice_coef_od: 0.9971 - dice_coefficient: 0.8156 - loss: 0.1983 - mean_io_u_2: 0.4948 - precision_1: 0.7968 - recall_1: 0.8488 - specificity: 0.9983 - val_accuracy: 0.4338 - val_auc_1: 0.9274 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9968 - val_dice_coefficient: 0.7071 - val_loss: 0.3194 - val_mean_io_u_2: 0.4966 - val_precision_1: 0.6885 - val_recall_1: 0.7329 - val_specificity: 0.9973\n",
            "Epoch 43/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4367 - auc_1: 0.9703 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9972 - dice_coefficient: 0.8162 - loss: 0.1973 - mean_io_u_2: 0.4945 - precision_1: 0.8009 - recall_1: 0.8459 - specificity: 0.9983 - val_accuracy: 0.4346 - val_auc_1: 0.9263 - val_dice_coef_oc: 0.9996 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.7107 - val_loss: 0.3161 - val_mean_io_u_2: 0.4967 - val_precision_1: 0.6919 - val_recall_1: 0.7326 - val_specificity: 0.9974\n",
            "Epoch 44/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4355 - auc_1: 0.9711 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9972 - dice_coefficient: 0.8187 - loss: 0.1944 - mean_io_u_2: 0.4948 - precision_1: 0.8021 - recall_1: 0.8496 - specificity: 0.9984 - val_accuracy: 0.4350 - val_auc_1: 0.9210 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9969 - val_dice_coefficient: 0.7029 - val_loss: 0.3247 - val_mean_io_u_2: 0.4973 - val_precision_1: 0.6951 - val_recall_1: 0.7180 - val_specificity: 0.9975\n",
            "Epoch 45/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4359 - auc_1: 0.9710 - dice_coef_oc: 0.9994 - dice_coef_od: 0.9973 - dice_coefficient: 0.8239 - loss: 0.1894 - mean_io_u_2: 0.4947 - precision_1: 0.8081 - recall_1: 0.8516 - specificity: 0.9984 - val_accuracy: 0.4265 - val_auc_1: 0.9197 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9967 - val_dice_coefficient: 0.6996 - val_loss: 0.3280 - val_mean_io_u_2: 0.4966 - val_precision_1: 0.6900 - val_recall_1: 0.7120 - val_specificity: 0.9974\n",
            "Epoch 46/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4363 - auc_1: 0.9686 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9973 - dice_coefficient: 0.8147 - loss: 0.1990 - mean_io_u_2: 0.4951 - precision_1: 0.8016 - recall_1: 0.8417 - specificity: 0.9984 - val_accuracy: 0.4249 - val_auc_1: 0.9291 - val_dice_coef_oc: 0.9996 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7156 - val_loss: 0.3101 - val_mean_io_u_2: 0.4968 - val_precision_1: 0.7031 - val_recall_1: 0.7330 - val_specificity: 0.9975\n",
            "Epoch 47/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4358 - auc_1: 0.9705 - dice_coef_oc: 0.9994 - dice_coef_od: 0.9972 - dice_coefficient: 0.8179 - loss: 0.1955 - mean_io_u_2: 0.4944 - precision_1: 0.8027 - recall_1: 0.8451 - specificity: 0.9983 - val_accuracy: 0.4480 - val_auc_1: 0.9273 - val_dice_coef_oc: 0.9996 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7108 - val_loss: 0.3152 - val_mean_io_u_2: 0.4971 - val_precision_1: 0.6948 - val_recall_1: 0.7331 - val_specificity: 0.9974\n",
            "Epoch 48/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4360 - auc_1: 0.9706 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9971 - dice_coefficient: 0.8135 - loss: 0.1999 - mean_io_u_2: 0.4950 - precision_1: 0.7962 - recall_1: 0.8455 - specificity: 0.9983 - val_accuracy: 0.4587 - val_auc_1: 0.9292 - val_dice_coef_oc: 0.9994 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7067 - val_loss: 0.3199 - val_mean_io_u_2: 0.4971 - val_precision_1: 0.6868 - val_recall_1: 0.7339 - val_specificity: 0.9973\n",
            "Epoch 49/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4381 - auc_1: 0.9712 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9973 - dice_coefficient: 0.8147 - loss: 0.1988 - mean_io_u_2: 0.4946 - precision_1: 0.7976 - recall_1: 0.8474 - specificity: 0.9983 - val_accuracy: 0.4538 - val_auc_1: 0.9297 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9973 - val_dice_coefficient: 0.7144 - val_loss: 0.3117 - val_mean_io_u_2: 0.4972 - val_precision_1: 0.6985 - val_recall_1: 0.7374 - val_specificity: 0.9975\n",
            "Epoch 50/50\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4360 - auc_1: 0.9713 - dice_coef_oc: 0.9993 - dice_coef_od: 0.9972 - dice_coefficient: 0.8237 - loss: 0.1894 - mean_io_u_2: 0.4949 - precision_1: 0.8067 - recall_1: 0.8533 - specificity: 0.9984 - val_accuracy: 0.4504 - val_auc_1: 0.9291 - val_dice_coef_oc: 0.9993 - val_dice_coef_od: 0.9970 - val_dice_coefficient: 0.7055 - val_loss: 0.3215 - val_mean_io_u_2: 0.4970 - val_precision_1: 0.6835 - val_recall_1: 0.7333 - val_specificity: 0.9973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m2.save_weights(\"/content/cupandDisctrainedScnn.weights.h5\")"
      ],
      "metadata": {
        "id": "aEgksjCF4APs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m2.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_smlm1-67mIy",
        "outputId": "80fe6c8f-420e-4cca-b5d6-d8387a90195f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.4486 - auc_1: 0.9265 - dice_coef_oc: 0.9888 - dice_coef_od: 0.9558 - dice_coefficient: 0.7079 - loss: 0.3181 - mean_io_u_2: 0.4967 - precision_1: 0.7050 - recall_1: 0.7222 - specificity: 0.9975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3273044228553772,\n",
              " 0.44347959756851196,\n",
              " 0.4966471791267395,\n",
              " 0.6982855796813965,\n",
              " 0.9582720994949341,\n",
              " 0.9894477725028992,\n",
              " 0.9975256323814392,\n",
              " 0.7125670909881592,\n",
              " 0.9218378067016602,\n",
              " 0.6990357637405396]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T1=x_test[0]\n",
        "T1=np.expand_dims(T1,axis=0)\n",
        "out3=m2.predict(T1)\n",
        "\n",
        "y_test[0].shape"
      ],
      "metadata": {
        "id": "1QwQJMHKm6aS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4364dd8e-4264-430b-a562-17ed2180d3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out3.min(),out3.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xsLL-OQxrU0",
        "outputId": "624ae9dc-ec6a-401a-9969-000e655a5817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5935066e-16 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(out3[0][:,:,0]>0.5, cmap='gray')  # Channel 0\n",
        "ax[1].imshow(out3[0][:,:,1]>0.5, cmap='gray')  # Channel 1\n",
        "# Channel 2\n",
        "# ax[2].imshow(y_test[0][:,:,2], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "NebhgmVTxh6x",
        "outputId": "2da0ed34-93d8-4ede-8321-d48b17370f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(out3[0][:,:,0]>0.9, cmap='gray')  # Channel 0\n",
        "ax[1].imshow(out3[0][:,:,1]>0.9, cmap='gray')  # Channel 1\n",
        "# Channel 2\n",
        "# ax[2].imshow(y_test[0][:,:,2], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "zPJupzg0xjFx",
        "outputId": "b697057c-c19d-483e-d0a4-31a869e59b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 4)\n",
        "ax[0].imshow(out3[0][:,:,0]>0.98, cmap='gray')  # Channel 0\n",
        "ax[1].imshow(out3[0][:,:,1]>0.98, cmap='gray')  # Channel 1\n",
        "# Channel 2 - y_test only has 2 channels, so use index 1 instead of 2\n",
        "ax[2].imshow(y_test[0][:,:,1], cmap='gray')\n",
        "ax[3].imshow(y_test[0][:,:,0], cmap='gray') # Corrected to access channel 1\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "4HJarKewWlR8",
        "outputId": "86f7192e-e168-405c-9ba6-6bc584541cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}